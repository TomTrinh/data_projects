"from_id","from_name","message","created_time","type","link","id","story","likes_count","comments_count","shares_count"
"10210845468545723","Vịt Trần","Chắc trang machinelearningmastery.com không còn lạ gì với các bạn. Tuy nhiên mình chưa bao giờ tìm được sách của trang này cả. Không biết có bạn nào có, có thể cho mình ""mượn"" đọc thử :D.

Nếu bạn có cuốn này ""Discover XGBoost With Python!"" thì thật là tuyệt.","2017-02-28T02:24:09+0000","status",NA,"472656846222343_754318104722881",NA,7,3,0
"10208357389116300","Nguyen Le Xuan Bach","Giới thiệu sách:
Đây là quyển sách mới do WILEY xuất bản ngày 24/10/2016.
Nội dung viết về lý thuyết thống kê cơ bản nhưng với cách trình bày khác, chủ yếu là hình ảnh minh họa đễ dễ nắm bắt hơn.
Xem thêm thông tin tại trang chủ WILEY: http://www.wiley.com/WileyCDA/WileyTitle/productCd-1119272033,descCd-buy.html
Và bài viết của tác giả: http://www.statisticsfromatoz.com/blog/the-book-statistics-from-a-to-z-confusing-concepts-clarified-is-now-available

Bạn nào cần thì pm nhé
hi all, Comment nào mình đã like, là đã gởi qua email hoặc tin nhắn của Face. Nhớ kiểm tra luôn phần tin nhắn yêu cầu, vì chưa kết bạn thì face sẽ đẩy qua bên đó. Nhiều quá không trả lời từng bạn được, thông cảm ạ","2016-10-26T12:15:35+0000","photo","https://www.facebook.com/photo.php?fbid=10207355225302831&set=gm.683764491778243&type=3","472656846222343_683764491778243",NA,197,286,40
"388815564825175","Lê Thị Hồng Thuỷ","cho e hỏi gán giá trị vào những ô dữ liệu trống như thế nào ạ?","2017-02-27T12:48:31+0000","photo","https://www.facebook.com/photo.php?fbid=388210291552369&set=gm.753983698089655&type=3","472656846222343_753983698089655",NA,1,2,0
"10208725271269151","Dung Nguyen Chi","Hanoi UseR! Meetup Announcement:

CÔNG BỐ ĐỊA ĐIỂM VÀ THỜI GIAN CHÍNH THỨC CHO ""R User Meeting"" .  

Dear các bạn, 

Nhóm tổ chức xin thông báo về thời gian và địa điểm buổi gặp mặt đầu tiên của cộng đồng người sử dụng R tại Hà Nội:

- Địa điểm: văn phòng công ty RTA, tầng 11, tòa nhà CATHAY, 167 Bùi Thị Xuân, Hà Nội

- Thời gian: thứ 7, ngày 04/03/2017, bắt đầu lúc 8:30

Các bạn đã đăng ký ngày Chủ nhật xin vui lòng thu xếp sang thứ 7 vì tòa nhà không làm việc ngày chủ nhật. Các bạn vẫn có thể đăng ký tham gia hoặc trình bày lightning talk tại đường link sau: https://goo.gl/forms/m6v8gX1j9WePI11s1

Thông tin liên hệ và hỗ trợ: Dũng (FB:  Dung Nguyen Chi) hoặc An Tom (097.3318.922)

Cảm ơn mọi người và rất mong được gặp các bạn. 

Thay mặt nhóm tổ chức: Nguyễn Chí Dũng","2017-02-27T07:22:28+0000","photo","https://www.facebook.com/photo.php?fbid=10208716235203255&set=gm.753883504766341&type=3","472656846222343_753883504766341",NA,50,5,0
"10210845468545723","Vịt Trần","Không có gì thú vị hơn là xem một trang web đẹp như vậy.","2017-02-26T23:32:04+0000","link","http://students.brown.edu/seeing-theory/index.html","472656846222343_753711368116888",NA,63,7,12
"10208725271269151","Dung Nguyen Chi","Thăm dò ý kiến cho ""Cuộc gặp mặt của những người sử dụng R ở Hà Nội"" 

Thân chào các bạn - những người sử dụng R. 

Sau khi tham khảo ý kiến một số người như anh Le Dang Trung ,Thanh Le, An Tom, Hoang Duc Anh , Mai Huong To, Ho Bich Hai ..
mình lên kế hoạch  tổ chức gặp mặt cho những anh/ chị /em sử dụng R (sau đây gọi là Vietnam R Users) tại Hà Nội nhằm tạo một không gian cho trao đổi, học hỏi lẫn nhau cũng như khả năng ứng dụng R trong industries cũng như nghiên cứu. 

Trước mắt gần như chắc chắn sẽ có các bạn được mình tag ở trên kia có mặt. Họ là những đại diện (hoặc đồng thời) cho cả hai khu vực mà R có thể sử dụng: industries và nghiên cứu. 

Trước hết mình muốn các bạn cho ý kiến về những điểm sau. 

1. Về thời gian gặp mặt nhau mình dự kiến là ngày mùng 4 hoặc mùng 5 tháng 3 (vì đó là ngày thứ 7 và Chủ Nhật). 

2. Về địa điểm tổ chức gặp mặt: dự kiến ở tầng 11, số 167 phố Bùi Thị Xuân - Quận Hai Bà Trưng  - Hà Nội (gần Vincom Bà Triệu). 

3. Nội dung (main topics) của lần gặp mặt lần này chính là thứ mình muốn nhận được phản hồi của các bạn vì đến giờ mình vẫn chưa có ý tưởng gì cho phần chủ đạo này. 

Rất mong nhận được sự phản hồi tích cực và hăng hái của các bạn. Cảm ơn các đóng góp và phản hồi của các bạn vì một cuộc gặp thành công và bổ ích cho tất cả.","2017-02-22T14:27:26+0000","photo","https://www.facebook.com/photo.php?fbid=10208682014507759&set=gm.751449485009743&type=3","472656846222343_751449485009743",NA,126,35,0
"10208725271269151","Dung Nguyen Chi","Phiếu thăm dò ý kiến cho ""Hanoi UseR! Meetup"" 

Thân chào các bạn, 

Như đã thông báo, mình muốn nhận được phản hồi của các bạn nhằm tổ chức một cách thành công Hanoi UseR! Meetup sẽ diễn ra vào đầu tháng 3. 

Vậy mong các bạn vui lòng điền cho mình những thông tin có link dưới đây: 

https://docs.google.com/forms/d/e/1FAIpQLSfvkKxXK5EwQBhzJDK3F717hKliuP48VVNTU3zNs3pFUozG-Q/viewform?c=0&w=1

Cảm ơn các bạn nhiều.","2017-02-23T14:34:34+0000","photo","https://www.facebook.com/photo.php?fbid=10208689070364151&set=gm.751939664960725&type=3","472656846222343_751939664960725",NA,26,0,0
"10210845468545723","Vịt Trần","Trên thực tế, chúng ta lúc nào cũng thiếu dữ liệu chất lượng. Chỉ có trường hợp lí tưởng, chúng ta mới có đủ dữ liệu. Mô phỏng Monte Carlo và Bootstrap là hai phương pháp giúp bạn khẳng định tính robust của mô hình của bạn. Xin chia sẻ với các bạn chương 8 của Machine Learning in Medicine project.

Những ai có góp ý gì cho bài viết, mình rất vui. Cám ơn các bạn.

","2017-02-09T02:03:43+0000","link","http://rpubs.com/tkvit/248504","472656846222343_743537495800942",NA,27,4,4
"1627919773889937","Nguyen Chi Thanh","Một kho dữ liệu khổng lồ.
","2017-02-14T07:52:02+0000","link","https://www.gapminder.org/data/","472656846222343_746341562187202",NA,51,2,21
"1104669302995554","Anh Nguyen","Chào mọi người. Mình là beginner trong R và mình đang bị stuck mong mọi người comment giúp. Mình muốn extract 3 ký tự đầu trong tên mẫu để merge các mẫu cùng tên với nhau lai. Code bên dưới chạy rất tốt khi extract and merge ký tự đầu tiên nhưng khi làm cho 3 ký tự thì mình gặp error cho hàm if

mergeATClevel2<-function(data){
       # for tests: levels=c(""A"",""B"")
       levels=c(""A02"",""A03"",""A04"","") 
       mergedatc=c()
       for(level in levels){
         print(paste(""level"",level))
         levelValues=c()
         # loop over samples
         for (colIndex in 1:ncol(data)){
           value=0
           # loop over rows
           for (rowIndex in 1:nrow(data)){
             threefirstLetter=strsplit(rownames(data)[rowIndex],split="""")[[1]][1:3]
            
             # row belongs to current level (starts with the level letter)
            
              if(threefirstLetter==level){
               if(data[rowIndex,colIndex]==1){
                 value=1
                 #print(paste(rownames(data)[rowIndex],"" is part of level "",level,sep=""""))
               }
             }
           } # end row loop
           levelValues=append(levelValues,value)
         } # end column loop
         mergedatc=rbind(mergedatc,levelValues)
       } # end level loop
       rownames(mergedatc)=levels
       colnames(mergedatc)=colnames(data)
       return(mergedatc)
     }

Warning:
In if (threefirstLetter == level) { ... :
  the condition has length > 1 and only the first element will be used

Mình biết là condition cho phần    
 if(threefirstLetter==level){
               if(data[rowIndex,colIndex]==1){
                 value=1

không được execute vì file output toan ""0"" nhưng mình không biết sửa code như thế nào. 
Mong mọi người giúp đỡ. Thanks a lot in advance!","2017-02-14T08:01:09+0000","link","http://[1:3]/","472656846222343_746346188853406",NA,4,4,0
"1530258666992232","Namlun Didong","Repost lại tập 8 series MLR Tutorial với kết quả mở rộng.","2017-02-12T18:43:47+0000","link","http://rpubs.com/ledongnhatnam/249423","472656846222343_745522138935811",NA,17,2,0
"1412242695487170","Linh Pham","Hi cả nhà,
Mình có data như sau:
id rule no_of_participants
1 1 4
2 2,3 6,8
3 4 2
trong đó có id 2 thõa mãn 2 rules: 2 và 3 với no_of_participants tương ứng là 6 và 8.
Mình muốn tách quan sát thứ 2 thành 2 quan sát riêng biệt tương ứng với mỗi rule và output sẽ như sau:
id rule no_of_participants
1 1 4
2 2 6
2 3 8
3 4 2

Rất mong được các bạn giúp đỡ (data in attached)","2017-02-12T12:26:39+0000","status",NA,"472656846222343_745355795619112",NA,0,2,0
"1860259990910347","Phuc Trinh","http://www.listendata.com/2016/02/propose-your-crush-with-r.html :D","2017-02-13T17:35:06+0000","link","http://www.listendata.com/2016/02/propose-your-crush-with-r.html","472656846222343_746001215554570",NA,18,0,2
"1298955620186423","Phat Chau","em xin chào mọi người
mọi người giúp em với
mọi người có thể cho em xin sách mà liên quan đến packages :""dplyr""
em xin cảm ơn","2017-02-09T04:23:27+0000","status",NA,"472656846222343_743586159129409",NA,5,7,2
"10206049751402436","Dương Lê Hoàng","TỰ HỌC DPLYR VỚI PACKAGE ""SWIRL""

Chào mọi người,
Mình thấy các câu hỏi liên quan đến cleaning và transform data rất hay xuất hiện trong group nên xin giới thiệu package ""swirl"", có thể dùng để học cách vận dụng dplyr để transform data, và các ứng dụng khác của R thông qua phương thức tương tác trên dòng lệnh.
Mọi người cài swirl bằng 

install.packpages(""swirl"")
library(""swirl"")
swirl()

sau đó theo hướng dẫn để cài course mà mình quan tâm nhé.","2017-02-13T04:00:43+0000","photo","https://www.facebook.com/photo.php?fbid=10205954500421221&set=gm.745726118915413&type=3","472656846222343_745726118915413",NA,14,0,0
"1530258666992232","Namlun Didong","Bài này sẽ hướng dẫn các bạn sử dụng vòng lặp trong R để dựng 50 mô hình Mixed linear tổ hợp giữa 10 outcomes và 5 predictor, trong bộ số liệu PISA 2013.

","2017-02-08T19:17:42+0000","link","http://rpubs.com/ledongnhatnam/248362","472656846222343_743406829147342",NA,11,3,2
"10212424694997184","Trinh Dinh Hoang","Hi,

I met the problem below and do not know how to find and fix the error, please help. Thanks!

 LeafData<- read.table(file=""D:/0.Wildcru2017/1. Distance learning/3.Statistics and R/RBasicSkills/LeafSizes.txt"",sep=""\t"",header=TRUE)
Error in file(file, ""rt"") : cannot open the connection
In addition: Warning message:
In file(file, ""rt"") :
  cannot open file 'D:/0.Wildcru2017/1. Distance learning/3.Statistics and R/RBasicSkills/LeafSizes.txt': No such file or directory","2017-02-09T02:50:47+0000","status",NA,"472656846222343_743557292465629",NA,0,3,0
"10155116806962188","Ha Do","moi cac data scientist vao tra loi, minh k lam chuyen ve data nen chi tra loi dc co 5/20 cau thoi hi hi
","2017-01-26T23:28:02+0000","link","https://www.quora.com/What-are-20-questions-to-detect-fake-data-scientists","472656846222343_736626053158753",NA,16,4,2
"1451674964905185","Tamu Le","Xin sách.
Mình đang đọc về quy hoạch thực nghiệm, nếu anh/chị nào có quyển https://www.crcpress.com/Design-and-Analysis-of-Experiments-with-R/Lawson/p/book/9781439868133 cho mình xin với nhé. Cám ơn anh/chị nhiều !","2017-01-19T14:33:23+0000","link","https://www.crcpress.com/Design-and-Analysis-of-Experiments-with-R/Lawson/p/book/9781439868133","472656846222343_732167343604624",NA,13,5,0
"10210845468545723","Vịt Trần","Giới thiệu cách vẽ hyetograph và Discharge  bằng ggplot2 và highcharter cho các bạn nào cần. Chúc các bạn vui.","2017-02-07T18:56:49+0000","link","http://rpubs.com/tkvit/248048","472656846222343_742861682535190",NA,21,0,2
"1530258666992232","Namlun Didong","CARET đấu với MLR: Tại sao Grid-based Tuning + Feature selection đáng tin cậy hơn quy trình tự động ?","2017-02-03T12:18:43+0000","link","http://rpubs.com/ledongnhatnam/246827","472656846222343_740508929437132",NA,9,0,1
"1530258666992232","Namlun Didong","Lần đầu tiên chúng tôi kết hợp Machine learning và Survival analysis. Trong bài giới thiệu 2 mô hình Cox-PH cổ điển và Cox Boosting, cùng tất cả những kỹ thuật ML cho 2 mô hình này.","2017-01-31T20:43:21+0000","link","http://rpubs.com/ledongnhatnam/246047","472656846222343_739106536244038",NA,28,0,3
"10208725271269151","Dung Nguyen Chi","Chi tiết tinh tế khi chia dữ liệu của hàm createDataPartition

Các thuật toán Machine Learning thường được sử dụng cho việc dự báo và mức chính xác trong dự báo của các thuật toán, ngoài những cái khác, là phụ thuộc đáng kể vào phân chia dữ liệu thành dữ liệu kiểm định và dữ liệu huấn luyện mà một trong các mấu chốt của phân chia dữ liệu là đảm bảo rằng các nhóm (các lớp) ở bộ dữ liệu huấn luyện và kiểm định phải có phân phối tương đương nhau (Calrk, 1997; Willet, 1999).

http://rpubs.com/chidungkt/245369

Bài viết này cũng là một phản hồi trước câu hỏi của Vịt Trần về việc xài caret khi làm ML hay làm thủ công bằng các gói riêng biệt.","2017-01-29T10:17:14+0000","status",NA,"472656846222343_737828703038488",NA,12,1,2
"1913258532222776","Tran Quy Phi",NA,"2017-01-27T23:42:54+0000","photo","https://www.facebook.com/photo.php?fbid=1897805237101439&set=gm.737126699775355&type=3","472656846222343_737126699775355",NA,21,0,0
"1530258666992232","Namlun Didong","MLM Case 52: The ROC curve as we know is just a two dimensioned line plot that shows the relationship between Sensitivity and 1-Specificity of a given classifier. So ANY classification rule (not a diagnostic test by its own, but any rule that implies stand-alone or combined clinical data, including symtomps, laboratory markers and medical imaging, simple or sophisticated algorithm…) could be visually evaluated by a ROC curve.

","2017-01-25T21:30:27+0000","link","http://rpubs.com/ledongnhatnam/244316","472656846222343_736016813219677",NA,9,1,1
"10210845468545723","Vịt Trần","#Rvui
Nếu làm với R nhiều, bằng cách này hoặc cách khác bạn sẽ phải sử dụng dplyr và data.table, hai gói package soái ca soái tỉ này.

Serie Rvui trở lại, chúc các bạn năm mới Tết đến ăn mau chóng lớn, được nhiều lì xi hoặc lì xi được nhiều người :)","2017-01-25T14:58:17+0000","link","http://rpubs.com/tkvit/244552","472656846222343_735820393239319",NA,21,0,0
"10210845468545723","Vịt Trần","MLM Case Study 57

Bác sĩ Nam đã giới thiệu với các bạn cách tiếp cận case study 57 bằng 2 mô hình Support Vector Machine và Extreme Gradient Boosting Tree. 

Mình xin được tiếp tục bài này bằng một cách nhìn khác : ""Liệu có đáng để làm một mô hình phức tạp hơn rất nhiều để cải thiện độ chính xác của mô hình một vài phần trăm? Bạn sẽ chọn thời gian tính toán hay độ chính xác của mô hình""

Bài này không chủ ý trau chuốt phần visualization nên hơi khô khan.","2017-01-24T04:11:53+0000","link","http://rpubs.com/tkvit/244156","472656846222343_734921556662536",NA,11,0,2
"1530258666992232","Namlun Didong","Đây là 1 thí nghiệm đặc biệt, nó khác với tất cả những nghiên cứu mà ta thường thấy, vì ở đây câu hỏi không phải là Dự báo (điều gì sẽ xảy ra), mà là ""Ta sẽ phải làm gì ?"". Như vậy mục tiêu là dùng Machine learning để giúp đưa ra quyết định đúng trong việc lựa chọn phương pháp điều trị. Và kết quả xuất ra của mô hình cây chính là 1 phác đồ điều trị đấy các bạn.

","2017-01-22T23:21:27+0000","link","http://rpubs.com/ledongnhatnam/243806","472656846222343_734175610070464",NA,17,0,3
"1530258666992232","Namlun Didong","Case study 7 in MLM project: Tại sao nên áp dụng Machine learning vào nghiên cứu, ngay cả cho mục tiêu diễn dịch ?

","2017-01-22T14:26:57+0000","link","http://rpubs.com/ledongnhatnam/243708","472656846222343_733896063431752",NA,8,0,1
"812309398919376","TuanVu Dang","Hi cả nhà, 

Cho em hỏi chút: 
Em đọc nội dung từ 1 file HTML thẳng vào content của outlook mà bị lỗi hình ảnh ( thiếu mất cái graph trong file HTML), có ai đã từng gặp và biết cách khắc phục không ạ. Em cảm ơn.!!

PS: bên dưới bao gồm code, nội dung outlook nhận và nội dung markdown.","2017-01-21T12:05:43+0000","photo","https://www.facebook.com/photo.php?fbid=788850704598579&set=gm.733135093507849&type=3","472656846222343_733135093507849",NA,2,2,0
"10208725271269151","Dung Nguyen Chi","Đây có là một trong những cuốn sách hay nhất về R cho thống kê. Hàng mới năm 2016 của Wiley. 

PS.  theo quy định của G này mình không post link download được. Tuy nhiên bạn nào cần sách có thể inbox với mình.","2016-06-16T20:59:32+0000","photo","https://www.facebook.com/photo.php?fbid=10206728542392177&set=gm.618516938302999&type=3","472656846222343_618516938302999",NA,213,134,8
"1530258666992232","Namlun Didong","The 57th case study (Chapter 13 - Machine Learning in Medicine-Cookbook Three  by T. J. Cleophas and A. H. Zwinderman, Springer, 2014) allows us to set up a duel match between 2 monsters in ML world: Extreme Gradient Boosting Tree versus Support Vector Machine. Who will be the winner ? 

","2017-01-20T11:49:11+0000","link","http://rpubs.com/ledongnhatnam/243186","472656846222343_732557040232321",NA,10,0,1
"10155161088099189","Mai Huong To","Các bác ơi, cho em hỏi 1 chút về lỗi này với : 
Em muốn vẽ boxplot của các biến (numeric) theo ID thì gặp lỗi Error: ggplot2 doesn't know how to deal with data of class numeric
---
rx0<-data.frame(rx0)
par(mfrow=c(2,3))
par(bg=""grey90"")
for(i in 4:9) {
  ggplot(rx0[, i], aes(x=rx0$ID, rx0[, i], colour = rx0$ID)) + geom_boxplot(show.legend = F) +   geom_hline(yintercept = mean(rx0[, i]), color = ""gold"")
}

----- 
Tuy nhiên, nếu em vẽ bình thường thì lại ok, nhưng lại không vẽ được được hline= yintercept = mean(rx0[, i])

for(i in 4:9) {
  boxplot(rx0[ ,i] ~ rx0$ID, col = rainbow(2), main=names(rx0$ID)[i])
}

Em cảm ơn ạ <3","2017-01-20T03:31:37+0000","status",NA,"472656846222343_732412900246735",NA,0,2,0
"1530258666992232","Namlun Didong","Dự án Machine learning in Medicine: Case study số 46: Dùng Cluster analysis để khai thác thông tin trong bộ dataset các biomarker cho bệnh viêm phổi.

Bài này đặt trọng tâm vào đồ họa, rất nhiều chiêu thức đã được sử dụng.

","2017-01-17T23:28:03+0000","link","http://rpubs.com/ledongnhatnam/242506","472656846222343_731310143690344",NA,30,2,3
"10210845468545723","Vịt Trần","Sau một thời gian lăn tăn, mình rút ra kết luận như vậy: package caret hay mlr chỉ tiện dụng khi bạn muốn làm exploration các mô hình khác nhau, nhưng không thể nào thay thế được cách viết thủ công, dùng từng package riêng lẻ. Không biết các bạn có ý kiến thế nào?","2017-01-17T00:14:43+0000","status",NA,"472656846222343_730761027078589",NA,7,5,0
"10208725271269151","Dung Nguyen Chi","Chào cả nhà ạ, 

Mình có bài toán này và mong nhận được ý kiến phản hồi từ mọi người: 

http://rpubs.com/chidungkt/242457

Cảm ơn các bạn rất nhiều.","2017-01-17T19:16:28+0000","link","http://rpubs.com/chidungkt/242457","472656846222343_731206187034073",NA,14,2,0
"1253776067993234","Nguyen Hiep","Nhờ các bạn, các bác tiền bối giúp đỡ.
1. Em có bảng số liệu gồm: 
Cỡ mẫu 100 và, mỗi đối tượng nhận các giá trị:
Time (0- 180 days),
PF (0-3)
CVF (0-3)
Activity (0-3)
Biến time cần phân nhóm lại theo tuần: 1, 2, 3, ..... 26
2. Câu hỏi đặt ra là: 
Em muốn vẽ một biểu đồ gồm 3 line graphs thể hiện sự biến thiên giá trị trung bình của PF, CVF, Activity, theo thời gian (tuần 1, 2, 3 ...) 
(như hình dưới_vẽ bằng exel_ cần thêm error bars)

Em cảm ơn nhiều.

Code cho group từ time (day) sang tuần:
fibrosis <-read.csv(""AI"" , header = TRUE)
fibrosis$week[Time <=7] <- 1 
fibrosis$week[Time > 7 & Time <= 14] <- 2 
fibrosis$week[Time > 14 & Time <= 21] <- 3 
fibrosis$week[Time > 21 & Time <= 28] <- 4 
fibrosis$week[Time > 28 & Time <= 35] <- 5 
fibrosis$week[Time > 35 & Time <= 42] <- 6 
fibrosis$week[Time > 42 & Time <= 49] <- 7 
fibrosis$week[Time > 49 & Time <= 56] <- 8 
fibrosis$week[Time > 56 & Time <= 70] <- 10 
fibrosis$week[Time > 70 & Time <= 84] <- 12 
fibrosis$week[Time > 84 & Time <= 98] <- 14 
fibrosis$week[Time > 98 & Time <= 112] <- 16 
fibrosis$week[Time > 112 & Time <= 126] <- 18 
fibrosis$week[Time > 126 & Time <= 140] <- 20 
fibrosis$week[Time > 140 & Time <= 154] <- 22 
fibrosis$week[Time > 154 & Time <= 168] <- 24 
fibrosis$week[Time > 168 & Time <= 180] <- 26","2017-01-17T12:58:22+0000","status",NA,"472656846222343_731059047048787",NA,1,3,1
"10210845468545723","Vịt Trần","[Machine Learning] Mình có một câu hỏi nhỏ, sau khi các bạn nắm tương đối về các thuật toán ML, lập trình bắt đầu kha khá, bước tiếp theo để nâng cao tư duy trong ML sẽ là gi? Và đối với bạn đỉnh cao của ML là ở đâu?

Vì đặt trong ngữ cảnh, các package bây giờ càng ngày càng tiện sử dụng, điển hình như caret và mlr, nếu chỉ đơn giản là cho chạy một loạt các mô hình rồi dựa trên các thông số phán thì e là quá dễ.

Riêng mình đang trau dồi phần feature engineering nhưng quá khó khó quá.","2016-12-25T23:15:55+0000","status",NA,"472656846222343_718889441599081",NA,10,9,0
"1530258666992232","Namlun Didong","Case study số 31 trong dự án Machine learning in medicine là 1 trường hợp khó chịu. Mục tiêu của chúng ta là áp dụng được Bootstrap và Kfold cross validation cho 1 linear mixed model. Do chủ đề này chưa từng được hỗ trợ trong cả caret và mlr, tác giả phải làm thủ công toàn bộ. Sau đây là báo cáo kết quả:

","2017-01-18T09:19:22+0000","link","http://rpubs.com/ledongnhatnam/241926","472656846222343_731520083669350",NA,25,0,1
"1264476596972172","Tom Duong","Em xin phép group, em có 1 câu hỏi ạ:
Em kiểm tra chiều dài sợi cây theo độ tuổi ở 2 vị trí trồng khác nhau (Y ~ X | site), sau khi plot em thấy rằng mối liên quan giữa 2 biến ở dạng đường cong (tuổi thấp, chiều dài tăng mạnh, về sau ổn định). Câu hỏi của em là xây dựng mô hình tiên đoán Y ~ X theo site trên R như thế nào ạ?
Rất mong các anh chị giúp đỡ.","2017-01-17T03:32:40+0000","status",NA,"472656846222343_730824243738934",NA,2,1,0
"1474530155892412","Le Nguyen","Mọi người ơi làm thế nào để cài R bản mới nhất nhỉ? Thanks.","2017-01-15T23:41:12+0000","status",NA,"472656846222343_730188140469211",NA,1,3,0
"1264476596972172","Tom Duong","Mọi người trong nhóm ai có tài liệu nói về  Non-linear regression model in R cho em xin với ạ? Em trân thành cảm ơn.","2017-01-16T09:13:02+0000","status",NA,"472656846222343_730430630444962",NA,1,2,1
"1298955620186423","Phat Chau","mọi ngưởi ơi xin giúp đỡ cho em với
Em có 1 file dữ liệu khoàng 1 triệu dòng
Trong dữ liệu có cột khách hàng, em muốm đềm khách hàng có mã phiếu giống nhau thì làm như thế nào mọi người","2017-01-16T04:11:17+0000","status",NA,"472656846222343_730298840458141",NA,2,2,0
"10210265532367664","Khánh Nguyễn","Chào anh, chị,
Anh chị nào có bản mềm cuốn sách này  ""Research methodology in applied economics"" của tác giả ""Don Ethridge"" xuất bản năm 2004 thì cho em xin với ạ. Em xin chân thành cảm ơn !
P/s: xin cảm ơn admin đã duyệt bài.","2017-01-16T02:37:17+0000","photo","https://www.facebook.com/photo.php?fbid=10209891041685631&set=gm.730255730462452&type=3","472656846222343_730255730462452",NA,4,1,0
"1233065793428203","Quang Hưng Phạm","Em chào anh chị và các bạn!
Cho em xin hỏi có anh, chị hoặc bạn nào đã từng ước lượng mô hình: Smooth Transition Regression(STR) hoặc Threshold Autoregressivie(TAR) bằng phần mềm R chưa cho em xin chỉ giáo chút kinh nghiệm ạ.

Em xin cảm ơn nhiều!","2017-01-13T00:50:41+0000","status",NA,"472656846222343_728587770629248",NA,0,1,0
"1530258666992232","Namlun Didong","Machine learning in Medicine project: Case study N°40

Body surface area (BSA) is an indicator for metabolic body mass, and is used for adjusting other physiological parameters. In clinical practice, BSA is usually approximated from Weight and Height using the Dubois formula (A polynomial model). This study aims to verify whether a model based on Bayesian regularization-feed-forward neural network - BRNN algorithm could be applied to accurately predict the body surface from gender, age, weight and height?

Materials and method

The original dataset was provided in Chaper 17, Machine Learning in Medicine—Cookbook Two (T. J. Cleophas and A. H. Zwinderman, SpringerBriefs in Statistics 2014). The target variable is BSA (in cm2) of 90 persons, calculated using direct photometric measurements. The features include: Gender, Age, Height and Weight.

Data analysis was performed in R statistical programming language. A BRNN algorithm based model was trained using brnn and mlr package. The final model's performance was evaluated by a resampling process that based on cross-validation. Attribution of each predictors to the predicted BSA was graphically evaluated using the Partial dependence function method.

","2017-01-14T20:50:26+0000","link","http://rpubs.com/ledongnhatnam/241767","472656846222343_729565800531445",NA,5,2,3
"1530258666992232","Namlun Didong","2 tựa sách mới xuất bản của Springer
, cả 2 đều có R codes","2016-11-01T10:57:16+0000","photo","https://www.facebook.com/photo.php?fbid=1358187660866001&set=gm.687444734743552&type=3","472656846222343_687444734743552",NA,70,19,5
"10210845468545723","Vịt Trần","Series Machine learning in Medicine tiếp tục với case study số 7: sử dụng Factor Analysis và Partial Least Squares Path Modelling.

Phần này được làm chung với bạn Hùng MPH, làm việc với bạn H rất là thoải mái, hiệu quả và vui. Cám ơn bạn.
Bài này tương đối đặc biệt hơn các bài khác vì thứ nhất mới đầu hơi rối với các thuật ngữ trong sách, thứ hai là Partial Least Square Path Modelling là cả một chân trời mới với bạn H và mình, thứ 3 nữa là trong khi làm phát hiện ra một vài sai sót trong sách (cả phần theory lẫn phần cookbook), cả hai đã phải rất đấu tranh để xác định lại là sách nhầm chứ không phải mình nhầm. 

Rất vui nếu mọi người có thể góp ý hoặc chỉ ra những sai sót.","2017-01-13T21:26:58+0000","link","http://rpubs.com/tkvit/241593","472656846222343_729060533915305",NA,28,0,2
"1530258666992232","Namlun Didong","R mỗi ngày 1 chút: Data reshape sử dụng package tidyverse

","2017-01-12T15:00:19+0000","link","http://rpubs.com/ledongnhatnam/241251","472656846222343_728319463989412",NA,14,0,4
"1530258666992232","Namlun Didong","Thí dụ minh họa cho sự tiện lợi của Toán tử pipe trong R:

Trong bài này, Bs. Khả Nhi sẽ minh họa ứng dụng của toán tử Pipe (%>%) bằng 1 thí dụ mang tính chất ""sinh lý học""

Giả sử ta có 1 hàm (function) cho phép ước tính gần đúng giá trị áp suất riêng phần khí O2 tại 1 trong 3 vị trí: Khí quản, Phế nang, và Động mạch nếu biết giá trị PO2 ở đầu vào.

Nếu áp dụng hàm này 3 lần với các tùy chỉnh PO2 và level khác nhau, ta sẽ có 3 kết quả khác nhau.

1 cách làm khác là đưa 1 giá trị duy nhất PO2 vào 1 quy trình liên hoàn nhờ toán tử Pipe.

Toán tử Pipe có cơ chế rất đơn giản: kết quả xuất ra của hàm đi trước sẽ được dùng như dữ liệu đầu vào của hàm tiếp theo. Từ đó ta có 1 quy trình liên hoàn, như 1 đường ống nước.

Thí dụ khác tương tự: Bạn có thể dùng Pipe để minh họa cho chu trình Krebs để tính số lượng ATP ở mỗi giai đoạn chuyển hóa Glucose...

","2017-01-12T14:14:19+0000","link","http://rpubs.com/ledongnhatnam/241247","472656846222343_728303523991006",NA,29,0,4
"10210845468545723","Vịt Trần","mlr có một trang tutorial khá là đủ nên sử dụng cũng không đến nỗi khó lắm. Hơn nữa một khi đã quen với caret thì qua mlr cũng không bỡ ngỡ. Tuy nhiên với bản thân mình thì mình thích dùng caret hay mlr để explore hơn, khi đã định hình mô hình và methodology đẩy đủ, viết bằng tay vẫn linh động hơn.

Xin lỗi vì bài viết dưới, mình mới rớt IELTS xong nên vẫn đang học :) Không phải mình thích viết tiếng anh hơn tiếng việt.","2017-01-09T05:33:11+0000","link","http://rpubs.com/tkvit/240571","472656846222343_726455797509112",NA,29,3,4
"1851955978351716","Nhung Nguyen","Hi anh chị em, em đang chạy quantile regression, dùng package [quantreg] thì bị báo lỗi Singular Matrix (như ở dưới). Em tìm hiểu thì thấy có vẻ như do data của em có một biến phân loại với khoảng 160 bậc. Nhưng em vẫn chưahiểu rõ lắm vấn đề này. Và có cách nào khác để khắc phục không ạ. Hi vọng mọi người có thể chỉ giúp. Cảm ơn anh chị em.

Error in base::backsolve(r, x, k = k, upper.tri = upper.tri, transpose = transpose,  : 
  singular matrix in 'backsolve'. First zero in diagonal [161]
In addition: Warning message:
In summary.rq(q25m_condi) : 71 non-positive fis","2016-12-31T10:13:14+0000","status",NA,"472656846222343_721738391314186",NA,4,1,0
"1913258532222776","Tran Quy Phi","Some statistics about our group.","2017-01-01T03:57:36+0000","status",NA,"472656846222343_722223027932389",NA,30,2,0
"603733173170302","Tân Trần","Chào mọi người !!!
Mọi người cho mình hỏi :Mình có 1 Dataframe bao gồm 2 cột là ID và điểm số, mỗi sinh viên có nhiều lần nộp bài, bây h làm sao để lấy ra dc 1 bảng bao gồm các lần nộp bài của sinh viên có ít nhất 1 điểm = 0 
VD:","2017-01-03T13:53:56+0000","photo","https://www.facebook.com/photo.php?fbid=576148872595399&set=gm.723499197804772&type=3","472656846222343_723499197804772",NA,2,2,0
"1253920847996458","Alon Tran","Em đang xử lý số liệu cho đề tài nghiên cứu bên sinh học cây trồng. Các chỉ tiêu sinh trưởng, phát triển và biochemical responses được thu thập. Nghiệm thức (2 yếu tố) gồm 2 species và 4 sediments.
Em đang tìm xem có mô hình tương quan hay hướng xử lý thống kê nào để so sánh mức độ sensitivity của 2 loài với nhau dựa trên các dữ liệu e thu thập ngoài việc sử dung ANOVA two-ways (interaction), correlation.
Em cần có một strong conclusion về mức độ nhạy cảm của 2 loài này trong điều kiện stress.

Mong mọi người trong forum cho em vài định hướng.
Thanks and happy new year,","2016-12-31T10:33:01+0000","status",NA,"472656846222343_721744667980225",NA,4,2,0
"10154630775082982","Duy Thọ Nguyễn","Ngày đầu năm là lúc mà chúng ta ""ôn cố tri tân"". Bài viết này cũng nằm trong tinh thần đó, tập trung cho 1 toán tử đặc biệt là %>%. 

Dù không phải được hỗ trợ mặc định từ engine của R nhưng pipe (chỉ xét trong nghĩa hẹp ở đây chỉ là %>%) đã thay đổi cách chúng ta lập trình và cả tư duy với R. 

","2017-01-01T04:38:20+0000","link","http://rpubs.com/thonguyenduy/pipe-history","472656846222343_722240987930593",NA,23,4,0
"10155067337149710","Le Dang Trung","CHÚC MỪNG NĂM MỚI 2017
Mình dùng R để xử lý Nghị định 46/2016: http://thuvienphapluat.vn/van-ban/Vi-pham-hanh-chinh/Nghi-dinh-46-2016-ND-CP-xu-phat-vi-pham-hanh-chinh-giao-thong-duong-bo-duong-sat-288330.aspx
------------------------------
# Get a website and turn it to a database

# Define the libraries for the analysis
libraries <- c(""haven"",""data.table"", ""ggplot2"", ""dplyr"",""tidyr"",""reshape2"", ""zoo"", ""stringr"", ""grid"", ""gridExtra"",""ggthemes"", ""quantmod"", ""lucr"", ""httr"", ""rvest"", ""readr"", ""docxtractr"", ""xlsx"")

# This is the function to download and/or load libraries on the fly
download_and_or_load <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, ""Package""])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

# Use the function from the last step
download_and_or_load(libraries)

nd46 <- as.data.frame(read_lines(""/Volumes/WORK/rtBox/labs/NghiDinh46_2016.txt""))
nd46$sqnum <- as.integer(rownames(nd46))
nd46$content <- nd46[,1]
nd46 <- select(nd46, sqnum, content)

nd46$dieu <- str_extract(nd46$content,regex(""^Điều \\d.""))
nd46$dieugr <- nd46$dieu
for(i in 1:nrow(nd46)) {
  word_i <- nd46$dieugr[i]
  j <- i + 1
  word_j <- nd46$dieugr[j]
  if (is.na(word_j) & is.na(word_i)==FALSE & j<=nrow(nd46)) {
    nd46$dieugr[j] <- word_i
    }
}

nd46$khoan <- str_extract(nd46$content,regex(""^\\d.""))
nd46$khoangr <- nd46$khoan
for(i in 1:nrow(nd46)) {
  word_i <- nd46$khoangr[i]
  j <- i + 1
  word_j <- nd46$khoangr[j]
  if (is.na(word_j) & is.na(word_i)==FALSE & j<=nrow(nd46)) {
    nd46$khoangr[j] <- word_i
  }
}

nd46$diem_1 <- str_extract(nd46$content,regex(""^[a-z]""))
nd46$diem_2 <- str_extract(nd46$content,regex(""^[a-z]*đ""))
nd46$diem <- str_c(nd46$diem_1,nd46$diem_2)
for(i in 1:nrow(nd46)) {
  diem2_i <- nd46$diem_2[i]
  if (diem2_i==""đ"") {
    nd46$diem[i] <- ""đ""
  }
}

nd46$maloi <- str_c(""ND46_2016."",nd46$dieugr,nd46$khoangr,nd46$diem,sep="""")

nd46$phattien_from <- str_locate(nd46$content,""Phạt tiền "")
nd46$phattien_to <- str_locate(nd46$content,"" đối với"")
nd46$tienphat <- """"
for(i in 1:nrow(nd46)) {
  pos_from <- nd46$phattien_from[i]
  pos_to <- nd46$phattien_to[i]
  if (is.na(pos_from)==FALSE & is.na(pos_to)==FALSE) {
    nd46$tienphat[i] <- str_sub(nd46$content[i],pos_from,pos_to)
  }
}

for(i in 1:nrow(nd46)) {
  word_i <- nd46$tienphat[i]
  j <- i + 1
  word_j <- nd46$tienphat[j]
  if (nchar(word_j)==0 & is.na(word_i)==FALSE & j<=nrow(nd46)) {
    nd46$tienphat[j] <- word_i
  }
}

phatGT_2017 <- nd46 %>% select(content,dieugr,khoangr,diem,maloi,tienphat) %>% filter(is.na(dieugr)==FALSE)

write.xlsx(phatGT_2017,""/Volumes/WORK/rtBox/labs/PhatGT_2017.xlsx"")

------------------------------

Kết quả là 1 db có mức phạt cho từng lỗi. Mình vẫn chưa hài lòng về mấy vòng lặp for như chưa biết phải xử lý thế nào.","2017-01-01T04:16:59+0000","link","http://thuvienphapluat.vn/van-ban/Vi-pham-hanh-chinh/Nghi-dinh-46-2016-ND-CP-xu-phat-vi-pham-hanh-chinh-giao-thong-duong-bo-duong-sat-288330.aspx","472656846222343_722230584598300",NA,25,14,0
"1913258532222776","Tran Quy Phi","HAPPY NEW YEAR WITH R!
> install.packages('animation')
> require(animation)
> demo('fireworks')","2017-01-01T03:34:58+0000","status",NA,"472656846222343_722215234599835",NA,22,2,1
"698367330368784","Trung Nhân Uchiha","Chào anh chị !
Cho em hỏi là trong một bảng data, ta cần liệt kê ra thông tin các đối tượng có số lần xuất hiện là bé hơn hoặc bằng k trong 1 cột thì làm sao ạ 
Cảm ơn mọi người !","2016-12-31T14:00:58+0000","status",NA,"472656846222343_721840567970635",NA,4,7,0
"726087944218386","Minh Thám","Cho em hỏi:
Nếu mình có một cột điểm với thang 10 , giờ mình có thể dùng gì để tìm được điểm cao thứ k, với k là một số cho  trước, và khi nhập k vào có thể chạy ra kết quả. 
Mình có nghĩ ra 1 cách là dùng subset với điểm nhỏ hơn điểm cao nhất, sau đó max(diem) với dữ liệu vừa tạo, thì được điểm cao thứ 2. Nhưng với điểm cao thứ 6,7..  phải lặp lại nhiều. Nên mong anh chị giúp em có lệnh nào trong R giúp tìm được một cách nhanh chóng không.
Cảm ơn anh chị!!","2016-12-29T08:53:57+0000","status",NA,"472656846222343_720596624761696",NA,6,5,0
"10208725271269151","Dung Nguyen Chi","Data wrangling với bộ dữ liệu PISA: 

","2016-12-29T15:22:32+0000","link","http://rpubs.com/chidungkt/238185","472656846222343_720775734743785",NA,23,1,4
"1851955978351716","Nhung Nguyen","Hi anh chị em, mọi người cho em/mình hỏi khi tính đến heterogeneity giữa các nhóm thì ta nên cân nhắc factor variables. Em/mình không hiểu tại sao trong lệnh ở dưới có thêm (trừ 1) vậy ạ? Nếu mình có trên hai factor variables thì sao? Cảm ơn mọi người đã dành thời gian.
library(foreign)
dulieu <-read.dta(""http://dss.princeton.edu/training/Panel101.dta"")
fixed.dum <-lm(y ~ x1 + factor(country) - 1, dulieu=Panel)","2016-12-28T23:48:29+0000","link","http://dss.princeton.edu/training/Panel101.dta","472656846222343_720419968112695",NA,7,1,0
"1608715779142507","Long Ngo","Chào mọi người, mọi người giúp em cái này với.

Em có 1 file Disease.csv như bên dưới, em dùng readr::read_csv() để đọc vào R thì nó cứ bị lỗi font như thế này ạ. Em đã thử đổi encoding sang UTF-8 rồi vẫn không được ạ. Em dùng excel mở ra thử thì cũng bị lỗi font luôn. Trong khi đó máy bạn em, UTF-8 là mở dc đúng font cả trong Excel lẫn Python.

Bây giờ em nên làm như thế nào ạ? 

X1
 <chr>
1  Cao huy<U+1EBF>t áp vô can (nguyên phát)(I10)
2  B<U+1EC7>nh ti<U+1EC3>u du<U+1EDD>ng không ph<U+1EE5> thu<U+1ED9>c insulin(E11)
3  B<U+1EC7>nh lý don dây th<U+1EA7>n kinh khác(G58)
4 R<U+1ED1>i lo<U+1EA1>n chuy<U+1EC3>n hóa sphingolipid và r<U+1ED1>i lo<U+1EA1>n tích luy lipid(E75)
5 Cao huy<U+1EBF>t áp vô can (nguyên phát)(I10)
6  B<U+1EC7>nh ti<U+1EC3>u du<U+1EDD>ng không ph<U+1EE5> thu<U+1ED9>c insulin(E11)","2016-12-30T12:34:15+0000","status",NA,"472656846222343_721239208030771",NA,2,4,0
"603733173170302","Tân Trần","Chào mọi người, mọi người cho mình hỏi : Mình có một tập hợp mẫu các sinh viên và điểm của sinh viên, bây h làm sao để Tính trung vị mẫu, cực đại mẫu, cực tiểu mẫu của mẫu trên bằng R ko ạ. Cảm ơn mọi người !","2016-12-31T04:54:53+0000","status",NA,"472656846222343_721633774657981",NA,1,1,0
"1128887990569960","Hiếu Phẩy","Mình có một chuỗi ký tự trong đó có 2 giá trị string ""Quản lý, điều hành bay"" và "" "" nhưng không thể nào kiểm tra được 2 giá trị này, với lệnh:

any(so_wrong == "" "")
any(so_wrong == ""Quản lý, điều hành bay"")

Theo logic thì 2 lệnh này đều phải trả lại là TRUE, nhưng trong cả hai trường hợp đều là FALSE.
Mình up hình minh họa ở dưới comment, hy vọng có người giúp mình giải đáp thắc mắc này.
Cảm ơn mọi người.","2016-12-28T19:20:45+0000","status",NA,"472656846222343_720324141455611",NA,1,5,0
"1312924752138295","Rainie Kenta","Mọi người ơi cho em hỏi một chút ạ. Yêu cầu là so sánh drug concentration giữa male và female, nhưng data lấy dưới dạng cluster (có 6 labs tương ứng với 6 cluster ạ).

Em định phân tích giống fixed-effect meta-analysis như cái hình em gửi dưới đây nhưng đang bị mắc ạ.

1. V(X_weight) = 1/sum(1/V(Xk)) khi V(Xk) biết trước. Nhưng điều này khó xảy ra trong thực tế. Nếu V(Xk) được ước lượng bằng biến ngẫu nhiên S_Xk thì suy luận bị sai hết, nhưng tại sao trong fixed-effect MA, người ta vẫn dùng V(X_weighted) = 1/sum(1/S(Xk)) ạ

2. Em muốn dùng 1 test để so sánh muy1 và muy2 thông qua X_weighted. Cần phải hiệu chỉnh t-test cho non-cluster data như thế nào ạ? Hoặc có thể dùng permutation test được không ạ?

Em hi vọng em diễn đạt tốt ạ :'(","2016-12-28T13:13:15+0000","photo","https://www.facebook.com/photo.php?fbid=1253553684742069&set=gm.720170768137615&type=3","472656846222343_720170768137615",NA,4,4,0
"180904445738884","Nguyễn Hương","cho em hỏi : Em có 1 cái data với 2 cột, uid và score.
uid là cột sinh viên , mỗi sinh viên xuất hiện nhiều lần với nhiều điểm khác nhau, làm thế nào để đưa ra một bảng mới 2 cột như vậy nhưng với mỗi sinh viên xuất hiện một lần ở uid và cột score là  điểm Max  của sinh viên đó ở cái bảng ban đầu","2016-12-28T15:03:09+0000","photo","https://www.facebook.com/photo.php?fbid=132186417277354&set=gm.720211521466873&type=3","472656846222343_720211521466873",NA,0,3,0
"1459512717394225","Duy Trần","Ai học về R rồi giúp em với. Làm sao để tính toán với dữ liệu thời gian ạ. Vd như tính khoảng thời gian nộp bài(tính từ nộp lần đầu đến nộp lần cuối) của các SV trong bảng dưới (MSSV là uid):","2016-12-21T15:25:51+0000","photo","https://www.facebook.com/photo.php?fbid=1389666077712223&set=gm.716721621815863&type=3","472656846222343_716721621815863",NA,8,5,0
"720484548128510","Huỳnh Thức","m.n cho em hỏi để tính tần xuất bấm chuông của A,B,C trong R thì phải làm thế nào ạ:::::","2016-12-27T06:50:54+0000","photo","https://www.facebook.com/photo.php?fbid=686532268190405&set=gm.719552498199442&type=3","472656846222343_719552498199442",NA,0,3,0
"631130503744147","Nhok Conan","Trên trang .packtpub.com đang Free 10 ngày dùng thử tất cả ebook và video .Rất nhiều về machine learning, data science, data mining cả R và Python . Mình đã học thử dc khoảng 5 ngày và thấy rất hay. Mọi người xem thử .
Bước 1: Truy cập https://www.packtpub.com/register để đăng ký tài khoản mới (đăng ký xong sẽ tự login)
Bước 2: Truy cập https://www.packtpub.com/packt/offers/free-learning và ấn ""Start free trial""
Bước 3: Chọn ""Skill"" -> xem khóa học, ""Library"" => đọc sách","2016-12-28T13:16:56+0000","link","https://www.packtpub.com/register","472656846222343_720171818137510",NA,21,2,5
"1087294494749138","Vũ Đào Anh Tuấn","cho mình hỏi câu này với: mình có 1 dataframe gồm mssv và điểm, yêu cầu tính điểm trung bình của các sinh viên thì mình tính được rồi, bây giờ đề hỏi đo mức độ phân tán của điểm quanh điểm trung bình thì làm thế nào?","2016-12-28T16:10:36+0000","status",NA,"472656846222343_720245808130111",NA,1,2,0
"1851955978351716","Nhung Nguyen","[Dữ liệu lớn] Anh chị em cho em hỏi chút về đọc dữ liệu dạng .sav của SPSS. Em muốn đọc bộ data của Pisa nhưng bộ này khủng quá: hơn 510,000 observations với 922 variables. Tất nhiên em chỉ dùng một phần của bộ này, nhưng trước khi cắt nhỏ nó ra thì phải nhét được nó vào R đã. 
Đầu tiên em dùng fread đọc file .sav, nhưng bị lỗi 'Embedded nul in string' error.
Sau đó em nghĩ nên chuyển file sang dạng .txt bằng lệnh write.table. Lần này thì đọc được file. Nhưng có một vấn đề là tên biến bị mất hết và giờ chỉ còn số thứ tự cột. Không biết anh chị em có giải pháp cho vấn đề này không ạ? Cảm ơn đã dành thời gian.

library(foreign)
pisa <- read.spss(filelink, to.data.frame=TRUE)
write.table(pisa, ""pisatext.txt"")
library(data.table)
dat<- fread(""pisatextfile.txt"")
> names(dat)
[1] ""V1""   ""V2""   ""V3""   ""V4""   ""V5""   ""V6""   ""V7""   ""V8""   ""V9""   ""V10""","2016-12-21T22:19:53+0000","status",NA,"472656846222343_716857925135566",NA,8,4,0
"10210845468545723","Vịt Trần","Cứu bồ mấy bạn ơi, mình vừa mới cài R open của microsoft. Sau khi cài xong, một phần lớn package không chạy được nữa, bị crash khi load. Mlr không chạy, xts cũg không. Mình đã cài lại cả R và Rstudio, nhưng vẫn không được. Có ai biết tại sao không?","2016-12-28T00:59:24+0000","status",NA,"472656846222343_719956138159078",NA,1,4,0
"631130503744147","Nhok Conan","Chào mọi người mình có một số thắc mắc rất mong được các bạn giúp . Mình sử dụng logistic regression để phân lớp . Trong R mình dùng hàm confusionMatrix trong package Caret để đánh giá độ chính xác của mô hình. Hình dưới đây có những chỗ mình đã highlight vì không biết nó được tính như thế nào và có ý nghĩa gì. 
Mong các bạn giúp đỡ :","2016-12-27T19:16:01+0000","photo","https://www.facebook.com/photo.php?fbid=600405823483282&set=gm.719824908172201&type=3","472656846222343_719824908172201",NA,5,6,0
"1825514541042918","Xuân Huy","m.n cho em hỏi làm sao ""Xác định danh sách MSSV có ít nhất một bài có số điểm thấp nhất (0đ)"" (MSSV là  uid). Giúp em với ạ. Em cảm ơn.","2016-12-27T15:08:39+0000","photo","https://www.facebook.com/photo.php?fbid=1794923394102033&set=gm.719719874849371&type=3","472656846222343_719719874849371",NA,1,2,0
"698367330368784","Trung Nhân Uchiha","xin chào các anh chi !
 cho em hỏi là lệnh subset có thể tạo ra data với nhiều điều kiện hk ạ, example: tạo ra data chứa thông tin của các sinh viên có id là x,y,z,...","2016-12-25T10:54:52+0000","status",NA,"472656846222343_718616451626380",NA,2,2,0
"1310556829011267","Trần Trọng Khải","[xu hướng thay đổi của kết quả khảo sát online khi tăng dần số lượng]

Thưa quý thầy, cô, anh, chị,

Em có lặp lại một phần khảo sát của Mark Granovetter (1974) về vai trò của mối quan hệ (MQH) trong vấn đế tìm việc.

Khảo sát ẩn danh gồm 6 câu:
Câu 1. Nhập năm sinh
Câu 2. Giới tính
Câu 3. Nhập tuổi khi tìm được việc làm đầu tiên
Câu 4. Với việc làm đầu tiên đó, quý vị làm cho tổ chức: nhà nước, tư nhân hay phi chính phủ.
Câu 5. Quý vị biết tin tuyển dụng đó thông qua MQH riêng hay Tự tìm/Kênh khác
Câu 6. Nếu thông qua MQH thì MQH lúc đó ở mức độ: hiếm khi, thỉnh thoảng hay thường xuyên.

Khảo sát của em nhằm tạo cơ sở dữ liệu cho việc tìm lời đáp các câu hỏi sau:
- tỷ lệ tìm được việc làm đầu tiên nhờ mối quan hệ là bao nhiêu?
- giới tính nào tìm được việc làm đầu tiên thông qua mối quan hệ cao hơn?
- độ tuổi trung bình tìm được việc làm đầu tiên trong khảo sát là bao nhiêu?
- độ tuổi trung bình của từng giới khi tìm được việc đầu tiên là bao nhiêu?
- độ tuổi tìm được việc làm đầu tiên trong các tổ chức (tư nhân, nhà nước và phi chính phủ) có đặc trưng gì?
- giữa thời kì internet chưa phổ biến và thời kì internet phổ biến thì ảnh hưởng của mối quan hệ khác nhau thế nào?
- mối quan hệ ở mức độ nào có ảnh hưởng trội hơn trong vấn đề tìm việc ứng với mỗi loại hình tổ chức?

Em chưa biết cách ước lượng cỡ mẫu cho khảo sát này nên em cố gắng khảo sát được càng nhiều người càng tốt.

Sau khi khảo sát được 100 người, em có thử phân tích cơ cấu lựa chọn (không nhờ MQH, nhờ MQH hiếm khi/thỉnh thoảng/thường xuyên) để ước lượng cỡ mẫu tối thiểu mà tại đó trở về sau kết quả của em có tính ổn định.

Em xem xét theo hai loại biểu đồ
- biểu đồ điểm để thấy xu hướng thay đổi so với trục hoành và do đó cho thấy thứ bậc so với xu hướng của các lựa chọn khác. Qua biểu đồ điểm, có thể thấy rằng xu hướng Nhờ MQH thỉnh thoảng và Nhờ MQH thường xuyên vẫn chưa xác lập được thứ hạng rõ ràng. Cũng có khả năng là tỷ lệ của hai lựa chọn này xấp xỉ nhau.
- biểu đồ miền để thấy tổng thể ứng với các n khác nhau.
Tổng hợp lại, có thể kết luận rằng: tại n=90 thì kết quả khảo sát của em đã đạt được tính ổn định.

Có một vấn đề được đặt thêm là: nếu như không phân tích theo thứ tự thời gian mà xáo trộn thứ tự thì kết quả có khác hay không? Em có thử xáo trộn một lần và cũng thấy rằng kết quả ổn định từ vị trí n=90 trở đi. Tuy nhiên, lúc này, xu hướng Nhờ MQH Thỉnh thoảng đã trội hơn xu hướng Nhờ MQH Thường xuyên.

Đến đây, em lại nhận thấy: kết quả khảo sát vẫn chưa ổn định.
Em giả định rằng: số lượng n mà em cần khảo sát là số lượng mà tại đó dù có xáo trộn bao nhiêu lần thì kết quả vẫn không thay đổi.

Em không biết ý tưởng như thế liệu có ổn không ạ. Em rất mong quý thầy, cô, anh, chị chỉ bảo thêm.

Nhân tiện, em rất mong mọi người tham gia khảo sát.
Khảo sát ẩn danh chỉ có 6 câu thôi ạ.
https://docs.google.com/forms/d/e/1FAIpQLScc7ccSzfSJmnOUefPNC0zf8TfVuEgapLqxgr5i-2dWcVXDig/viewform

Em xin cảm ơn sự quan tâm của mọi người ạ.","2016-12-26T08:29:57+0000","photo","https://www.facebook.com/photo.php?fbid=1254228777977406&set=gm.719054948249197&type=3","472656846222343_719054948249197",NA,2,1,0
"1814941822089228","Vũ Hoài Nam","Mình xin hỏi chút 
có cách nào để lưu script mà sau khi mở lại mấy chỗ để dấu tiếng việt không bị lỗi không nhỉ ( như trong ảnh mấy chỗ để dấu của mình bị thành những dấu ""???"") 
tks :)","2016-12-25T16:53:52+0000","photo","https://www.facebook.com/photo.php?fbid=1782662181983859&set=gm.718772674944091&type=3","472656846222343_718772674944091",NA,2,1,0
"1125448724231403","Hai Nguyen","Xin chào anh chị và các bạn,
Tôi đang học stata, về phần hồi quy tuyến tính "" phần Đưa ra mô hình tiên lượng (dư báo) "" một phần rất quan trọng. Vì thời gian không cho phép nên Thầy cô chỉ giới thiệu sơ qua, nhưng thực tế áp dụng rất nhiều, Tôi đã tìm tài liệu thì hầu hết chỉ hướng dẫn trên R, mà trường mình lại dạy stata.
Anh chị và các bạn có kinh nghiệm chỉ mình với. Xin chân thành cám ơn rất nhiều. chúc mọi người giáng sinh an lành.
Gmail : Haiyds@gmail.com","2016-12-25T03:45:50+0000","status",NA,"472656846222343_718466998307992",NA,11,5,0
"1530258666992232","Namlun Didong","christmastree=function(message=NULL){
  
mess=message

plot(1:10,1:10,xlim=c(-5,5),ylim=c(0,10),type=""n"",xlab="""",ylab="""",xaxt=""n"",yaxt=""n"")

rect(-1,0,1,2,col=""tan3"",border=""chocolate4"",lwd=3)
polygon(c(-5,0,5),c(2,4,2),col=""green3"",border=""green4"",lwd=3)
polygon(c(-4,0,4),c(3.5,5.5,3.5),col=""green2"",border=""green3"",lwd=3)
polygon(c(-3,0,3),c(5,6.5,5),col=""green3"",border=""green4"",lwd=3)
polygon(c(-2,0,2),c(6.25,7.5,6.25),col=""green2"",border=""green3"",lwd=3)

for(i in 1:3){
points(x=runif(4,-5,5),y=rep(2,4),col=sample(c(""gold"",""red""),size=4,replace=T),cex=3,pch=19)
points(x=runif(4,-4,4),y=rep(3.5,4),col=sample(c(""gold"",""red""),size=4,replace=T),cex=3,pch=19)
points(x=runif(4,-3,3),y=rep(5,4),col=sample(c(""gold"",""red""),size=4,replace=T),cex=3,pch=19)
points(x=runif(4,-2,2),y=rep(6.25,4),col=sample(c(""gold"",""red""),size=4,replace=T),cex=3,pch=19)
points(0,7.5,pch=8,cex=5,col=""gold"",lwd=3)
}

xPres = runif(10,-4.5,4.5)
xWidth = runif(10,0.1,0.5)
xHeight=runif(10,0,1)
for(i in 1:10){
  rect(xPres[i]-xWidth[i],0,xPres[i]+xWidth[i],xHeight[i],col=sample(c(""blue"",""red""),size=1))
  rect(xPres[i]-0.2*xWidth[i],0,xPres[i]+0.2*xWidth[i],xHeight[i],col=sample(c(""gold"",""grey87""),size=1))
}

text(x=0,y=9,labels=mess,vfont=c(""serif"",""plain""),cex=2,col=""red"")

}

christmastree(""Best wishes to R group"")","2016-12-24T11:50:45+0000","status",NA,"472656846222343_718118975009461",NA,31,4,0
"10206950570583227","An Tom","Hi all,
Mình để ý thời gian gần đây, group mình ngày càng có nhiều câu hỏi về cách áp dụng R để xử lý dữ liệu trong các trường hợp cụ thể. Để mọi người có thể hiểu và giải đáp câu hỏi nhanh và chính xác, các bạn trước khi hỏi nên tuân theo một số hướng dẫn đã được phổ biến trong giới lập trình nói chung, và cộng đồng R nói riêng. 

Mình có đưa một số links để các bạn tham khảo:
1. How to ask? http://stackoverflow.com/help/how-to-ask
2. How to ask questions the smart way? http://www.catb.org/~esr/faqs/smart-questions.html
3. How to make a great R reproducible example? http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Về cơ bản, câu hỏi hoặc ví dụ của bạn nên bao gồm 3 thứ:

- Một bộ dữ liệu tối thiểu để chạy code. Các bạn đang làm cho doanh nghiệp, hoặc viện nghiên cứu, cơ quan của chính phủ nên cân nhắc việc đưa dữ liệu lên group có vị phạm quy định của tổ chức mình không. Thông thường, chỉ cần lấy ngẫu nhiên 1 phần nhỏ của bộ dữ liệu mà bạn đang làm và loại bỏ các cột xác định thông tin riêng của cá nhân/tổ chức,... Cách khác, bạn có thể giả lập 1 bộ dữ liệu có cấu trúc tương tự (help(dput))

- Đoạn script dùng để chạy bộ dữ liệu. Vì đây là page của Facebook - không phải một website có hỗ trợ syntax highlighting/indent - rất khó theo dõi, nên mình khuyến nghị bạn trong trường hợp code dài và phức tạp nên viết hẳn 1 file R script và đưa lên hoặc sử dụng Rpubs hoặc github. Trường hợp code ngắn có thể viết gọn và post trực tiếp trên facebook.

- Thông tin về phiên bản của R, của packages, của hệ thống mà bạn đang sử dụng (sessionInfo()). Thường thì, các thông tin này là không cần thiết vì R hỗ trợ chạy đa nền tảng tương đối ổn định, các packages (đặc biệt là default packages của R) đều hỗ trợ backward compatibility. Tuy nhiên, khi code gặp lỗi, bạn cũng nên lưu ý đọc releases của packages để xem có thay đổi gì không. Ví dụ, mình đã mất khá nhiều thời gian để detect lỗi khi update dplyr lên bản 0.5, hàm distinct() thay đổi cách dùng (https://github.com/hadley/dplyr/releases)

Có thể thấy, không cần chụp màn hình, bạn vẫn còn nhiều cách để đặt câu hỏi. Còn nhiều good practices khác mà mình không nêu ra hết, các bạn có thể tham khảo các links trên. Chúc bạn sớm trở thành người sử dụng R chuyên nghiệp.

Thanks.","2016-12-24T02:04:59+0000","link","http://stackoverflow.com/help/how-to-ask","472656846222343_717951995026159",NA,32,2,3
"1199264930194467","Hoang Nguyen","Mình xin phép đăng tin: Hiện mình đang có một nhóm tư vấn làm về môi trường và lâm nghiệp; hiện tại nhóm cần hợp tác với một bạn tốt nghiệp ít nhất đại học chuyên về toán thống kê sử dụng thành thạo các công cụ như SPSS hay R. Nhóm sẽ thực hiện điều tra xã hội học và để thực hiện nó phải viết đề cương nghiên cứu và phát triển bộ câu hỏi điều tra. Nếu bạn nào quan tâm và có những phẩm chất trên thì vui lòng cho mình biết qua tin nhắn.","2016-12-22T08:03:28+0000","status",NA,"472656846222343_717086661779359",NA,12,7,1
"1298955620186423","Phat Chau","Em xin chào tất cả các anh/chị
Em mới bắt đầu học R và muốn ứng dụng R trong việc phân tích dữ liệu 
Anh /chị có thể tư vấn giúp em, đầu tiên em nên đọc những cuốn sách nào để đạt được mục tiêu là ứng dụng trong lĩnh vực phân tích dữ liệu
Em xin cảm ơn","2016-12-22T09:37:48+0000","status",NA,"472656846222343_717114545109904",NA,3,5,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn, 

Mình có một data frame có tên ngaythang lưu ở file có tên ngaythang.rda trong đó có biến NgayDen (định dạng POSIXc). Thách thức  như sau: mình muốn tạo một biến mới có tên là ThoiDiem và gán nó vào data frame sẵn có trong đó: (1) các quan sát nằm trong tháng 10 của biến NgayDen sẽ được gán nhãn là Thang10, các quan sát nằm trong tháng 11 của biến NgayDen sẽ được dán nhãn Thang11 và số còn lại là được gán nhãn Thang12. 

Ngóng chờ câu trả lời của các bạn. Cảm ơn các bạn nhiều. 

Data lấy ở đây: http://www.mediafire.com/file/p5bzx20c6hxjgl0/ngaythang.rda","2016-12-22T08:19:30+0000","status",NA,"472656846222343_717092715112087",NA,6,3,0
"10206049751402436","Dương Lê Hoàng","Hôm nay ngồi nghịch ggplot2 thì tìm được đoạn code này nên post lên để các bác thử cho vui:

library(raster)
library(ggplot2)
vietnam  <- getData(""GADM"",country=""Vietnam"",level=2)
china    <- getData(""GADM"",country=""China"",level=0)
laos     <- getData(""GADM"",country=""Laos"",level=0)
cambodia <- getData(""GADM"",country=""Cambodia"",level=0)
thailand <- getData(""GADM"",country=""Thailand"",level=0)

ggplot(vietnam,aes(x=long,y=lat,group=group))+
    geom_polygon(aes(fill=id),color=""grey30"")+
    geom_polygon(data=china,fill=""grey60"",color=""grey80"")+
    geom_polygon(data=laos,fill=""grey60"",color=""grey80"")+
    geom_polygon(data=cambodia,fill=""grey60"",color=""grey80"")+
    geom_polygon(data=thailand,fill=""grey60"",color=""grey80"")+
    coord_map(xlim=c(-1,1)+bbox(vietnam)[""x"",],ylim=c(-1,1)+bbox(vietnam)[""y"",])+
    scale_fill_discrete(guide=""none"")+
    theme_bw()+theme(panel.grid=element_blank())","2016-12-21T10:02:02+0000","status",NA,"472656846222343_716605151827510",NA,10,5,2
"10210265532367664","Khánh Nguyễn","Chào các anh chị trong nhóm, em là sinh viên năm 1 của chương trình Kinh tế nông nghiệp tại trường Kasetsart tại Thái Lan.Nay em xin các anh chị tư vấn cho các đầu sách tiếng Anh về Thông Kê. Do trình độ về Math và Econometrics chưa cao nên mong các anh chị giới thiệu những cuốn sách tác giả uy tín, dễ đọc và dễ hiểu. Ví dụ như về Econometrics book, em rất thích phong cách của tác giả Gujarati vì rất diễn giải rất dễ hiểu ,dễ đọc cho người có trình độ cơ bản như em. Em xin cám ơn mọi người ạ ! Xin admin đã duyệt bài ạ !","2016-12-22T01:37:27+0000","status",NA,"472656846222343_716922101795815",NA,7,7,2
"1356519944399387","Lê Khắc Linh","Các anh chị cho em hỏi:
Em cần một bản đồ thế giới, trong đó minh họa số case mắc bệnh cho từng nước và hoặc vùng địa lý (vùng theo phân loại của WHO). Ví dụ data của em
USA: 5 
Canada: 10
Brazil : 15
UK: 20
Vietnam: 30
Uganda 40...

Vậy trong R em dùng package nào vậy ạ?","2016-12-21T15:10:16+0000","status",NA,"472656846222343_716717091816316",NA,2,3,0
"10210845468545723","Vịt Trần","TIết kiệm thời gian chạy Random Forest. Năm anh em siêu nhân vẫn là mạnh chán :)","2016-12-22T00:27:02+0000","link","http://rpubs.com/tkvit/236948","472656846222343_716894331798592",NA,6,0,0
"10208725271269151","Dung Nguyen Chi","Chơi với thống kê ngày  cuối tuần. 

1. Tại sao Việt Nam nghèo mà giỏi? 
2. Tại sao nữ càng lớn (đồng nghĩa với càng xinh) thì học càng kém? 

Mời các bạn tham khảo kết quả và đưa ra câu trả lời: 

","2016-12-18T09:08:06+0000","link","http://rpubs.com/chidungkt/236088","472656846222343_715107965310562",NA,42,10,3
"180533879103599","Tran Duy","Mọi người có thể cho em nhận xét về kết quả của mô hình như hình dưới được không ạ?. Trong bài này em dùng mixed binary logit model, tuy nhiên các hệ số cho ra kết quả quá lớn. Em nghĩ là có vấn đề gì đó trong dữ liệu. Các anh chị cho em nhận xét với ạ!","2016-12-18T14:50:05+0000","photo","https://www.facebook.com/photo.php?fbid=131634940660160&set=gm.715261498628542&type=3","472656846222343_715261498628542",NA,4,0,0
"1530258666992232","Namlun Didong","Đây là bài đầu tiên trong series Bayes, mình sẽ trình bày lại chi tiết, đầy đủ mọi công đoạn phân tích BAYES bằng package brms.

Chủ đề của bài này là dùng Bayes thay thế cho ANOVA. Bạn sẽ thấy sức mạnh và tính linh hoạt của phương pháp này.

https://drive.google.com/file/d/0B1vaOU1uB8DPZ19xMGNmOWpJNVk/view","2016-05-13T12:22:53+0000","photo","https://www.facebook.com/photo.php?fbid=1196466077038161&set=gm.604299379724755&type=3","472656846222343_604299379724755",NA,119,14,14
"1530258666992232","Namlun Didong","Bài thứ 8 trong serie mlr, cách tạo ra một mô hình tập hợp khá mạnh để xử lý tự động toàn bộ dữ liệu thiếu sót trong dataset của mình. Ưu thế của phương pháp tập hợp mô hình đó là: tinh tế và chính xác hơn nhiều phương pháp hệ thống, máy móc khác. Mỗi biến số được xử lý bằng algorithm hồi quy hoặc phân loại tối ưu nhất có thể, kết hợp đồng thời huấn luyện và imputation trong cùng 1 gói mô hình, xử lý toàn bộ dataset cùng lúc, mềm dẻo và linh hoạt vì cho phép áp dụng bất kì algorithm nào làm chỉ huy... 

https://drive.google.com/open?id=0B1vaOU1uB8DPMkhRbGw5RlhXU2s","2016-12-16T20:16:24+0000","photo","https://www.facebook.com/photo.php?fbid=1420264471324986&set=gm.714333145388044&type=3","472656846222343_714333145388044",NA,17,0,4
"1902396496656572","Huynh Kim An","Mong anh chị giúp:
Mình có 2 cột: cột ngày tháng năm và cột giờ phút; muốn nhập thành 1 cột (ngày tháng năm giờ phút) ?
Ví dụ: [25/8/2016] và [10:30]
Thành 1 cột [25/8/2016 10:30]
Anh chị chỉ giúp, cảm ơn","2016-12-16T12:55:51+0000","status",NA,"472656846222343_714132738741418",NA,1,1,0
"1412242695487170","Linh Pham","Hi cả nhà,
Mình có một matrix (2x3): A=[  3 9 8
                                               15 2 5]
Mình muốn tìm theo dòng các giá trị lớn hơn 7 và thông báo index về column của giá trị đấy. Cụ thể mình muốn output là một matrix:
B=[2 3
     1 NA]
vì: dòng 1: giá trị 9 và 8 > 7 ở các cột tương ứng là 2 và 3
     dòng 2: giá trị 15 > 7 ở cột 1
Mong được các anh/chị/bạn giúp đỡ ạ.","2016-12-15T07:11:23+0000","status",NA,"472656846222343_713440005477358",NA,3,3,0
"10210845468545723","Vịt Trần","Machine Learning và Statistics là một hay là hai? Hãy cho mình biết ý kiến cá nhân của bạn. Xin đừng copy hay dẫn link vì mình thực sự muốn nghe quan điểm cá nhân của bạn. Cám ơn các bạn.","2016-12-12T01:22:00+0000","status",NA,"472656846222343_711488172339208",NA,13,13,0
"1096212410525094","Hoa Hong Trang Nguyen","mọi người cho em hỏi, từ K=power e thiếu function chỗ nào. báo lỗi như v là sao ạ. cam ơn đã đọc","2016-12-13T02:34:34+0000","photo","https://www.facebook.com/photo.php?fbid=1038323699647299&set=gm.712103955610963&type=3","472656846222343_712103955610963",NA,2,0,0
"1849942691933972","Nguyen","Em có case này mong mọi người chỉ giáo ạ.
Em có data dạng panel, với model đơn giản là:

y = a0 + a1*x1 + a2*x2 + a3*x3 + ...+ a15*x15

Em dùng pooled OLS để chạy nhưng có thêm vài restrictions cho các hệ số hồi quy, ví dụ:

a1 + a2 + a3= 1
a4 + a5 + a6 = 0
a7 + a8 + a9 = 0

Trong R thì mình code ra sao để ra kết quả vậy ạ?

Xin cảm ơn anh chị rất nhiều.","2016-12-09T01:44:52+0000","status",NA,"472656846222343_709294865891872",NA,1,4,0
"1608715779142507","Long Ngo","Mọi người ơi, cho em hỏi xíu. 

Nếu bây giờ em muốn build một mô hình classification bằng random forest với từng cây là C5.0 tree thì em nên làm thế nào, dùng package gì ạ?","2016-12-12T11:18:33+0000","status",NA,"472656846222343_711723872315638",NA,1,1,0
"1530258666992232","Namlun Didong","2 hàm đồ thị Missing Value, áp dụng trực tiếp cho dataframe luôn nhé.

# Histogram : tỉ lệ % missing value cho từng biến
ggplot_histo_missing <- function(x){
  library(dplyr)
  library(reshape2)
  library(ggplot2)
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2)) +
    geom_bar(aes(y = 100*(..count..)/sum(..count..),fill=value),alpha=0.7)+scale_fill_manual(values=c(""skyblue"",""red""),name = """",
                    labels = c(""Available"",""Missing""))+
    theme_minimal()+ 
    theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
    labs(x = ""Variables in Dataset"",
         y = ""Percent of observations"")+coord_flip()
}

# Matrix : định vị missing value trong dataframe
ggplot_mice_missing <- function(x){
  library(dplyr)
  library(reshape2)
  library(ggplot2)
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2,
               y = Var1)) +
    geom_tile(aes(fill = value),alpha=0.6) +
    scale_fill_manual(values=c(""skyblue"",""red""),name = """",
                      labels = c(""Available"",""Missing"")) +
    theme_minimal()+ 
    theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
    labs(x = ""Variables in Dataset"",
         y = ""Total observations"")+coord_flip()
}","2016-12-12T10:47:26+0000","photo","https://www.facebook.com/photo.php?fbid=1412850922066341&set=gm.711712785650080&type=3","472656846222343_711712785650080",NA,6,1,0
"1312924752138295","Rainie Kenta","Mọi người ơi cho em hỏi một chút về hàm regsubsets() trong package leaps của R với ạ. 

Chẳng hạn em có 1 biến y và 10 covariates x. Nếu em dùng hàm này để cho ra model có 3 biến x tốt nhất trong số các mô hình có 3 biến x, thì nó sẽ dùng criterion nào để quyết định ạ? Em nghĩ là adjusted-R2 nhưng em không chắc chắn lắm. 

Em cảm ơn mọi người ạ","2016-12-11T12:06:44+0000","status",NA,"472656846222343_711113615709997",NA,2,8,0
"10208725271269151","Dung Nguyen Chi","Toán tử hút thuốc %>% (the pipe operator): 

","2016-12-11T06:45:21+0000","link","http://rpubs.com/chidungkt/234438","472656846222343_710969409057751",NA,17,1,0
"1096212410525094","Hoa Hong Trang Nguyen","Có anh chị nao biết về code markov trong R không ạ. Em đang cần tai liệu vè markov trong R de lam de tai luận văn dự báo giá cổ phiếu. Do tai lieu e dang doc có code nhưng khi chạy báo lỗi và ko ra kết quả được ạ","2016-12-11T05:08:47+0000","status",NA,"472656846222343_710928455728513",NA,1,0,0
"10210975771002768","Luong Duc Anh","Em đang làm xây dựng một mô hình hồi quy đa biến, nhưng khi làm diagnostic mô hình thì kết quả cho ra như hình dưới đây. Có vẻ residuals không theo phân bố chuẩn. Các assumptions khác được test theo gvlma() cũng không đạt. Vậy trong trường hợp này có cách nào/phương pháp nào để xử lý không ạ. Cảm ơn các anh/chị nhiều!","2016-12-11T00:10:59+0000","photo","https://www.facebook.com/photo.php?fbid=10210244233714793&set=gm.710796469075045&type=3","472656846222343_710796469075045",NA,10,5,1
"1530258666992232","Namlun Didong","Series Machine learning in Medicine tiếp tục với case study số 5: Mô hình Cox-Ph trong survival analysis. 
(Các cao thủ khác trong dự án đã bặt vô âm tín nên chỉ còn 1 mình Ronin nấm lùn soạn bài). 

Trong thí dụ này, mình nâng cấp Case study về survival analysis với CoxPh model trong tài liệu gốc thành 1 thí nghiệm thăm dò về Survival analysis trong package mlr, bao gồm:

1) Thăm dò dữ liệu bằng Feature selection
2) Benchmark study so sánh 7 algorithms survival khác nhau
3) Huấn luyện mô hình Cox-ph Boosting 
4) Diễn giải trực quan mô hình này.","2016-12-09T21:30:06+0000","status",NA,"472656846222343_709923762495649",NA,25,2,5
"1205787479527610","Diệp Phong","Chào mọi người, trong đây chắc không ít bạn sử dụng Rstudio. Mình muốn hỏi các bạn/anh/chị/chú/bác một chi tiết hơi nhỏ:

Có ai biết làm thế nào để đổi con trỏ của Rstudio từ gạch đứng ""|"" sang gạch dưới ""_"" không?
Hay nói cách khác là từ I-Beam sang Underscore T_T
Mình quen nhìn Underscore hơn, dùng terminal thì đổi ok, nhưng trong Rstudio mình chưa biết . . .","2016-12-10T03:32:00+0000","status",NA,"472656846222343_710107695810589",NA,0,1,0
"10208725271269151","Dung Nguyen Chi","Xuất các kết quả phân tích ra dạng bảng HTML: 

http://rpubs.com/chidungkt/233830

Cảm ơn An Tom nhé.","2016-12-08T15:28:59+0000","link","http://rpubs.com/chidungkt/233830","472656846222343_709021975919161",NA,14,1,0
"10210845468545723","Vịt Trần","[#Rvui2] Mặc dù post đầu tiên không nhiều bạn tham gia lắm, nhưng có 2 bạn tham gia là quá vui rồi.

Làm thêm cái nữa cho vui nhé mấy bạn.

Data frame df gồm 26 biến và 39 hàng. Bài toán đặt ra, tạo df1 chỉ chứa những biến có số % Na missing value < 40%

Mình viết khoảng 3 dòng code. Sẽ đưa ra cách giải quyết của mình sau. Cám ơn các bạn

df <- read.csv(""https://raw.githubusercontent.com/tkvit/Data_No_Project/master/dplyr2.csv"")","2016-12-06T00:58:10+0000","link","https://raw.githubusercontent.com/tkvit/Data_No_Project/master/dplyr2.csv","472656846222343_707406879414004",NA,14,6,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn. Cho mình hỏi là tại sao câu lệnh logit1 thì vận hành nhưng logit2 (như trong hình) thì R lại báo lỗi là: 

Error in vector(type, length) : 
  vector: cannot make a vector of mode 'NULL'.

Cảm ơn các bạn nhiều lắm.","2016-11-20T17:00:05+0000","photo","https://www.facebook.com/photo.php?fbid=10207875205538039&set=gm.697927650361927&type=3","472656846222343_697927650361927",NA,8,8,0
"10210845468545723","Vịt Trần","[Vui] Mình có một bài toán nhỏ này về data manipulation cho các bạn, nhỏ thôi nhưng mà hồi đó gặp phải mình cũng mất một ít thời gian để làm được.

Data gồm có 3 cột: Variable, Value và Label

Variable gồm:
1) cá biến đuôi ""_12"",""_13"" và ""_14"" chứa giá trị trong Value
2) Var_xx , xy_Var, chứa NA trong Value

Label: cột để trống.

Mục đích mình muốn làm như sau:
1) Tất cả các dòng có biến đuôi ""_12"" sẽ mang Label ""mot_hai"", ""_13"", Label ""mot_ba"", ""_14"", mang Label ""mot_bon""
2) Lọại tất cả các dòng có Value = NA
3) Bỏ phần đuôi ""_12"", ""_13"" và ""_14"" trong cột Variable.

Data các bạn có thể load từ đây
df <- read.csv(""https://raw.githubusercontent.com/tkvit/Data_No_Project/master/dplyr_test1.csv"")

Mọi hướng giải quyết đều rất cám ơn, nếu làm bằng dplyr càng ngắn gọn càng tốt.

Tầm cuối ngày chủ nhật mình sẽ đưa hướng giải quyết của mình.
Cám ơn các bạn đã đọc.","2016-12-03T14:11:39+0000","link","https://raw.githubusercontent.com/tkvit/Data_No_Project/master/dplyr_test1.csv","472656846222343_705976362890389",NA,7,3,0
"380518235638520","Linh Phan","Anh chị cho em hỏi gấp ạ, khi em có predictor là ordinal data (likert scale), dependent variable là numeric discrete data (số người)   thì nên dùng cách nào để tính mối quan hệ giữa 2 variable này ạ? Linear regression là không được đúng ko ạ?","2016-12-05T11:00:30+0000","status",NA,"472656846222343_707027246118634",NA,4,1,0
"1530258666992232","Namlun Didong",NA,"2016-12-02T18:14:14+0000","photo","https://www.facebook.com/photo.php?fbid=1397745146910252&set=oa.705296706291688&type=3","472656846222343_705296709625021",NA,32,0,3
"10210975771002768","Luong Duc Anh","Mình đang làm một mô hình hồi quy tuyến tính (linear regression). Có anh/chị nào có tài liệu, hoặc kinh nghiệm gì về đánh giá model quality/performance cho linear regression thì share cho mình với. Cảm ơn các anh/chị.","2016-12-01T22:30:09+0000","status",NA,"472656846222343_704642036357155",NA,2,1,0
"1205401282846677","Duy Tran","Em chào các anh chị, cho em hỏi nhóm mình có ai có sô liệu thống kê theo tháng (hoặc năm) của thị trường chứng khoán Việt Nam không ạ?. Em đang muốn phân tích mối tương quan giữa Stock market index với một vài biến Macroeconomic. Đây chỉ là bài tập cuối kì trong môn ""phân tích thống kê"" em đang học, nên có anh chị nào có thì cho em xin với ạ.
Em xin cảm ơn!","2016-11-29T07:19:02+0000","status",NA,"472656846222343_702746163213409",NA,3,2,0
"1419118098140780","Nguyễn Thị Mai Liên","Mọi người cho mình hỏi là mình muốn tìm mối tương quan giữa biến nhiệt độ và thông số oxy hòa tan trong nước theo thời gian thì có thể dùng hàm gì được ạ?
Cảm ơn mọi người rất nhiều, xin giúp đỡ","2016-11-29T02:35:27+0000","status",NA,"472656846222343_702649889889703",NA,2,8,1
"1530258666992232","Namlun Didong","Trước 1 bộ số liệu với nhiều biến số, 5 câu hỏi có thể đặt ra:

1) Những biến số nào thực sự có quan hệ ý nghĩa với kết quả Y ? Làm cách nào để phân lập chúng ?

2) Ta nên đưa tất cả biến số vào mô hình hay chỉ chọn lọc một vài biến số ? Việc lựa chọn này sẽ gây ra tác động như thế nào đối với hiệu năng của 1 algorithm nhất định ? 

3) Trong những mẫu được lựa chọn ngẫu nhiên từ quần thể khảo sát, liệu câu trả lời cho 2 câu hỏi 1 và 2 có còn chính xác ? 

4) Giả sử bạn đã có trong tay 1 mô hình dự báo tối ưu, nhưng nó là một mô hình blackbox, bạn phải diễn giải thế nào về vai trò đóng góp của những biến số độc lập trong mô hình ?

5) Tôi phải làm gì để tạo ra một mô hình thực sự thông minh, có thể tự chọn lọc biến số để tối ưu hóa khả năng dự báo của chính nó ?

Bài thực hành số 6 Feature selection (Chọn lọc thông tin) sẽ giúp bạn trả lời cho cả 5 câu hỏi nêu trên. Đây là bài hay nhất và khó nhất trong series này

","2016-11-29T17:02:31+0000","link","https://drive.google.com/open?id=0B1vaOU1uB8DPZENBeGpxRWdrblU","472656846222343_703037223184303",NA,44,3,11
"1530258666992232","Namlun Didong","Các bạn đều biết về algorithm Random Forest, đúng như câu ca dao ""1 cây làm chẳng nên non, 3 cây chụm lại nên hòn núi cao"", Random Forest hoạt động hiệu quả nhờ cơ chế Bootstrap Aggregating.

Ta có thể áp dụng Bootstrap Aggregating cho bất cứ algorithm nào mình muốn không ? mlr cho phép bạn làm điều này rất dễ dàng. Chúng ta cùng Bs. Nhi khám phá tính năng này nhé.

https://drive.google.com/open?id=0B1vaOU1uB8DPeDBVMm9WME1BLUU","2016-11-25T15:25:27+0000","photo","https://www.facebook.com/photo.php?fbid=1387212121296888&set=gm.700688690085823&type=3","472656846222343_700688690085823",NA,28,1,2
"1640747595938853","Binh Thang","Các a/c cho em hỏi kinh nghiệm chạy non-linear regression với ạ
Em muốn xem là khuynh hướng của hàm lượng sodium trong giai đoạn này có thay đổi gì không ah? tăng hoặc giảm có ý nghĩa thống kê hay không (p-for trend). Trước đó có sử dụng linear regression analyses nhưng mà giáo không chịu (do transformation trong trường hợp này không tốt) và gợi ý sử dụng non-linear regression. 
Biến outcome của em là (n_na) và độc lập là year, adjusted var là age.

Nếu bác nào có kinh nghiệm xin chia sẻ cách làm với ah. Cám ơn mọi người nhiều ah

dataset: https://drive.google.com/file/d/0Bz4nSwuF86KAYTZDSFNTdVgxVXc/view?usp=sharing","2016-11-26T07:55:20+0000","photo","https://www.facebook.com/photo.php?fbid=1524484880898459&set=gm.701059980048694&type=3","472656846222343_701059980048694",NA,4,6,1
"10154630775082982","Duy Thọ Nguyễn","Khi số dòng mã và thư viện được sử dụng tăng lên, việc nạp (qua lệnh library, hoặc source) các package, module R là 1 vấn đề cần cân nhắc. Đây là 1 package mà mình thấy thú vị và cảm thấy hữu ích trong quá trình xây dựng data product.  
Tác giả của package này cũng chính là người đã viết package magittr (dplyr sử dụng lại phát kiến về toán tử pipe %>% của package magittr). 

","2016-11-26T04:33:30+0000","link","https://github.com/smbache/import","472656846222343_700980570056635",NA,17,0,1
"640048829536068","Thi Duyen Nguyen","Xin chào, em đang học về Linear Regression model và nghe nói quyển sách Regression Model for Data Science in R rất hay nên muốn hỏi các anh chị có ai có link download codes + solution videos đi kèm với quyển sách có thể cho em không ạ? Em có sách định dạng pdf rồi. :)","2016-11-24T21:58:59+0000","status",NA,"472656846222343_700325470122145",NA,6,2,4
"1530258666992232","Namlun Didong","Đây là bài thực hành thứ 5 trong series mlR, mục tiêu của bài này là giải quyết bài toán phân loại nhiều nhãn giá trị cùng lúc. Trong bài chúng ta sẽ dự báo 6 loại cảm xúc khác nhau dưới tác động của âm nhạc. Hai hướng giải quyết được trình bày, 1) Dùng 2 algorithm chuyên dụng và 2) Chuyển bài toán đa giá trị thành bài toán dự báo liên hoàn nhiều biến nhị phân với 5 algorithms.

Do mình có việc đột xuất phải giải quyết nên chỉ mới kịp viết xong code, bài giảng xin nợ lại hôm khác.

https://drive.google.com/open?id=0B1vaOU1uB8DPdmgzaHVuV2FTTkU","2016-11-23T20:36:26+0000","photo","https://www.facebook.com/photo.php?fbid=1384733404878093&set=gm.699748803513145&type=3","472656846222343_699748803513145",NA,24,2,2
"10208725271269151","Dung Nguyen Chi","Muộn còn hơn không

Ngày 20/11 qua rồi nhưng mình cũng muốn nói lời cảm ơn đến các bạn - những người Thầy. 

R là thứ mình tự học (và chỉ học một mình) nên có những khó khăn mà mình không thể tự xử lý được, mình thường post lên đây. Theo truyền thống ""một chữ cũng là thầy, nửa chữ cũng là thầy"" mình trân trọng và biết ơn những người thầy ở Group này - những người cho mình hoặc là câu trả lời giải quyết trực tiếp câu hỏi, hoặc là cho mình gợi ý để xử lý câu hỏi. 

Các bạn thực sự là thầy của mình. 

Nhân đây, mình (xin được mạn phép dùng từ này) cảm ơn rất nhiều đến anh - kiêm thầy Namlun Didong, Tho Duy Thọ Nguyễn, Vịt Trần, Tran Quy Phi, Nguyen Le Xuan Bach , anh Le Thanh (không tag được) và nhiều bạn khác vì những đóng góp và những bài học miễn phí cung cấp trên G này. 

Cuối cùng, mình cũng muốn chuyển lời cảm ơn đến Bác Nguyễn Văn Tuấn - người VN đầu tiên chia sẻ tài liệu về R bằng tiếng Việt trên Blog của mình từ những năm 2004.","2016-11-22T11:44:26+0000","photo","https://www.facebook.com/photo.php?fbid=10207889452494204&set=gm.698885966932762&type=3","472656846222343_698885966932762",NA,89,8,0
"414572095545206","Nguyễn Hoàng","Mình là dân kinh tế. Lần trước tình cờ mình đọc được bài giới thiệu sách Kinh tế lượng ứng dụng với R của tác giả Nguyễn Chí Dũng thấy rất hay. Các anh chị em ai biết bài đó ở đâu chỉ mình với. Bản cập nhật càng tốt ạ. Nhân tiện bạn nào biết tài liệu nào liên quan ứng dụng đến Panel data trong R chỉ mình với. Tài liệu trên cũng có đề cập nhưng còn sơ khai. Cảm ơn mọi người.","2016-11-22T05:19:07+0000","status",NA,"472656846222343_698757173612308",NA,19,10,0
"1901239790111508","Bu Cháu","Chào các bạn. Các bạn có thể giúp mình tìm một statistical test phù hợp cho experiment này được không ạ?  
Mình có 4 independent variables (đều là categorical variables), gồm: vị trí sản phẩm trên giá hàng (hàng dọc, hàng ngang), số sản phẩm bày trên giá, và nhãn hiệu (brand)
1 dependent variable là nhãn hiệu được lựa chọn (brand choice) (khoảng 50 brands) 
Dạng experiment: mixed design of between and within subject.  
Với dạng experiment này thì mình có thể dùng dạng phân tích nào? 
Cảm ơn các bạn rất nhiều !","2016-11-21T14:12:41+0000","status",NA,"472656846222343_698389693649056",NA,3,5,0
"1640747595938853","Binh Thang","Thay đổi thứ tự của x scale.
Em đang vẻ biểu đồ này biểu diễn giá trị PM25 dao động trong 24h trong R, bây giờ muốn thay đổi thứ tự thời gian từ 7:00 trở đi. (chứ không phải 0:00h). Anh chị nào có thể giúp em với ah

ggplot(newdata1, aes(x=hour, y=pm25, fill=hour)) + geom_boxplot()+geom_smooth(method = ""lm"", formula = y ~ splines::bs(x, 25), se = FALSE)+geom_smooth(aes( group = 1 ))+theme_bw()+theme_bw()+theme(legend.position=""none"")","2016-11-22T04:20:39+0000","photo","https://www.facebook.com/photo.php?fbid=1520009981345949&set=gm.698733873614638&type=3","472656846222343_698733873614638",NA,14,2,2
"1258259990947824","Khánh Long Tốt Bụng","Xin chào group, trong group có bạn nào có bản pdf của quyển sách theo đường link sau: Introduction of satistical data analysis life science. thì cho mình xin bản pdf nhé
https://books.google.com.vn/books?id=UzLcBQAAQBAJ&pg=PA151&lpg=PA151&dq=2.71+value+in+statistical&source=bl&ots=J7elmuBSro&sig=vctKUp6MqKajDkFGlo7IOP23-p0&hl=vi&sa=X&ved=0ahUKEwiBsZCg9KzQAhWMnpQKHeCpDZgQ6AEIFzAA#v=onepage&q=2.71%20value%20in%20statistical&f=true
Tks all","2016-11-19T03:31:03+0000","link","https://books.google.com.vn/books?id=UzLcBQAAQBAJ&pg=PA151&lpg=PA151&dq=2.71+value+in+statistical&source=bl&ots=J7elmuBSro&sig=vctKUp6MqKajDkFGlo7IOP23-p0&hl=vi&sa=X&ved=0ahUKEwiBsZCg9KzQAhWMnpQKHeCpDZgQ6AEIFzAA#v=onepage&q=2.71%20value%20in%20statistical&f=true","472656846222343_697024033785622",NA,12,4,2
"1258259990947824","Khánh Long Tốt Bụng","mọi người cho mình, mọi người có biết về tri số xích ma trong thống kê, trị số giữa các kết quả thí nghiệm giữa các lần lặp lại để kết quả có ý nghĩa thống kê. tks all","2016-11-16T23:32:55+0000","status",NA,"472656846222343_695944520560240",NA,1,3,0
"10208725271269151","Dung Nguyen Chi","Sử dụng màu sắc cho Data Visualization:

http://rpubs.com/chidungkt/227932","2016-11-17T10:10:51+0000","photo","https://www.facebook.com/photo.php?fbid=10207850288555130&set=gm.696127710541921&type=3","472656846222343_696127710541921",NA,21,5,1
"1849942691933972","Nguyen","Dành cho các anh chị đang nghiên cứu về tài chính, kinh tế, ngân hàng... 

Các anh chị em đã quá quen thuộc với tình trạng website của Ngân hàng Nhà nước, Cục thống kê... thường xuyên không cung cấp đầy đủ thông tin cần thiết cho các nghiên cứu của mình. Với các trường lớn, có nhiều ngân sách dành cho database, BankScope hoặc Fitch là sự lựa chọn tốt nhất nhưng chi phí rất đắt đỏ. 

Đồng nghiệp của mình vừa giới thiệu một công ty ở Việt Nam cung cấp data chất lượng và đầy đủ- stoxplus. Anh ấy vừa đăng 2 bài trên tạp chí tốt:

Nguyen, T., Locke, S., & Reddy, K. (2015). Ownership concentration and corporate performance from a dynamic perspective: Does national governance quality matter?. International Review of Financial Analysis, 41, 148-161.

Nguyen, T., Locke, S., & Reddy, K. (2015). Does boardroom gender diversity matter? Evidence from a transitional economy. International Review of Economics & Finance, 37, 184-202.

Mình vừa dạo qua công ty này thì thấy bên công ty cũng đang tuyển người phân tích, rất đúng chuyên ngành của anh em trong forum. Mình mạn phép chia sẻ ở đây cho những anh em muốn thử sức với phân tích tài chính:

http://stoxplus.com/news/detail/311366?lang=vi-vn

Chúc anh chị em cuối tuần vui vẻ.","2016-11-18T11:54:00+0000","status",NA,"472656846222343_696647167156642",NA,34,2,8
"1530258666992232","Namlun Didong","Sau 2 ngày mày mò và liên tục thất bại khi tìm cách customize leaner trong caret và mlr cho linear mixed  model, mình đành phải quay về với giải pháp thủ công... 

Đây là nội dung giải pháp để làm K-folds cross-validation cho mô hình thuộc lớp nlmer (package lme4):

#  Loading data
data(""sleepstudy"",package=""lme4"")

# Structuring a new dataframe for KFCV
dataset=sleepstudy
k=10
folds=cvTools::cvFolds(nrow(dataset),K=k)
dataset$holdoutpred=rep(0,nrow(dataset))
  dataset$RMSE=rep(0,nrow(dataset))
  dataset$MAE=rep(0,nrow(dataset))
  dataset$R2=rep(0,nrow(dataset))
  dataset$AIC=rep(0,nrow(dataset))
  dataset$BIC=rep(0,nrow(dataset))
  
# Cross-validation
for(i in 1:k){
  train=dataset[folds$subsets[folds$which != i], ]
  validation=dataset[folds$subsets[folds$which == i], ]
  newlm=lmer(formula=Reaction ~ Days + (Days | Subject),data=train)
newpred=predict(newlm,newdata=validation)
true=validation$Reaction
error=(true-newpred)
rmse=sqrt(mean(error^2))
R2=1-(sum((true-newpred)^2)/sum((true-mean(true))^2))
mae=mean(abs(error))
dataset[folds$subsets[folds$which == i], ]$holdoutpred <- newpred
dataset[folds$subsets[folds$which == i], ]$RMSE=rmse
dataset[folds$subsets[folds$which == i], ]$MAE=mae
dataset[folds$subsets[folds$which == i], ]$R2=R2
dataset[folds$subsets[folds$which == i], ]$AIC=AIC(newlm)
dataset[folds$subsets[folds$which == i], ]$BIC=BIC(newlm)
}

# Explore the results
Hmisc::describe(dataset$RMSE)
Hmisc::describe(dataset$MAE)
Hmisc::describe(dataset$R2)
Hmisc::describe(dataset$AIC)
Hmisc::describe(dataset$BIC)

# END

Bằng cách này bạn chỉ cần thay đổi formula là có thể áp dụng cho mọi mô hình mixed model, kết quả được xuất ra ngay trong dataframe.","2016-11-18T13:07:09+0000","status",NA,"472656846222343_696678393820186",NA,8,0,0
"1530258666992232","Namlun Didong","Thân chào các bạn. Đây là bài thực hành thứ ba về mlR, một giao thức hiệu quả cho Machine learning trong R.Nếu các bạn thực hiện xong 2 bài trước, chắc hẳn các bạn đã quen thuộc với quy trình cơ bản để huấn luyện mô hình phân loại trong mlr và cơ chế hoạt động của mlR, thông qua những  đối tượng trung gian như Task, Learner, Resample, … 

Trong bài này, chúng ta sẽ luyện đến một đẳng cấp cao hơn trong mlr, đó là thực hiện thí nghiệm Benchmark. Mục tiêu của thí nghiệm này là nhằm so sánh hiệu năng giữa nhiều algorithms khi áp dụng chúng trên cùng 1 nhiệm vụ, hoặc tuần tự trên nhiều nhiệm vụ khác nhau. Đây là một trong những tính năng mà mlr chứng tỏ sức mạnh vượt trội của nó so với caret

Mục tiêu của bài thực hành: So sánh 4 algorithms khác nhau (Random Forest, Gradient Boosting Machine,  
 support  vector machine và Neural network

https://drive.google.com/open?id=0B1vaOU1uB8DPSEwzNjJpRHh5a2c","2016-11-15T23:01:46+0000","photo","https://www.facebook.com/photo.php?fbid=1375430089141758&set=gm.695402723947753&type=3","472656846222343_695402723947753",NA,43,2,5
"10210845468545723","Vịt Trần","Bài này tập tành hút thuốc (viết pipe với dplyr). Hy vọng mấy bữa nữa nhả khói hình tròn vuông đủ kiểu.","2016-11-18T02:14:12+0000","link","http://www.rpubs.com/tkvit/228141","472656846222343_696466953841330",NA,12,3,2
"1530258666992232","Namlun Didong","Trong bài 2 này, chúng ta sẽ làm một việc rất thú vị, đó là tinh chỉnh mô hình (Tuning), việc này vốn rất dễ dàng (vì hoàn toàn tự động) trong caret, nhưng trong mlR nó lại trở nên phức tạp hơn nhiều, vì yêu cầu người dùng phải chủ động kiểm soát từng chi tiết nhỏ nhất và thực hiện theo trình tự nhất định, một cách thủ công. Tuy nhiên, một lần nữa đặc tính này lại trở nên hữu ích cho công việc tương lai khi các bạn hiểu rõ việc mình đang làm và tùy cơ ứng biến…

","2016-11-13T20:31:25+0000","link","https://drive.google.com/open?id=0B1vaOU1uB8DPd2ZpVHlrNzJuQ1k","472656846222343_694302937391065",NA,40,9,4
"10154630775082982","Duy Thọ Nguyễn","Bạn Dung Nguyen Chi có hỏi về việc ""chỉnh"" histogram cho ""chuẩn"". Kinh nghiệm cá nhân mình thấy là phải thử/sai nhiều lần để chọn ra cách hiển thị histogram ""vừa ý"". Tình cờ thấy có cái add-in của RStudio cho phép tạo instagram thông qua cách tương tác trực tiếp và có kết xuất ra code ggplot2. Do dùng giao diện nên người còn mới với R cũng có sử dụng dễ dàng. 

","2016-11-17T06:00:24+0000","link","https://github.com/Stan125/limoaddin","472656846222343_696050583882967",NA,19,2,2
"10210845468545723","Vịt Trần","Có những thứ rất đơn giản, nhưng không phải ai cũng biết và biết hết.
Bỏ 2 phút coi qua, biết đâu lại có cái trick nhỏ nhỏ cứu rỗi nguyên ngày hôm nay của bạn :))","2016-11-16T21:27:40+0000","link","https://www.rstudio.com/rviews/2016/11/11/easy-tricks-you-mightve-missed/","472656846222343_695900233898002",NA,23,3,3
"10208790529222919","Vu Nguyet Minh","Cám ơn Tùng Thanh Hoàng đã add vào nhóm. Mình muốn bắt đầu làm việc với phần mềm R trong thống kê vì thấy rất nhiều chuyên gia cmt điểm mạnh của R. K biết để cài R vào macbook thì có phần mềm free nào k ạ? Xin cám ơn!","2016-11-16T03:53:13+0000","status",NA,"472656846222343_695510593936966",NA,2,2,1
"10210845468545723","Vịt Trần","So sánh thời gian chạy giữa 2 đoạn code dùng vòng lặp for-loop và lapply. 
Về mặt thời gian chạy, read.csv < read_csv (package readr) << fread (package data.table)

Ai có đóng góp gì sửa code mình rất vui","2016-11-15T18:14:22+0000","link","http://rpubs.com/tkvit/227446","472656846222343_695308417290517",NA,12,7,2
"1157950860970774","Nguyen Loc","hello các b,b nào có từng làm về gói Rfacebook chưa...có thể cho m hỏi 1 chút được không ?","2016-11-16T13:32:18+0000","status",NA,"472656846222343_695693810585311",NA,0,25,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn, 

Mình có một vấn đề và muốn nhận được ý kiến trả lời từ các bạn: 

Vì R mặc định việc chia khoảng cách trên trục X và Y nên khi vẽ, chẳng hạn, histogram thì R sẽ tự chia trục X và Y theo một luật nào đó mà chúng ta chưa rõ. Ví dụ với bộ số liệu iris  với lệnh hist(iris$Sepal.Length) cho ra sản phẩm như hình 1 (phía trên). 

Muốn hiệu chỉnh khoảng cách trên trục X chẳng hạn ta thường phải làm bằng một loạt 4 câu lệnh sau: 

hist(iris$Sepal.Length,axes = F,breaks = seq(from=4,to=8,by=1),ylim=c(0,60))

xticks <- seq(from=4, to=8, by=1)

axis(1, at = xticks)

axis(2)

Dãy 4 lệnh này cho ra sản phẩm như hình 2 (phía dưới). 

Câu hỏi của mình là: LIỆU CÓ LỆNH NÀO TẠO RA HISTOGRAM NHƯ THẾ MÀ CHỈ DÙNG MỘT DÒNG LỆNH DUY NHẤT KHÔNG? 

Cảm ơn các bạn nhiều.","2016-11-16T13:59:42+0000","photo","https://www.facebook.com/photo.php?fbid=10207844500170424&set=gm.695705650584127&type=3","472656846222343_695705650584127",NA,7,1,1
"1748154595500374","Nguyễn Minh Thành","Các bác cho em hỏi, giả sử working directory của em đang có 100 file đuôi .csv, em muốn dùng forloop read.csv để đọc, mỗi lần đọc lại tạo 1 cái object mà tên trùng với đoạn string trước .csv thì làm thế nào ạ? cái đoạn đọc thì ok nhưng em ko biết gán cái object cho read.csv bên trong loop! tks các bác","2016-11-14T16:08:57+0000","status",NA,"472656846222343_694746890680003",NA,7,2,0
"1298955620186423","Phat Chau","Em xin chào mọi người
Em là thành viên mới
Anh chị tư vấn em với, hiện tại công việc của em là phân tích dữ liệu và R là công cụ em lựa chọn
Mọi người chỉ giúp em với em nên học từ đâu","2016-11-15T10:57:34+0000","status",NA,"472656846222343_695134243974601",NA,3,1,0
"1398499446838965","Duong Duc Pham","Mình có một dataset với biến Y và 36 biến tự do. Khi làm poisson regression bằng function glm và bằng gamlss thì thấy hầu hết kết quả giống nhau (như dự kiến), trừ kết quả cho biến X13. Các cao thủ có thể chỉ giúp yếu tố nào gây ra điều này không? Cám ơn mọi người nhiều.","2016-11-10T08:29:42+0000","photo","https://www.facebook.com/photo.php?fbid=1288052354550342&set=gm.692314627589896&type=3","472656846222343_692314627589896",NA,6,3,1
"10210845468545723","Vịt Trần","Bài này hay tuyệt, vì vẽ bằng ggplot2 từ đầu đến cuối. Tuy hơi mất công, nhưng kết quả tuyệt vời","2016-11-13T15:10:44+0000","link","https://rpubs.com/bradleyboehmke/weather_graphic","472656846222343_694156170739075",NA,27,0,7
"1408132582571373","Quan Nguyen","Kính chào các bác, 
Mình đang tập tành với ggplot2. Bác nào có tài liệu hay thì giới thiệu cho mình với nhé. Chân thành cảm ơn mọi người!","2016-11-13T00:17:41+0000","photo","https://www.facebook.com/photo.php?fbid=1283344215050211&set=gm.693793234108702&type=3","472656846222343_693793234108702",NA,15,2,0
"282364888847551","Nguyễn Thu","Bộ tóm tắt code R thường dùng (base, ggplot, dplyr,...)
","2016-11-11T01:55:08+0000","link","https://www.rstudio.com/resources/cheatsheets/","472656846222343_692812440873448",NA,72,1,25
"1530258666992232","Namlun Didong","Tải bài ở đây: https://drive.google.com/open?id=0B1vaOU1uB8DPUkotcmtYLUcySzQ","2016-11-11T20:23:09+0000","photo","https://www.facebook.com/photo.php?fbid=1370054066346027&set=gm.693218260832866&type=3","472656846222343_693218260832866",NA,36,1,3
"1913258532222776","Tran Quy Phi","#Rlittlebit  08- 8/11/2016
-----------------------------------
TRÍCH PHẦN TỬ CỦA MATRIX
----------------------------------
Vị trí của một phần tử trên ma trận được xác định bởi hai con số, như là một điểm trên mặt phẳng toạ độ! HÀNG TRƯỚC, CỘT SAU và như vector chúng được đặt trong ngoặc vuông.
> M=matrix(c(""C"",""D"",""E"",""A"",""F"",""G""),nrow=2)
> M
       [,1] [,2] [,3]
[1,] ""C""  ""E""  ""F"" 
[2,] ""D""  ""A""  ""G"" 
 
> M[1,2] # Hang 1 cot 2
[1] ""E""

> M[2,3] # Hang 2 cot 3
[1] ""G""

> M[3,1] # Hang 3 cot 1
Error in M[3, 1] : subscript out of bounds
Lỗi cuối cùng là chỉ số vượt giới hạn, vì ma trận M chỉ có 2 hàng.

Bây giờ ta lấy cả một hàng. Uhm, vậy thì ta chẳng chỉ ra cột nào cả:
> M[2,]  # Hang 2
[1] ""D"" ""A"" ""G""

Lấy cả một cột thì không chỉ ra hàng nào cả:
> M[,2]  # Cot 2
[1] ""E"" ""A""
Nhưng luôn nhớ là có dấu phẩy!

Bây giờ ta đưa một chỉ số thôi, không có dấu phẩy, điều gì sẽ xảy ra?
> M[2]
[1] ""D""
> M[5]
[1] ""F""
Vậy là đã rõ, các phần tử của ma trận được xếp thứ tự từ trên xuống dưới (theo cột), hết cột này đến cột khác. DÙNG MỘT CHỈ SỐ CŨNG OK!, nhưng nó hơi mẹo một chút. Với một phần tử thứ N, trong một ma trận X hàng, Y cột ta sẽ xác định được phần tử đó ở hàng nào cột nào, và ngược lại! Bạn hãy thử xem!

Thử xem không chỉ ra hàng ra cột nào cả, chắc là cả ma trận
> M[,]
Đúng vậy!

Bây giờ ta nói vấn đề thực tế hơn:
> M=matrix(c(1,2,1,3,2,4,5,5,4,8,6,7),nrow=3)
> M
       [,1] [,2] [,3] [,4]
[1,]    1    3    5    8
[2,]    2    2    5    6
[3,]    1    4    4    7
Ta muốn trích (các) hàng mà cột 1 có giá trị là 2?
Ta muốn trích (các) cột mà hàng 3 có giá trị là 5?
Xin hẹn bữa sau!

#Rbasics
#Rlittlebit
#RMatrix
#RIndex","2016-11-08T03:03:54+0000","status",NA,"472656846222343_691092107712148",NA,13,4,1
"1748154595500374","Nguyễn Minh Thành","[hỏi đáp] Cho em hỏi các tiền bối 1 chút, trong R có parse() và eval(), em có đọc 1 số đoạn code rất hay lồng eval(parse(paste(...))), cho em hỏi structure của cú pháp này có nghĩa là gì ạ? ví dụ như đoạn code bên dưới
merge1 <- paste(""merge("", paste(data1[,""Mouse""], collapse ="",""), "")"", collapse="""")
data.merge2 <- eval(parse(text = merge1))
Tks các bác!","2016-11-09T21:55:08+0000","status",NA,"472656846222343_692084107612948",NA,1,6,0
"1913258532222776","Tran Quy Phi","#Rlittlebit  03- 3/11/2016
---------------------------------------------------------------
COPY VÀ DÁN GIÁ TRỊ TỪ EXCEL: SCAN()
--------------------------------------------------------------

GHI CHÚ: Bác Namlun Didong cũng tham gia cung cấp cho các bạn mỗi ngày một chút. Như vậy là mình có hai bữa rồi. Bữa của mình chắc là điểm tâm thôi. Bữa của Bác Namlun Didong chắc là bữa chính. Bất kỳ bạn nào có thể cung cấp vài bữa nữa cho mọi người. Mong rằng không ai bị bội thực, hoặc tệ hơn là ngộ độc :-). Have a nice day!
----------------------------------

Thường có hai cách nhập dữ liệu (data):
1. Đọc từ file (Excel, SPSS...)
2. Nhập thẳng từ bàn phím.
Nhập thẳng từ bàn phím rất chán, chỉ dùng cho số lượng dữ liệu ít.
Ta hay dùng hàm c. ""c"" là ""concatenate"", nối lại. Ta nối các giá trị riêng rẽ thành một dãy, R gọi là vector.
> age=c(40,23,26)
>name=c(""Hoa"", ""Hanh"",""Dao"")

Thường thì mình hay dùng Excel để nhập, lưu giữ và xử lý sơ sơ trước khi tiến hành phân tích với R, vì Excel dễ dùng, ai cũng biết, nhờ ai cũng được (Excel là ""Excellence"" đó!). Với dữ liệu khá đơn giản mình sẽ dán (paste) thẳng vào R bằng hàm scan().

Bạn hãy thử dùng scan() bình thường như sau:
1. Gõ age=scan() trên R
2. Enter.
3. R sẽ cho ra từng dòng, có sẵn số thứ tự, bạn nhập xong một giá trị thì Enter.
4. Đến giá trị cuối cùng, đừng nhập chi cả, chỉ Enter thôi.

Bây giờ giả sử đã có dãy giá trị trong Excel rồi. 
1. Trong Excel hãy chọn chúng và copy (Ctrl+C).
2. Ở trong R gõ age=scan() như trên rồi Enter.
3. Khi R nhắc cho giá trị thứ nhất, hãy bấm Ctrl+V (dán).
4. Loạt giá trị sẽ được điền vào cùng một lúc.
5. Enter để kết thúc.

Voilà!
#Rlittlebit, #Rscan, #RExcel","2016-11-03T02:09:22+0000","status",NA,"472656846222343_688379334650092",NA,55,1,3
"1913258532222776","Tran Quy Phi","#Rlittlebit- 10-10/11/2016
-----------------------------------
TRÍCH PHẦN TỬ CỦA MATRIX (tt2)
----------------------------------
 M=cbind(1:5,c(9,8,8,7,6),c(25,25,21,20,20))
> M
     [,1] [,2] [,3]
[1,]    1    9   25
[2,]    2    8   25
[3,]    3    8   21
[4,]    4    7   20
[5,]    5    6   20
Ta sẽ trích các hàng, các cột của Ma trận M theo một số điều kiện, ví dụ trích các hàng mà cột 2 bằng 8, lớn hơn 7 v.v…
Trước hết quay lại vector một chút.
V=c(1,4,5,1)
Nếu ta cung cấp một dãy chỉ số có giá trị là TRUE, hay FALSE thì R sẽ chỉ trích phần tử tương ứng với TRUE.
> EX=c(TRUE, FALSE, FALSE, TRUE)
> V[EX]
> 1  1
Thay vì định rõ EX, ta sẽ so sánh các phần tử của V bằng một phép so sánh, phép so sánh này có kết quả là một dãy TRUE, FALSE:
V[V==1]
Trở lại ma trận, giả sử ta muốn trích các hàng mà cột 2 có giá trị là 8.
Ta trích cột 2, để so sánh với 8. Nhớ lại HÀNG TRƯỚC, CỘT SAU:
C2=M[,2] 
So sánh với 8:
EX= C2==8
Nếu lấy tất cả các hàng thì ta sẽ ghi là:
M[ , ]
Nhưng vì chỉ lấy các hàng bằng 8, nên chỗ chỉ số hàng ta đưa EX vào:
M[EX,]
> M[EX,]
     [,1] [,2] [,3]
[1,]    2    8   25
[2,]    3    8   21
OK.
Nếu thành thạo rồi ta sẽ ghi một lần như thế này:
> M[M[,2]==8,]
     [,1] [,2] [,3]
[1,]    2    8   25
[2,]    3    8   21
Cách ghi một lần như vậy trông rất ...ghê, có thể dùng để hù doạ  :-)","2016-11-10T01:52:01+0000","status",NA,"472656846222343_692166787604680",NA,6,0,0
"10210845468545723","Vịt Trần","Có bạn hỏi code mấy cái hình mình vẽ hôm nọ. Xin chia sẻ với các bạn trên đây.

Nếu ai rảnh thấy code mình có gì sai hoặc xấu thì mình rất vui lòng đón nhận những lời góp ý của mấy bạn.","2016-11-08T16:58:04+0000","link","http://rpubs.com/tkvit/225467","472656846222343_691430537678305",NA,7,1,3
"1398499446838965","Duong Duc Pham","Các bạn cho mình hỏi với featurePlot trong gói caret làm thế nào để tùy biến thứ tự của các biến trong hình (VD. Biến Age, Height, Weight sẽ được sắp xếp ở hàng trên cùng)
Code mình đang dùng là
featurePlot(x = data2[,c(3:11)],
             y = as.factor(data2$Gender),
             plot = ""density"",
             scales = list(x = list(relation=""free""),
                           y = list(relation=""free"")),
             adjust = 1,
             pch= ""|"",
             layout = c(3,3),
             auto.key= list(columns = 2))
Cám ơn nhiều","2016-11-08T05:59:29+0000","photo","https://www.facebook.com/photo.php?fbid=1285810851441159&set=gm.691192154368810&type=3","472656846222343_691192154368810",NA,2,2,0
"1530258666992232","Namlun Didong","R MỖI NGÀY MỘT CHÚT 07- 6/11/2016
(Bs. Nam)
--------------------------------------------------
TẠO BẢNG CHÉO TỪ VECTOR, MATRIX 
LÀM TEST CHI-squared ...
---------------------------------------------------

Chào các bạn sinh viên Y khoa và các đồng nghiệp. Mình biết là ở bên nhà chúng ta rất thích dùng test Chi bình phương (thích lắm lắm luôn). Do đó bài này sẽ nói về test Chi2.

Để tuân thủ đúng tinh thần của Admin, theo đó serie này chỉ làm những thứ rất cơ bản, đi từng chút một, và để tiếp nối loạt bài hiện hành của Admin đang bàn về Vector, List, Matrix... mình cũng sẽ đi từ những object cơ bản này. Tuy bước từng bước một nhưng các bạn sẽ thấy cuối cùng mình đi được khá xa, theo 3 chặng như sau:

1) Tạo bảng chéo hoàn toàn thủ công, từ Vector, từ Matrix 

2) Làm test Chi2, Fisher-exact và Chi2 kèm mô phỏng Monte-Carlo 

3) Tính effect-size cho Chi2-test hoàn toàn thủ công bằng cách khai thác List và Matrix

---------------------------------
1) Tạo bảng chéo từ Vector và Matrix

Giả sử ta có 1 nghiên cứu thử nghiệm thuốc X trên 36 bệnh nhân:

                Cải thiện triệu chứng
Nhóm      Thấp   Trung bình  Cao
Thuốc X     3       7        8 
Placebo     9       5        4

Ta muốn làm test chi2, do đó phải tạo ra 1 bảng chéo như trên, trong R 

# Cách thứ nhất là sử dụng Vector : Ta có thể ghép 2 vector chỉ hàng hoặc 3 vector chỉ cột bằng 2 lệnh rbind và cbind

> r1<-c(3,7,8)
> r2<-c(9,5,4)

> tableR<-rbind(r1,r2)

> tableR

   [,1] [,2] [,3]
r1    3    7    8
r2    9    5    4

> c1<-c(3,9)
> c2<-c(7,5)
> c3<-c(8,4)

> tableC<-cbind(c1,c2,c3)

> tableC

     c1 c2 c3
[1,]  3  7  8
[2,]  9  5  4

# Ta có thể đi từ Matrix cũng được, như sau:

freqs<-c(3,9,7,5,8,4)

> tableM<-matrix(freqs,nrow=2)

 dimnames(tableM)
<-list(Nhom=c(""ThuocX"",""Placebo""),Caithien=c(""Thap"",""TB"",""Cao""))

> tableM
               Caithien
  Nhom      Thap TB Cao
  ThuocX     3  7   8
  Placebo    9  5   4

2) Test Chi2 và những thứ liên quan...

# Bây giờ có bảng chéo rồi, mình làm test Chi2:

> chisq.test(tableC)

Pearson's Chi-squared test
data:  tableC
X-squared = 4.6667, df = 2, p-value = 0.09697

# Hoặc test chính xác Fisher:

fisher.test(tableM)

 Fisher's Exact Test for Count Data
data: tableM
p-value = 0.1749
alternative hypothesis: two.sided

# Hoặc test Chi2 với giá trị p xác định bằng mô phỏng Monte-Carlo

 > chisq.test(tableM,simulate.p.value=T,B=1000)

 Pearson's Chi-squared test with simulated p-value (based
 on 1000 replicates)

data:  tableM
X-squared = 4.6667, df = NA, p-value = 0.1558

3) Tính Effect size cho Chi2 test:

Nếu bạn vào trang wikipedia sau: https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V

Bạn sẽ biết Effect size cho Chi2 test được đo bằng hệ số V theo Cramér hay Phi (chú thích: không phải tên của admin), với công thức:

Cramér's V = sqrt((chi2/n)/(k-1))

Với n= cỡ mẫu và k= số nhỏ hơn giữa số hàng và số cột

# Tính hệ số Cramer's V từ matrix và list kết quả của hàm chisq.test:

# Đầu tiên ta khai thác Matrix TableM để có n, nrow, ncol, từ đó tính K
n=sum(tableM)
nrow<-nrow(tableM)
ncol<-ncol(tableM)
k<-min(nrow,ncol)

(Hoặc bạn có thể đi tắt)

k<-min(nrow(tableM),ncol(tableM)) 

# Ta trích xuất giá trị chi2 từ kết quả test chi2 từng bước 1: đầu tiên ta thăm dò nội dung bên trong list kết quả, sau khi định vị được thành tố cần trích xuất, ta dùng toán tử $ và gán cho object chi2.

stat<-chisq.test(tableM)
str(stat)
chi2<-stat$statistic
chi2

# Cuối cùng ta tính được Cramér's V rồi nè:
V<-sqrt((chi2/n)/(k-1))
V<-as.numeric(V)

V
[1] 0.3600411

Kết quả trên có thể diễn đạt như sau:

Không có mối liên hệ ý nghĩa giữa loại thuốc điều trị và mức độ cải thiện triệu chứng (X2(2) = 4.67, effect-size thấp: Cramér's V=0.36, p=0.097)

Câu hỏi đặt ra: Giữa Effect-size và p-value, cái nào mang lại thông tin quan trọng hơn ?

Như có lần mình từng nói: Khả năng của R phụ thuộc vào người sử dụng, bạn giỏi đến đâu, R mạnh đến đó. Vì bạn có thể biến lý thuyết thống kê thành hiện thực khi viết công thức trong R, một cách thủ công hoàn toàn chứ không dựa vào package nào cả.

Cuối tuần vui vẻ...

(Còn tiếp)","2016-11-06T11:14:08+0000","status",NA,"472656846222343_690197777801581",NA,25,3,3
"1465665680112658","Nam Nguyễn","Các bác cho mình hỏi có quyển nào hướng dẫn về ""cách lập mô hình"" cho các bài toán cần giải quyết.

VD: đối với sales forecast thì khuyến khích dùng ARIMA, khi nào dùng logit/probit, khi nào dùng garch/arch, khi nào dùng Bayesian, v.v. ...

Mong các bác giúp đỡ cho lời khuyên.","2016-11-05T03:59:27+0000","status",NA,"472656846222343_689514331203259",NA,4,2,0
"1312924752138295","Rainie Kenta","Em chào các thầy cô và anh chị ạ.

Hiện giờ em đang tìm hiểu sâu về meta-analyses (MA), mọi người có thể tư vấn cho e một quyển sách giải thích cặn kẽ về cơ sở thống kê của M.A được không ạ? Vì phần lớn các sách chỉ hướng dẫn cách làm còn không giải thích tại sao lại làm như thế ạ.

Em cảm ơn nhiều ạ :D","2016-11-03T12:45:33+0000","status",NA,"472656846222343_688602071294485",NA,10,4,5
"1530258666992232","Namlun Didong","R: MỖI NGÀY MỘT CHÚT: 03/11/2016

Hàm đầu tiên cần học khi sử dụng R ?

Nếu bạn muốn biết function nào tôi học đầu tiên khi bắt đầu làm quen với R, tôi sẽ có câu trả lời ngay đó là str()

Khi đối diện lần đầu tiên với cửa sổ command line editor của R cách đây 3 năm, mọi thứ đều bí hiểm với tôi. Chính hàm str() đã đồng hành trong suốt quá trình học và thực hành, nó giúp tôi không còn lo sợ.Giống như trong nghi thức Exorcism khi ta phải biết tên của con quỷ nếu muốn chế ngự nó, hàm str() là một câu hỏi bạn đặt ra trước bất cứ thứ gì lộ diện trên màn hình hay ẩn giấu sâu bên trong R, dù object đó có vẻ đáng sợ thế nào, bạn chỉ cần bắt nó khai báo : bản chất của mi là gì ? sau đó bạn sẽ chế ngự nó dễ dàng

# str() áp dụng cho 1 dataset sẽ cho biết cấu trúc, bản chất và nội dung tóm lược bên trong nó

Thí dụ mỗi khi khởi động R, có 1 vài dataset đã được tự động tải vào bộ nhớ, ta có thể điều tra về một trong số chúng: data iris

str(iris)

'data.frame': 150 obs. of  5 variables:
  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
$ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
$ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
$ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
$ Species     : Factor w/ 3 levels ""setosa"",""versicolor"",..: 1 1 1 1 1 1 1 1 1 1 ...

Kết quả str() cho ta biết object có tên ""iris"" có bản chất là data.frame, có 5 biến số, 4 biến kiểu số và 1 biến Factor 3 levels, có 150 quan sát

# 1 dataset khác : Titanic

str(Titanic)

table [1:4, 1:2, 1:2, 1:2] 0 0 35 0 0 0 17 0 118 154 ...
- attr(*, ""dimnames"")=List of 4
..$ Class   : chr [1:4] ""1st"" ""2nd"" ""3rd"" ""Crew""
..$ Sex     : chr [1:2] ""Male"" ""Female""
..$ Age     : chr [1:2] ""Child"" ""Adult""
..$ Survived: chr [1:2] ""No"" ""Yes""

# str() có thể áp dụng trên bất cứ thứ gì, 1 hàm, 1 lệnh, 1 chuỗi giá trị...

str(rnorm(100,10,2))

kết quả: num [1:100] 8.7 11.61 10.9 7.74 8.48 ...

str(1:20)
 int [1:20] 1 2 3 4 5 6 7 8 9 10 ...

# Khi áp dụng trên 1 hàm, str() cho biết cú pháp của hàm đó.
str(lm)

function (formula, data, subset, weights, na.action, method = ""qr"", model = TRUE, 
    x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, 
    offset, ...)  

# str() cho phép khai thác kết quả xuất ra của một hàm, thí dụ trong mô hình hồi quy như sau:

height<-rnorm(100,160,15)
weight<-rnorm(100,60,15)

str(height)
num [1:100] 146 162 159 163 163 ...

str(glm)

model<-glm(weight~height)
model

bây giờ bạn điều tra về kết quả này thử xem sao:

str(model)

...

Chính bằng cách này, tôi đã có thể bóc vỏ hầu hết kết quả thô của những package khó chịu nhất như gamlss, caret hay brms để khai thác phần lõi bên trong, như vẽ đồ thị bằng ggplot, hay làm nhữn thứ mà package gốc không cung cấp

Hàm str() được dùng hằng ngày, và nó sẽ mở rộng khả năng của bạn.

(Còn tiếp)","2016-11-03T14:22:26+0000","status",NA,"472656846222343_688645121290180",NA,65,2,8
"10210845468545723","Vịt Trần","[Có thể là hơi lạc đề một tí]

Những từ khoá quan trọng được nhấn mạnh trong 2 cuộc tranh luận trực tiếp ngày 26/09/2016 và 09/10/2016 giữa Clinton và Trump.

Rất là thú vị khi dùng text mining để tiếp cận 2 cuộc tranh luận giữa Clinton và Trump đợt vừa rồi. Một góc nhìn khác của những keywords và wordcloud.
Các hình đều cố gắng tuân thủ code màu: Clinton Xanh, Trump Đỏ :))

Hình 1: Những từ được Clinton và Trump lặp lại nhiều nhất
Hình 2: Word Cloud những từ khoá của Clinton và Trump, kích cỡ chữ tỉ lệ thuận với số lần xuất hiện trong diễn văn.
Hình 3: Những từ khoá chung và số lượng lần được lặp lại bởi Clinton và Trump.

Vẫn là câu nói trên, bạn thấy điều gì bạn muốn thấy. Bạn không tin những điều bạn không muốn tin.

Riêng mình thì thấy, một là Trump tấn công cá nhân nhiều hơn hẳn, hai là những từ khoá của Trump ít chứa những từ khoá về vấn đề xã hội so với Clinton.

Transcript được lấy từ The Washinton Post
https://www.washingtonpost.com/news/the-fix/wp/2016/09/26/the-first-trump-clinton-presidential-debate-transcript-annotated/

Nhân tiện muốn hỏi mọi người luôn, ở đây có ai đã dùng package RWeka chạy trên MacOS bị lỗi java chưa? Nếu có thì cách khắc phục như thế nào?","2016-11-02T23:09:32+0000","photo","https://www.facebook.com/photo.php?fbid=10209755628500403&set=gm.688325277988831&type=3","472656846222343_688325277988831",NA,39,1,4
"10154431995100415","Ninh Nguyen","Mọi người cho mình hỏi hình như trong R khi làm mixed model thì không có cách nào để chỉ định là mình làm repeated measure đúng không? Theo mình tìm hiểu thì khi muốn làm repeated measure với biến subject, mình gán subject là random factor. Mình lấn cấn là random factor rất khác với repeated measure, vậy tại sao trong câu lệnh hoàn toàn giống nhau?","2016-11-01T16:02:53+0000","status",NA,"472656846222343_687593404728685",NA,0,5,0
"1530258666992232","Namlun Didong","R: MỖI NGÀY MỘT CHÚT - Ngày 03/11/2016
(Bs. Nam)

Ứng dụng các hàm Vòng lặp trong thống kê mô tả 

R cung cấp một số hàm vòng lặp (Loop function), bao gồm:
apply(), sapply(), lapply() và tapply()

Dù các hàm này có nhiều ứng dụng khác nhau, nhưng trong giới hạn bài hôm nay ta chỉ đề cập tới ứng dụng phổ biến nhất của chúng, đó là làm thống kê mô tả.

Khi kết hợp những loop function với các function cho thống kê mô tả như mean, median, sd, quantile... bạn có thể cho ra kết quả mô tả của hàng loạt biến số hoặc chia theo phân nhóm, chỉ với 1 dòng lệnh duy nhất.

1) Hàm lapply()

Hàm lapply được áp dụng trên đối tượng là 1 list, nó cho phép thực hiện 1 hàm F cho mỗi thành tố trong list
và xuất ra kết quả cũng là 1 list

'l' gợi ý về đối tượng là 1 ""list""

Cú pháp : lapply(tên list,hàm F,tùy chỉnh của hàm F...)

Do đó bạn có thể làm 1 thống kê mô tả cho hàng loạt biến trong 1 list

Thí dụ:

#Tạo 1 list L1, chứa 4 biến A,B,C,D. Nội dung: A= số thứ tự từ 1:100, B=100 con số ngẫu nhiên theo phân phối chuẩn, C=100 số ngẫu nhiên có trung bình = 20,sd=1; D: 100 số ngẫu nhiên, trung bình = 50,sd=3
L1<-list(A = c(1:100), B = rnorm(100), C = rnorm(100,20,1), D = rnorm(100,50,3))

#Tính bách phân vị cho A,B,C,D 
lapply(L1,quantile)

#Tính phân vị 2.5% và 97.5% cho A,B,C,D
lapply(L1,quantile,probs = c(0.025, 0.5,0.975))

Một cách tổng quát, hàm lapply nhận diện nội dung của tùy chỉnh đầu tiên nó gặp sau dấu (và gán nội dung này làm tùy chỉnh đầu tiên cho hàm F đi sau)

2) Hàm sapply()

Hàm sapply() có công dụng giống như lapply, nhưng nó còn tóm tắt kết quả xuất ra theo quy tắc như sau:
Nếu kích thước mỗi thành tố trong kết quả = 1, sapply xuất kết quả là vector
Nếu kích thước mỗi thành tố > 1 và đồng nhất , sapply xuất kết quả là matrix
Nếu kích thước mỗi thành tố > 1 nhưng KHÔNG đồng nhất , sapply xuất kết quả là list (như lapply)

""s"" tương ứng với ""simplify"", cho biết sapply có khả năng đơn giản hóa kết quả xuất ra.

Trong trường hợp thí dụ kể trên, do A,B,C,D đều có 100 quan sát (>1 và đồng nhất), nên sapply sẽ xuất kết quả là matrix

sapply(L1,quantile)
sapply(L1,quantile,probs = c(0.025, 0.5,0.975))

3) Hàm split()

Hàm split cho phép phân nhóm 1 vector dựa vào 1 biến số phân nhóm (factor); với factor là 1 list

Ứng dụng của split là rất tuyệt nếu bạn muốn làm thống kê mô tả cho riêng từng phân nhóm do 1 biến số phân nhóm quy định trong dataset

Thí dụ

# Tạo 1 vector V1 chứa 300 quan sát, tương ứng với 3 phân nhóm A,B,C
Nội dung: Phân nhóm A: 100 số ngẫu nhiên, tb=20,sd=1
Phân nhóm B: 100 số ngẫu nhiên phân phối uniform
Phân nhóm C: 100 số ngẫu nhiên, phân phối chuẩn, trung bình 5, sd=1.5

V1<-c(rnorm(100,20,1), runif(100), rnorm(100,5,1.5))

#Tạo 1 list phân nhóm, gồm 3 level, mỗi level 100 cá thể, dán nhãn lần lượt là ANorm20, BUniform và CNorm5

factor<-gl(3,100,labels=c(""ANorm20"",""BUniform"",""CNorm5""))

#Phân nhóm V1 theo factor

split(V1,factor)

#Tính bách phân vị cho V1 theo 3 phân nhóm quy định bởi factor 

lapply(split(V1,factor),quantile)
sapply(split(V1,factor),quantile)

4) Hàm tapply

tapply là một sự kết hợp giữa split() và sapply() và chỉ dùng cho vector.
Như vậy tapply() vừa áp dụng 1 hàm F cho mỗi phân nhóm, vừa đơn giản hóa kết quả

cú pháp là : tapply(vector,factor,function)

Không rõ ""t"" muốn chỉ điều gì, có lẽ là ""tabulate"" ?

# Thí dụ:
tapply(V1,factor, quantile)

5) Hàm apply()

Công dụng của hàm apply() thường là áp dụng 1 hàm F cho một chiều nhất định của một dataframe hay matrix
theo quy ước:  1 là hàng, 2 là cột.

Ứng dụng thường thấy nhất của apply là tính Sum, mean, median... cho từng hàng, và từng cột trong data.

Cú pháp: apply(đối tượng, 1 hoặc 2, hàm F)

Thí dụ:

# Tạo matrix m với 100 quan sát, gồm các số ngẫu nhiên, chia theo 10 hàng x 10 cột)
M=matrix(rnorm(100),10,10)

#Tính trung bình cho từng hàng
apply(M,1,mean)

#Tính tổng mỗi cột
apply(M,2,sum)

rowSum<-apply(M, 1, sum)
rowMean<-apply(M, 1, mean)
colSum<-apply(M, 2, sum)
colMean<- apply(M, 2, mean)

# Hàm apply cũng dùng tốt cho dataframe, như trong nhiều bài giảng về thống kê mô tả đã trình bày
thí dụ:

apply(as.data.frame(M),2,quantile,probs=c(0.025,0.5,0.975))

(Còn tiếp...)","2016-11-02T18:56:58+0000","status",NA,"472656846222343_688233824664643",NA,29,0,5
"1530258666992232","Namlun Didong","R-MỖI NGÀY MỖI CHÚT 2/11/2016
(Bs. Nam)

Các toán tử trích xuất dữ liệu: [ ] , [ [ ] ]  và $

Trích xuất dữ liệu là một thao tác thường xuyên khi sử dụng R, từ bước chuẩn bị, làm sạch dữ liệu, phân nhóm cho đến khai triển kết quả bằng cách đi sâu vào nội dung tiềm ẩn nằm trong phần lõi output của các function mà package mang lại. Bài này giới thiệu về 3 toán tử cho phép bạn trích xuất dữ liệu từ mọi class data.

Nguyên tắc cơ bản:

Như ta biết, R có nhiều lớp (class) dữ liệu, như vector, matrix, list, dataframe

1. Toán tử [ ] có thể dùng cho mọi class (vector, matrix, list, dataframe), dùng để trích xuất 1 hay nhiều thành phần trong object, và nó xuất ra kết quả cùng class với object gốc

2. Toán tử [[ ]] chỉ áp dụng cho object thuộc lớp List hay dataframe, dùng để trích xuất 1 thành phần trong object gốc

3. Toán tử $ chỉ áp dụng cho Dataframe hay List và trích xuất Column hay Variable, $ tương đương với [[ ]]

4. Có thể kết hợp $ và [ ] để trích xuất sâu

5. Có thể dùng c( ) để trích xuất hàng loạt giá trị và theo thứ tự tùy chọn

=========================================
I) Trích xuất nội dung Vector

vector có thể hiểu như 1 chuỗi số hay kí tự, xem như object cơ bản (và trung gian) trong R, thí dụ:

v<-c(1,4,8,""a"",""b"",""c"")

# [n] Trích xuất thành tố thứ n trong vector v
v[2]
v[5]

# Có thể trích xuất 1 chuỗi giá trị
v[2:5]

# Thậm chí có thể tùy chọn thứ tự bằng cách dùng c()
v[c(3,1,6,2)]

# Có thể trích xuất theo 1 điều kiện nào đó, thí dụ chỉ chọn giá trị lớn hơn kí tự a.

v[v>=""a""]

=================================================
II) Trích xuất nội dung Matrix

Matrix là 1 bảng (i x j) gồm i hàng và j cột

#Tạo 1 matrix 6x5, nội dung xếp giá trị từ 1:30 
#Xếp theo cột
m1<-matrix(1:30,6,5,F)
m1

# Xếp theo hàng
m2<-matrix(1:30,6,5,T)
m2

# Tạo matrix 5x4, xếp thứ tự từ 1:20
m<-matrix(1:20,5,4)
m

Toán tử [i,j] trích xuất giá trị tại vị trí hàng i và cột j

#Trích xuất giá trị hàng thứ 4
m[4,]

#Trích xuất giá trị cột thứ 2
m[,2]

#Trích giá trị kèm theo định vị
m[,2,drop=F]
m[2,,drop=F]

#Trích giá trị hàng 4, cột 3
m[4,3]

==================================
III) Trích xuất giá trị từ 1 list

List là 1 tập hợp biến có độ dài tùy chọn, 
List chưa phải là 1 matrix, càng không phải như data.frame đúng nghĩa vì các giá trị không quan hệ tương ứng với nhau theo hàng và cột
nhưng các thao tác trích xuất trên list gần giống như df, và việc trích xuất thông tin từ list rất quan trọng khi ta muốn khai thác sâu kết quả xuất ra từ các hàm thống kê, phân tích.
Thí dụ nhờ trích xuất thông tin từ kết quả mô hình hồi quy mà ta có thể tính được các chỉ số như R2, RMSE, v.v  

#Tạo 1 list gồm 2 biến A, B với A=1:10 và B=1,2,3
l<-list(A=1:10,B=c(1,2,3))
l

#Toán tử [n] trích xuất thành tố thứ n trong list, thí dụ: 
l[1]

#Có thể nêu đích danh biến số bằng """" hay dùng $ thay cho []
l[""B""]
l$A

#[n,i] trích xuất giá trị thứ i trong thành tố thứ n
l[[c(1,4)]]

#Tương đương với:
l[[1]][[4]]

#Có thể kết hợp nhiều biến trong cùng toán tử  [], sử dụng c()
l[c(1,2)]

================================
IV) Trích xuất giá trị từ Dataframe

Dataframe là 1 đối tượng dữ liệu phổ quát và cùng đặc tính như matrix, 
Ta có thể hoán chuyển giữa df và matrix, và cả 2 đều có thể dùng khi làm thống kê
df tương đương với bảng số liệu các phần mềm như SPSS, Medcalc, hay SAS

Toán tử $ và [ ] có thể áp dụng cho dataframe

#Có thể tạo 1 dataframe rỗng, để dành 
d0=as.data.frame(NULL)

#Có thể hoán chuyển matrix thành dataframe
d1=as.data.frame(m)

#Toán tử [i,j] cho phép trích xuất dữ liệu tại vị trí hàng i, cột j từ df
d1[2,3]

#Có thể dùng [i , ] và [, j ] để trích xuất nguyên cả hàng/cột
d1[,1]
d1[3,]

#Dùng c( ) để trích xuất 1 phần nội dung df theo thứ tự và nội dung tùy chọn
d1[c(2,1)]

#tương đương với
d1[,c(2,1)]

#Trích xuất hàng 5,4 của cột 4, 2
d1[c(5,4),c(4,2)]

#Toán tử $ dùng để trích xuất đích danh 1 biến trong df
d1$V3

#Có thể kết hợp $ và [ ], thí dụ: trích xuất biến V2, hàng thứ 3
d1$V2[3]

#Trích xuất biến V3, hàng 2,3,4
d1$V3[c(2:4)]

#Trích xuất biến V1, hàng 4,1,5
d1$V1[c(4,1,5)]

(Còn tiếp)","2016-11-02T11:14:40+0000","link","http://[2:5]/","472656846222343_688013301353362",NA,35,4,5
"1913258532222776","Tran Quy Phi","R-MỖI NGÀY MỖI CHÚT-1- Ngày 1/11/2016: PHÉP GÁN

Mình dự định sẽ post trên group này mỗi ngày một ghi chú ngắn về R, nói về một số điều cơ bản trong R mà mình biết và thấy thú vị. Mong nó giúp ích cho mọi người. Have a nice day!

> a=2
> x=y

Dấu bằng được gọi là phép gán (assignment), là gán cái bên phải (2) cho cái bên trái (a), và gán y cho x.

Cũng có thể dùng mũi tên gồm dấu < và -
> a<-2

Mũi tên nêu rõ chiều của phép gán, nghĩa là bạn có thể viết là:
> 2->a

Cần thấy một dấu bằng là phép gán, còn so sánh thì dùng hai dấu bằng. 

> a==4
[1] FALSE /*Không đúng*/","2016-11-01T02:54:11+0000","status",NA,"472656846222343_687223511432341",NA,53,7,5
"1913258532222776","Tran Quy Phi","R MỖI NGÀY MỖI CHÚT-NOTE 02-2/11/2016
SO SÁNH 
Để so sánh hai đối tượng bằng nhau không ta dùng hai dấu bằng
> 2==3
[1] FALSE
> 2==2
[1] TRUE
Kết quả là đúng hoặc sai.
> x=2; y=3 /* Bạn có thể ghi nhiều lệnh cách nhau bằng dấu ; rồi mới Enter
> x == y
[1] FALSE
Các phép so sánh khác là >, <, >=, <= như Excel nhưng dấu khác là !=, chứ không phải <>
Nếu hai đối tượng có nhiều phần tử, R sẽ so sánh từng phần tử:
> x= c (1,2,3)
> y= c (1,5,6)
> x == y
[1]  TRUE (1==1) FALSE (2==5) FALSE (3==6)
Kết quả nó sẽ cho ra một dãy sai đúng cho từng cặp phần tử…
Nhưng có khi ta chỉ cần biết TẤT CẢ CẶP đều bằng nhau không. Rất đơn giản:
Có hai cách hỏi R:
Có phải MỖI  x đều bằng MỖI y không (theo thứ tự từng cặp):
>  all(x==y) 
Có phải có một x nào khác y không (theo thứ tự từng cặp):
> any(x!=y)
So sánh hai dữ liệu (là hai bảng) cũng tương tự như vậy. 
Ví dụ, bạn có thể cho hai người khác nhau nhập dữ liệu, sau đó bạn so sánh có bất kỳ sai khác nào không. Đặc biệt, sai khác đó nó nằm ở dòng nào cột nào? Hẹn buổi khác!","2016-11-02T00:01:43+0000","status",NA,"472656846222343_687786271376065",NA,33,2,4
"10206740887835617","Hoang Van Hai","TL=c(346,350)
CN=c(467,320)
SN= c(23,46)
barplot(rbind(TL,CN,SN), beside=TRUE, names=c(""Thung lũng"",""Chân núi"",""Sườn vách núi""), col=c(""red"",""green""),xlab=""Địa hình"",ylab=""Số lượng cây"")
legend(""top"", c(""Tái sinh hạt"",""Tái sinh  chồi""), fill=c(""red"",""green""),box.lty=0)
  Không hiểu em nhầm ở đâu mà không ra được biểu đồ.
Nhờ các thầy giúp em với ah.","2016-11-01T05:10:54+0000","status",NA,"472656846222343_687299514758074",NA,6,3,0
"10206950570583227","An Tom","Trong post trước về hàm attach(), thấy mọi người đã trao đổi nhiều về lợi và hại của hàm này rồi, mình cũng đồng ý là tùy trường hợp mà sử dụng, nhưng chưa thấy ai nói rõ hơn về cơ chế đằng sau của attach(). Mình có viết 1 cái tut ngắn ở đây, hi vọng là giúp các bạn mới không bị confused.

http://rpubs.com/anchu/rattach

Any comments would be appreciated","2016-10-29T09:12:16+0000","link","http://rpubs.com/anchu/rattach","472656846222343_685479764940049",NA,22,2,2
"1913258532222776","Tran Quy Phi","GHI CHÚ VỀ ATTACH
Có bạn cho rằng ""Đừng bao giờ dùng lệnh attach"". Cũng hơi cực đoan. Ở đây xin giải nghĩa một chút về lệnh attach, với một xíu cẩn thận thì attach rất có ích.
Ta có biến gender và age như sau:
> gender=c(1,0,1,1)
> age=c(4,5,2,4)
Tạo data frame:
> dat=data.frame(gender,age)
> dat
  gender age
1      1   4
2      0   5
3      1   2
4      1   4
Để ý tới gender: ở đây có hai gender lận. gender đầu tiên nằm ""ngoài"" (nằm ở môi trường toàn cục, global, theo ngôn ngữ chính thức) và gender nằm ""trong"" dat.
Để chỉ gender nằm trong dat ta dùng dấu $
> dat$gender
[1] 1 0 1 1
khác với
> gender
[1] 1 0 1 1
Không tin bây giờ ta thay đổi gender
> gender=c(0,0,0,0)
thì dat$gender vẫn là 1 0 1 1.
Vì cho gọn (và có thể có lý do khác), nên ta chỉ muốn dùng gender thay cho dat$gender
ta dùng attach 
> attach(dat)
lúc này các ""con"" của dat, là gender và age sẽ ra nằm ""ngoài"". Nhưng bởi vì ở ""ngoài"" đã có gender, nên ta sẽ có cảnh báo:
The following objects are masked _by_ .GlobalEnv: age, gender
Nghĩa là: Các đối tượng sau đây (của dat) age, gender sẽ bị che (ngụy trang!) bởi .GlobalEnv.
Khi gặp câu này, bạn hãy biết rằng mình sẽ dễ dàng phạm sai lầm!
Lúc này mặc dù, đã được attach, nhưng các thành phần age, gender của dat vẫn không được truy xuất trực tiếp, tức là nếu muốn nói gender của dat, bạn vẫn phải ghi là dat$gender.
Muốn mọi việc trở lại ban đầu, đừng làm gì thêm, hãy detach lại
detach(dat)
nếu bạn không muốn nhầm lẫn giữa gender bên ""ngoài"" và gender bên ""trong"" dat.","2016-10-27T22:52:35+0000","status",NA,"472656846222343_684627828358576",NA,20,10,5
"1595146587166138","Hai Nguyen","Trợ giúp về graph in ggplot2, dùng data.table package phối hợp:

Plot thể hiện raw means và 95% CI cho 4 time points (1=Baseline, 2=6 months, 3=12 months, 4=18 months) cùng với ""individual"" linear, quadratic, và cubic trend (vẽ dựa trên predicted values từ output mixed regression model, chứ không regressed on 4 raw means). 

Vấn đề (loay hoay mãi mà không ra, nên nhờ anh chị em giúp đỡ):
1. Làm sao thay đổi values của Visit mà không làm thay đổi 3 individual curves đã vẽ, tức là thay vì x-axis hiển thị 1,2,3,4 , sẽ hiển thị Baseline, 6 months, 12 months, 18 months.

2. Thêm chú thích vào legend của plot: 
-- (blue color) : linear
-- (red color): quadratic
-- (green color): cubic

Mình attach coding và file số liệu dưới đây.
Chân thành cảm ơn sự giúp đỡ từ anh chị em.

Hai.

install.packages(""ggplot2"")
library(ggplot2)
install.packages(""data.table"")
library(data.table)

# Calculate means for each Visit
rpcs12set <- fread(""U:/KDQoL Subscale Means Across Time/Datasets/wPredicted/rpcs12dataset.csv"")
rpcs12mean  <- rpcs12set[, list(RPCS12 = mean(RPCS12, na.rm = T), 
                                stderror = sd(RPCS12, na.rm = T)/sqrt(length(RPCS12))), 
                         by = Visit]

rpcs12mean

# After getting raw means from observations for 4 Visits, 
# we keep in dataset only 2 varibles Pred and Visit (change Pred name to RPCS12)
rpcs12set <- rpcs12set[, !""RPCS12"", with=FALSE]
setnames(rpcs12set, old=c(""Pred""), new=c(""RPCS12""))

# Physical Health Composite Means (SE) across Time 
#  with individual linear (SE) and Quadratic (SE) Regression Lines. Plus DECORATION
p <- ggplot(mapping = aes(x=Visit, y=RPCS12)) + 
  geom_errorbar(aes(ymin=RPCS12-1.96*stderror, ymax=RPCS12+1.96*stderror), width=.1, data = rpcs12mean) +
  geom_line(data = rpcs12mean) +
  geom_point(data = rpcs12mean) +
  xlab(""Visit"") +
  ylab(""Physical Health Composite"") +
  ggtitle(""Physical Health Composite Mean Changes Across Visits"")

p + stat_smooth(method = ""lm"", formula = y ~ x, se = FALSE, size = 1, colour = ""blue"", data = rpcs12set) + 
    stat_smooth(method = ""lm"", formula = y ~ x + I(x^2), se = FALSE, size = 1, colour = ""red"", data = rpcs12set) +
    stat_smooth(method = ""lm"", formula = y ~ x + I(x^2) + I(x^3), se = FALSE, size = 1, colour = ""green"", data = rpcs12set) +
    theme_bw()","2016-10-28T21:28:37+0000","status",NA,"472656846222343_685183418303017",NA,1,2,2
"10154630775082982","Duy Thọ Nguyễn","RMarkdown có hỗ trợ việc kết xuất ra file Word nhưng nhiều ý kiến cho là không ""native"" lắm. Dù sao đi nữa, Microsoft Office vẫn là phần mềm văn phòng thông dụng nhất thế giới và với rất nhiều người, việc sử dụng 1 report trình bày rõ ràng bằng Word hay Power Point vẫn mang lại cảm giác gần gũi và thân thuộc hơn các report định dạng giống báo cáo khoa học (layout mặc định khi compile PDF từ RMarkdown)

Package này hỗ trợ việc kết xuất các report với format của Microsoft Office. Cá nhân mình thì khi review  package thì không thích cách thức viết script tạo report lắm vì nó gợi nhớ  cách thức sử dụng các ngôn ngữ lập trình truyền thống (RMarkdown sử dụng đơn giản hơn và ""expressive"" hơn) 

Nhưng 1 công cụ cho phép bạn làm việc tốt với các sản phẩm của  Microsoft thì bao giờ cũng nên có sẵn trong túi áo để dùng ngay khi cần. 

","2016-10-28T16:56:47+0000","link","http://davidgohel.github.io/ReporteRs/index.html","472656846222343_685076271647065",NA,20,1,7
"2252918234934208","Tín Nguyễn","Giới thiệu sách :

Đây là quyển sách hay về  Statistical Learning (Data Mining, Inference, and Prediction) với nhiều bài tập dùng R.
Mọi người ai muốn tìm hiểu thêm hay muốn download thì có thể vào trang web của tác giả.

","2016-10-28T12:43:32+0000","link","http://www-bcf.usc.edu/~gareth/ISL/","472656846222343_684964514991574",NA,59,2,10
"10208725271269151","Dung Nguyen Chi","Kinh nghiệm xương máu: Đừng bao giờ dùng lệnh attach()

Vừa rồi em có viết một  chương trình dài nhưng lúc chạy thì bị lỗi. Điều tra mãi thì mới biết là do lệnh attach() gây ra. Lúc mới học R chắc ai cũng thích sử dụng lệnh này vì nó tiết kiệm thời gian gõ. Nhưng thật không may, nếu là viết R code, viết function thì lệnh này thật là tai hại. Giải thích như trong hình. 

Nhân tiện đây cũng rất cảm ơn Duy Thọ Nguyễn vì đã chia sẻ việc sử dụng dấu = thay cho dấu <- trong phép gán sẽ gây tai hại. Chi tiết tưởng nhỏ này hóa ra lại gây họa trong nhiều tình huống.","2016-10-27T18:31:21+0000","photo","https://www.facebook.com/photo.php?fbid=10207683524226126&set=gm.684536995034326&type=3","472656846222343_684536995034326",NA,47,11,5
"1916473528585841","Tue Nguyen","[Khắc phục lỗi gõ tiếng Việt với Markdown trong Windows]
Mình thấy có vài bạn gặp vấn đề với việc gõ tiếng Việt trong Markdown, trong khi mình vẫn gõ đc bình thường (Windows 10). Mình nghĩ có khả năng là do các bạn ko chọn đúng mã hóa lúc save file. Các bạn thử làm như thế này xem đc ko.

1. Chọn new file .Rmd, chưa save vội
2. Gõ vài ký tự tiếng việt vào (có dấu má hoặc ư, ô, ê, ... vào nhé)
3. Ctrl + S hoặc click save button.
Lúc đó RStudio sẽ hiện một Pop-up hỏi các bạn muốn lưu file dưới định dạng nào vì nó phát hiện ký tự bạn gõ vào ko phải mã ASCII.
4. Chọn UTF-8 (vì tiếng Việt mã hóa theo Unicode). Nhấn Ok là xong.
(Hình minh họa)","2016-10-28T04:16:09+0000","photo","https://www.facebook.com/photo.php?fbid=1854767234756471&set=gm.684750158346343&type=3","472656846222343_684750158346343",NA,12,3,4
"1849942691933972","Nguyen","Hôm nay em có đọc qua 1 bài báo. Để xử lý các outliers, tác giả dùng kỹ thuật ""winsorization"" sau đó loại các quan sát là outliers.

Google thì em thấy kỹ thuật này có 2 cách để làm:
Cách 1- loại outliers như bài báo trên.
Cách 2- thay thế các outliers bằng những giá trị nhất định

Có anh chị nào đã từng làm kỹ thuật này chưa ạ? Việc thực hiện theo cách 2 có làm lệch lạc bản chất của data đã thu thập không ạ?

Trong R có 1 package tên là robustHD thực hiện điều này. Ngặt nỗi nếu dataframe có missing value thì lệnh wisorize không thể thực hiện được.

Trong STATA cũng có một gói tương tự có cùng chức năng tên là winsor và có thể thực hiện kỹ thuật này với dataframe có missing values. Thao tác tiến hành nhanh với lệnh đơn giản.","2016-10-28T12:49:58+0000","status",NA,"472656846222343_684966688324690",NA,8,3,1
"1205787479527610","Diệp Phong","Sách mới của thím Wickham tuy chưa ra lò nhưng thím ấy đã public trên web rồi :3 :3","2016-10-28T12:11:23+0000","link","http://r4ds.had.co.nz/","472656846222343_684952174992808",NA,68,4,7
"1849942691933972","Nguyen","Mình có vấn đề tí hon này ko biết có anh chị nào đã từng trải qua chưa.

Lấy ví dụ cho dễ trình bày:

Mình có 1 data gồm 4 biến: 
x1 <-  c(1,2,3,4,5,6,7,8,9,10)
x2 <-  c(2,NA,3,4,5,6,1,8,1,20)
x3 <-  c(2,10,99,8,7,6,5,4,1,NA)
x4 <-  c(11,6,33,20,NA,6,4,6,5,20)

data <- data.frame(x1,x2,x3,x4)

Để tính correlation, thông thường mình làm:

data.cor <- na.omit(data)
cor(data.cor) hoặc 
pairs.panels(data.cor, cex.cor =1.5)

Tương đương với: 
cor(data, use= ""complete.obs"")

Với cách này R sẽ xóa các dòng có ít nhất 1 missing obs, sau đó tính bình thường. 

Còn 1 cách nữa là tính correlation cof. cho từng cặp biến:
cor(data, use= ""pairwise.complete.obs"")
pairs.panels(data, cex.cor =1.5)

Với 2 cách khác nhau, kết quả tính ra có khác biệt nhau tùy thuộc vào đặc tính của data. 
Theo kinh nghiệm của mọi người thì bảng correlation trong các paper họ thường dùng cách nào nếu có sự khác biệt tương đối giữa 2 cách ạ?","2016-10-26T06:33:16+0000","status",NA,"472656846222343_683606148460744",NA,2,5,1
"10202996672153443","Nguyễn Cường","Thứ để vọc vạch cho anh em ngày mùa thu buồn buồn! 
Khá là hữu ích cho anh em bắt đầu tập chơi forcasting như em với nền cơ bản OLS, ARIMA và Neural networking... 
Tiện thể thì nó cũng ngắn, đọc tầm 2,3 hôm từ từ là hết sạch. 
khó chịu tí tí là data của course này nằm luôn 1 1 packages(fpp) do Rob J Hyndman và George Athana­sopou­los tạo lập. các bác thao tác như sau để load package cũng là dữ liệu về R nhé: 
install.packages(""fpp"", dependencies=TRUE)
library(fpp)
require(fpp)

","2016-10-27T22:54:19+0000","link","https://www.otexts.org/fpp/1","472656846222343_684628638358495",NA,21,1,3
"10208725271269151","Dung Nguyen Chi","Solution for chapter 3 (Applied Predictive Modeling by Max Kuhn)

http://rpubs.com/chidungkt/221544","2016-10-25T12:26:51+0000","photo","https://www.facebook.com/photo.php?fbid=10207667294540394&set=gm.683053621849330&type=3","472656846222343_683053621849330",NA,35,5,7
"10155067337149710","Le Dang Trung","Hello ngày mới!

Nếu các bạn hỏi R sẽ đi vào cuộc sống như thế nào thì đây là 1 trong những ứng dụng của R:

Các bạn có thể tìm hiểu thêm về PAPI tại đây: http://papi.org.vn","2016-10-28T01:24:44+0000","photo","https://www.facebook.com/photo.php?fbid=10154645887229710&set=gm.684688925019133&type=3","472656846222343_684688925019133",NA,33,2,3
"1627919773889937","Nguyen Chi Thanh","Thảo luận về nghiên cứu
Mong mọi người cùng cho ý kiến để tiếp cận theo hướng nào thì tốt hơn có thể thông kê ra kết quả tốt hơn
Đặt vấn đề, câu hỏi nghiên cứu: mùi thơm của gạo có bị ảnh hưởng một quá trình sấy hay không?
Bối cảnh: 
- Nhà máy vừa trang bị hệ thống sấy lúa (làm khô lúa)
- Ban giám đốc muốn biết mùi thơm của giống gạo có bị suy giảm sau khi sấy qua hệ thống hay không
- Giá trị đo mùi thơm gạo chỉ có ba giá trị: 0: không thơm; 1: thơm nhẹ; 2: Rất thơm. Dựa vào cảm giác của người ngửi và cho điểm lên mẫu đó. Phương pháp đo hàm lượng hợp chất rất phức tạp và đắt đỏ
Cách tiếp cận:
- Đánh giá mùi thơm lúa đầu vào
- Đánh giá mùi thơm lúa đầu ra
- Dựa vào tổng điểm từng nhóm để phân tích (dự kiến là Chi-square hoặc t.test)
- Có mẫu chuẩn để ngửi trước cho ba cấp độ 0: không thơm; 1: thơm nhẹ; 2: Rất thơm
- Các mẫu đánh giá sẽ được mã hóa và lập lại 3 lần cho mỗi mẫu. Người đánh giá hoàn toàn không biết gì về mẫu
Tranh cãi:
Ai sẽ tham gia đánh giá?
1. Chuyên gia (mấy người có kinh nghiệm): số lượng rất ít, coi như chính xác đi cho dễ
2. Rât nhiều người cùng tham gia. Họ sẽ ghi điểm cho các mẫu sau khi ngửi mẫu chuẩn
Có thể cho mình ý kiến giúp nên tiêp cận cách 1 hay cách 2, (hoặc kết hợp cả hai cách-cái này xem như không có nha mọi người vì đúng là không nên thoả hiệp trong nghiên cứu khi phân tích phương pháp)","2016-10-27T03:35:19+0000","status",NA,"472656846222343_684159421738750",NA,6,10,0
"10208725271269151","Dung Nguyen Chi","Sách hay

Cuốn sách này phù hợp với những bạn có nền tảng thống kê không tốt cho đến những bạn có trình độ trung cấp (intermediate). Đây là ba điểm khác biệt của sách so với những cuốn thống kê khác cùng thể loại. 

1. Đề cập đến kĩ năng Data manipulation đầu tiên (như sử dụng gói resharp2) ngay ở những chương đầu. 

2. ĐÚng như tên gọi, ngoài những con số thống kê khô khan còn nhấn mạnh đến data visualization. TẤT CẢ các hình vẽ có trong sách đều có code tươgn ứng. 

3. Viết code ở trình độ rất cơ bản. 

Sách dày 909 trang của Heiberger & Holland (Temple University) và được sử dụng làm giáo trình cho ngành Thống Kê của trường này.","2016-10-25T15:29:53+0000","photo","https://www.facebook.com/photo.php?fbid=10207668186762699&set=gm.683159485172077&type=3","472656846222343_683159485172077",NA,138,6,32
"1902396496656572","Huynh Kim An","mình gặp trục trặc này, mong a/c giúp:
nhập  chunk code vào Markdown:
```{r,echo=TRUE} 
x<-rnorm(100) 
length(x) 
hist(x)
```
khi mở HTML thì bị lỗi:
"" Quitting from lines 102-105 (Tinh_Toan.Rmd) 
Error in evaluate_call(expr, parsed$src[[i]], envir = envir, enclos = enclos,  : 
  unused argument (include_timing = include_timing)
Calls: <Anonymous> ... call_block -> block_exec -> in_dir -> evaluate -> evaluate_call
Execution halted ""
cảm ơn.","2016-10-26T03:16:16+0000","status",NA,"472656846222343_683511525136873",NA,0,5,0
"1627919773889937","Nguyen Chi Thanh","Một cuốn sách kết hợp giữa lý thuyết và thực hành khá đầy đủ và chi tiết về R, dành cho ai muốn dùng R như công cụ phân tích dữ liệu nghiên cứu từ căn bản đến chuyên sâu. Cuốn sách đi qua hầu hết các phương pháp phân tích dữ liệu đang được nhiều lĩnh vực khác nhau sử dụng.
""R in Action (SECOND EDITION): Data analysis and graphics with R"" của ROBERT I. KABACOFF
brief contents
PART 1 GETTING STARTED ...................................................... 1
1 �¡ Introduction to R 
2 �¡ Creating a dataset 
3 �¡ Getting started with graphs 
4 �¡ Basic data management
5 �¡ Advanced data management 
PART 2 BASIC METHODS ...................................................... 115
6 �¡ Basic graphs 
7 �¡ Basic statistics
PART 3 INTERMEDIATE METHODS ........................................ 165
8 �¡ Regression
9 �¡ Analysis of variance 
10 �¡ Power analysis 
11 �¡ Intermediate graphs
12 �¡ Resampling statistics and bootstrapping 
PART 4 ADVANCED METHODS ............................................... 299
13 �¡ Generalized linear models
14 �¡ Principal components and factor analysis 
15 �¡ Time series 
16 �¡ Cluster analysis 
17 �¡ Classification
18 �¡ Advanced methods for missing data 
PART 5 EXPANDING YOUR SKILLS ......................................... 435
19 �¡ Advanced graphics with ggplot2 
20 �¡ Advanced programming
21 �¡ Creating a package
22 �¡ Creating dynamic reports 
23 �¡ Advanced graphics with the lattice package 1 online only","2016-10-04T06:52:18+0000","photo","https://www.facebook.com/photo.php?fbid=1457559664259283&set=gm.671167143037978&type=3","472656846222343_671167143037978",NA,63,18,7
"10208725271269151","Dung Nguyen Chi","Basic R: Chương 12 cuốn ""Phân tích số liệu với R"" của tác giả Nguyễn Văn Tuấn được trình bày lại với gói caret cũng như bổ sung thêm phần cải thiện khả năng dự báo của mô hình Logistic: 

","2016-10-23T14:06:48+0000","link","http://rpubs.com/chidungkt/221015","472656846222343_681800941974598",NA,56,6,5
"10210845468545723","Vịt Trần","Machine Learning dưới góc nhìn của những người lập trình. Cuốn này hay do 2 lý do: thứ nhất có code và data sẵn giúp cho các bạn thực hành luôn và ngay, thứ hai cách viết code của những người viết sách mang phong cách của những người làm bên IT nhiều hơn là bên thống kê. 

Ps: Một vài function trong sách đã cũ, nên một là không tồn tại nữa, hai là dài dòng hơn so với các package mới bây giờ. Chúc các bạn ngon miệng :)","2016-10-24T23:49:14+0000","photo","https://www.facebook.com/photo.php?fbid=10209670886261900&set=gm.682775438543815&type=3","472656846222343_682775438543815",NA,38,0,7
"10208725271269151","Dung Nguyen Chi","Gẫy xương 2 với một số cách tiếp cận của Machine Learning: 

http://rpubs.com/chidungkt/221015","2016-10-23T17:51:41+0000","photo","https://www.facebook.com/photo.php?fbid=10207653391112817&set=gm.681951018626257&type=3","472656846222343_681951018626257",NA,23,4,2
"1188768411232084","Yến Hoa","hello mọi người,
mình mới cài lại R studio trên win 7 (trước mình đã cài rồi và dùng tốt, sau đó mình cài lại win, từ lúc đó không dùng được R studio nữa). Bây giờ mình cài lại, nó báo error như thế này. Mình đã làm theo: control panel -> change location -> change system local.. rồi mà vẫn không được. 
Bạn nào đã gặp tình trạng này rồi thì bảo mình với nhé :) cám ơn mn","2016-10-21T15:27:50+0000","photo","https://www.facebook.com/photo.php?fbid=1052484034860523&set=gm.680593778761981&type=3","472656846222343_680593778761981",NA,1,1,0
"474927739564498","Nguyen Ynes","Xin chào mọi người,
Mình mới được biết đến thống kê bằng ứng dụng R và MINITAB thông qua cuốn sách mới của VIASM. Tuy nhiên, do còn thiếu phần nền tảng về R nhiều nên mình đọc sách hiểu không kĩ cho lắm. Các bạn có thể reccommend mình đọc cuốn sách hay tài liệu nào đó cho người mới bắt đầu như mình không?
Xin cảm ơn nhiều!","2016-09-27T11:22:39+0000","status",NA,"472656846222343_667582066729819",NA,4,5,0
"408620806155776","Mai Thanh Nguyen","Hello các anh chị...
Em đang đọc cuốn Mastering Data Analysis with R. Trong cuốn sách lúc loading số liệu từ Web/Internet, địa chỉ https:/ bị thay đổi, nên nhiều lúc làm theo y nguyên như sách mà không có ra đúng kết quả như sách, làm em phải mò mãi mới ra được. Mọi người ơi ai đọc hết cuốn sách này rồi, cho em xin 1 giải pháp đi ạ! 

Ví dụ sinh động nhất là chapter 1, phần Getting data from the Web. Không phải là ""x94z-ydhh"" mà là ""s6ew-h6mp"". 

Thật không thể yêu đương nổi...:<","2016-10-16T10:28:17+0000","photo","https://www.facebook.com/photo.php?fbid=336767103341147&set=gm.677547242399968&type=3","472656846222343_677547242399968",NA,10,2,0
"10208725271269151","Dung Nguyen Chi","Câu hỏi về Data Manipulation

Chào tất cả các bạn, 

Thông thường thì định dạng thời gian của Tây là Năm-Tháng-Ngày, ví dụ: 2015-01-27. Tuy nhiên của VN thì khác với định dạng kiểu 27/01/2015. Do vậy em có hai câu hỏi (mới đọc qua các bạn có thể thấy ..dễ nhưng thực tế bắt tay vào làm mới thấy có nhiều vấn đề nảy sinh chứ không đơn giản như hình dung) như sau: 

1. Làm thế nào chuyển định dạng thời gian từ 27/01/2015 thành 2015-01-27 ? 

2. Làm thế nào biến một data frame thành một object kiểu như AAPL ? 

Tất cả câu hỏi và vấn đề được trình bày rõ trong link dưới đây (mình có lỗi khi dùng Rpub nên các bạn thông cảm download câu hỏi về): 

http://www.mediafire.com/file/0gvz7tsgtz62baf/th%E1%BB%A9_t%E1%BB%B1_ng%C3%A0y_th%C3%A1ng%282%29.docx

Cảm ơn các bạn nhiều.","2016-10-12T13:23:48+0000","link","http://www.mediafire.com/file/0gvz7tsgtz62baf/th%E1%BB%A9_t%E1%BB%B1_ng%C3%A0y_th%C3%A1ng%282%29.docx","472656846222343_675309679290391",NA,12,4,1
"10208725271269151","Dung Nguyen Chi","Một câu hỏi hay về sử dụng ggplot2 và mong nhận được câu trả lời của các bạn: 

http://rpubs.com/chidungkt/216350

Cảm ơn rât nhiều.","2016-10-08T12:42:45+0000","photo","https://www.facebook.com/photo.php?fbid=10207522179632612&set=gm.673208449500514&type=3","472656846222343_673208449500514",NA,14,3,0
"10154630775082982","Duy Thọ Nguyễn","Nếu làm quen với Python trong data analysis, gần như chắc chắn là bạn đã thử qua notebook của Python.  Dù trong thực tế mình code khá nhiều Python tuy nhiên theo quan điểm của mình thì Noteboom của Python có những hạn chế rất quan trọng. Giờ đây khi R Notebook chính thức release thì chắc người ta sẽ không còn so sánh Notebook của Python với Rmarkdown nữa. :D 
","2016-10-05T15:45:59+0000","link","https://blog.rstudio.org/2016/10/05/r-notebooks/","472656846222343_671818206306205",NA,42,0,6
"10154630775082982","Duy Thọ Nguyễn","Deep learning là lĩnh vực mà R khá thất thế so với Python. Tuy nhiên cuối cùng thì cũng có library cho phép làm việc với Tensorflow - thư viện Machine Learning mà Google mới open source năm ngoái. Tuy nhiên Tensorflow không support Windows dù bạn có thể ""né"" hạn chế này bằng cách sử dụng Docker
","2016-09-30T14:29:55+0000","link","https://github.com/rstudio/tensorflow","472656846222343_669254736562552",NA,44,9,5
"1703957449618038","Phương Ngọc","Em kính chào các anh các chị,

Em chưa biết tí gì về R và đang muốn tìm lớp học hoặc cộng đồng ofline chia sẻ/ tự học ở khu vực Hà Nội. Các anh chị nào có thông tin thì giúp em với ạ? Em chân thành cảm ơn!","2016-09-28T12:58:27+0000","status",NA,"472656846222343_668181806669845",NA,10,6,0
"10154630775082982","Duy Thọ Nguyễn","Làm sạch dữ liệu văn bản là 1 tác vụ ""mệt mỏi"", ngay cả khi sử dụng những ngôn ngữ lập trình truyền thống. Link dưới đây là sách điện tử miễn phí đi kèm với package tidytext theo triết lý tidyverse của Hadley Wickham. 
","2016-09-25T13:33:06+0000","link","http://tidytextmining.com/","472656846222343_666400663514626",NA,65,0,12
"10154630775082982","Duy Thọ Nguyễn","Thấy có specialization mới về R trên Coursera. Lần này focus nhiều hơn về Software Development. Mặc dù trong thực tế phát triển 1 giải pháp phần mềm chuyên về data analysis đòi hỏi nhiều công nghệ  khác nhau không chỉ gói gọn trong kiến thức chuyên ngành và khả năng viết R để phân tích dữ liệu, tuy nhiên course này hứa hẹn là thú vị cho ai muốn đào sâu về R. Ai join course thì liên hệ học chung nha. :D 
","2016-09-22T11:03:28+0000","link","https://www.coursera.org/specializations/r","472656846222343_664771743677518",NA,52,2,2
"1285424814877041","Gravis Trương","Hi all, 
Cho em hỏi lệnh:
txn <- as(i, ""cate"")
Nó trả về :
rror in as(i, ""cate"") : 
  no method or default for coercing “list” to “cate”
Là sao ạ? Mong anh/chị chỉ giúp em @@?","2016-09-14T04:58:48+0000","status",NA,"472656846222343_660583454096347",NA,0,1,0
"1530258666992232","Namlun Didong","Thư tạm biệt

Vì lý do cá nhân, mình sẽ phải đóng tài khoản FB và do đó không thể tiếp tục trao đổi cùng các bạn trong nhóm nữa.Sau khi mình đóng tài khoản thì 2 chuyện sau đây sẽ xảy ra: 1) Tất cả những bài mình đã đăng tại đây và toàn bộ comment mình đã viết sẽ biến mất (như khi thầy NV Tuấn đã làm). 2) Mình không thể đọc những gì các bạn viết trong tương lai và cũng sẽ không còn quyền truy nhập vào group này để đăng bài, dù với 1 account khác.

Do đó trong 1 tuần nữa các bạn có thể tranh thủ download và ghi lại những bài mình đã chia sẻ trong group hay trang cá nhân, sau đó các bạn có toàn quyền sử dụng, phân phối, chia sẻ chúng tại đây hay bất cứ nơi nào khác, không cần hỏi mình.

Mình sẽ sớm tạo 1 trang blog cá nhân để tiếp tục chia sẻ bài giảng và tài liệu trong những dự án về R như Bayes, Machine learning... Những tài liệu này có thể được tải về và đăng lại tại đây. Không cần hỏi ý kiến.

Email và googledrive của mình vẫn hoạt động bình thường.

Chân thành cáo lỗi với các bạn, mong các bạn thông cảm và chúc các bạn nhiều thành công.

BS. Nam (AKA Namlundidong,Lê Ngọc Khả Nhi)","2016-09-16T08:33:09+0000","status",NA,"472656846222343_661613967326629",NA,107,37,3
"1530258666992232","Namlun Didong","Tựa sách mới nhất (cũng là cuốn đắt tiền nhất) trong series ""Studies in Classification, Data Analysis, and Knowledge Organization"" 

(Các bạn biết tìm nó ở đâu rồi nha).","2016-08-09T13:11:11+0000","photo","https://www.facebook.com/photo.php?fbid=1262651880419580&set=gm.642904085864284&type=3","472656846222343_642904085864284",NA,112,19,19
"1249192251823862","Kevin Nguyen Vo","Tất cả bài viết và Files của anh Nam, mọi người có thể download tại đây:

https://www.dropbox.com/s/9cwsm3hi7nnox4i/namlundidong.html?dl=0

Cám ơn anh Nam Namlun Didong vì đã chia sẽ kiến thức nhiều cho group. Chúc anh nhiều sức khoẻ và thành công.","2016-09-16T10:52:28+0000","link","https://www.dropbox.com/s/9cwsm3hi7nnox4i/namlundidong.html?dl=0","472656846222343_661657653988927",NA,76,6,11
"10154630775082982","Duy Thọ Nguyễn","ggplot2, reshape, tidyr, dplyr, purrr ... và ... RStudio. Có lẽ không phải giới thiệu nhiều nữa. Trong danh sách câu hỏi được đặt ra trên Quora thấy có nhiều câu hỏi thú vị mà nhiều người sẽ quan tâm. Hadley sẽ trả lời vào ngày 20/9.  
","2016-09-14T00:39:35+0000","link","https://www.quora.com/session/Hadley-Wickham/1?srid=uqCJ","472656846222343_660506404104052",NA,15,2,0
"1354928117900253","Chương Văn","[Tãn mạn] Làm thế nào để trở thành 1 nhà khoa học dữ liệu ?
Một bài viết rất hay dành cho những bạn đam mê và đang kiên trì trên con đường này :)","2016-09-14T06:55:12+0000","link","http://www.phantichkinhte123.com/2016/04/lam-nao-e-tro-thanh-mot-nha-khoa-hoc-du.html","472656846222343_660621950759164",NA,9,0,1
"1814941822089228","Vũ Hoài Nam","Xin chào mn, mình mới gia nhập nhóm 
Khi lưu script, mình bị lỗi ntn, kb lỗi như này khắc phục ntn nhỉ? mình cảm ơn :D","2016-08-31T13:08:22+0000","photo","https://www.facebook.com/photo.php?fbid=1728090087441069&set=gm.653556554799037&type=3","472656846222343_653556554799037",NA,6,2,0
"1245895802184304","Dinh Tien Tai","Xin chào mọi người. Mình dùng facet_wrap() để làm biểu đồ cho 5 biến liên tục và muốn điều chỉnh y-axis riêng biệt cho từng panel, nhưng chưa biết phải làm thế nào. Xin mọi người góp ý ạ.","2016-09-01T08:18:52+0000","status",NA,"472656846222343_653977598090266",NA,5,1,0
"10208314748176383","Le Manh Hung","mình bị lỗi như này: khi đọc text file 
""
Warning message:
In readLines(""VietnamSCRdrought.txt"") :
  incomplete final line found on 'VietnamSCRdrought.txt'
""
Có ai biết cách khắc phục như nào không ạ? Xin cảm ơn

Link file: https://drive.google.com/open?id=0B6ZINDS0znc5ajFfQ2VTRTl0cXc

Code của mình: 
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
file = readLines(""VietnamSCRdrought.txt"")","2016-08-27T16:17:57+0000","link","https://drive.google.com/open?id=0B6ZINDS0znc5ajFfQ2VTRTl0cXc","472656846222343_651671134987579",NA,0,2,0
"10207877287919574","Hung Vu","Em chưa hiểu nhiều về thống kê nên đang có thắc mắc về khoảng tin cậy 95% (95% Confidence Interval) em cũng đã tìm hiểu và thấy có thể tính CI bằng t.test(x) và cách khác cũng thì dùng quantile(x, prob=c(0.025, 0.50, 0.975)), tính bằng upper95 và lower95=mean±1.96xSD. Nhưng kết quả từ số liệu của mình lại khác nhau. Mong cả nhà chỉ điểm cho ah. Thanks","2016-08-26T02:15:50+0000","status",NA,"472656846222343_650876651733694",NA,5,9,2
"1530258666992232","Namlun Didong","Quy trình Bootstrap:

1) Chuẩn bị câu hỏi dưới dạng 1 function
2) Triệu hồi thần may mắn
3) Đặt câu hỏi cho nữ thần
4) Chờ đợi câu trả lời

","2016-08-24T20:23:20+0000","link","https://drive.google.com/open?id=0B1vaOU1uB8DPMS1SUXFkcmZKNmc","472656846222343_650259655128727",NA,51,7,1
"10212790460500196","Hoang Viet Anh","Thêm một nguồn để kiếm số liệu

","2016-08-27T03:57:59+0000","link","https://datasearch.elsevier.com/","472656846222343_651408991680460",NA,11,7,2
"10202824185922593","Long Dang","http://www.computerworld.com/article/2497464/business-intelligence/business-intelligence-60-r-resources-to-improve-your-data-skills.html#tk.drr_mlt","2016-08-27T00:11:22+0000","link","http://www.computerworld.com/article/2497464/business-intelligence/business-intelligence-60-r-resources-to-improve-your-data-skills.html#tk.drr_mlt","472656846222343_651344861686873",NA,5,0,1
"1530258666992232","Namlun Didong","Bạn đang ở đâu trên giản đồ Conway ?

Năm 2010, Drew Conway vẽ giản đồ sau đây để mô tả ý tưởng liên hệ giữa 3 lĩnh vực: (1) Chuyên môn, (2) Lập trình - dữ liệu và (3) Toán - Thống kê. Biểu đồ này còn cho phép chúng ta phân ra 7 vùng và xác định 7 loại ""khoa học gia"" tương ứng với mỗi vùng:

Vùng 1: Những người chỉ có duy nhất kiến thức và kĩ năng trong chuyên ngành của mình. Thí dụ 1 bác sĩ lâm sàng có kiến thức sinh lý bệnh học uyên thâm, kỹ năng khám, phẫu thuật xuất sắc. Tuy nhiên ông ta không biết gì về thống kê học, và không có khả năng sử dụng bất cứ phần mềm, công cụ phân tích dữ liệu nào.

Vùng này đông hơn các bạn tưởng, bên trong nó chứa rất nhiều chuyên gia, giáo sư, trưởng khoa, kỹ sư ... thậm chí những người có quyền lực rất cao về học thuật.

Vùng 2: Những kẻ mệnh danh là Hacker máy tính, họ nói chuyện với máy tính bằng các dòng lệnh, thông thạo ít nhất 1 ngôn ngữ lập trình, có tư duy giải quyết vấn đề theo thuật toán, sơ đồ, giỏi khai thác dữ liệu nhưng KHÔNG có bất cứ kiến thức nào về Thống kê học lẫn chuyên môn

Sự giao thoa giữa vùng 1 và 2 tạo ra 1 vùng rất nguy hiểm số 4: Những kẻ trong vùng này ngộ nhận là mình đã có khả năng phân tích dữ liệu và vì có kiến thức chuyên ngành, họ sẽ dễ dàng thiết kế nghiên cứu, thu thập số liệu, bật máy tính lên và chạy 1 phần mềm thống kê và cho ra kết quả ngon lành, nhưng vì không có kiến thức thống kê, họ sẽ chọn sai phương pháp và diễn đạt bậy bạ kết quả. Nguy hiểm hơn khi họ dùng quyền lực và uy tín học thuật của mình để công bố kết quả nghiên cứu và đánh lừa thiên hạ...

Nếu bạn cảm nhận mình đang nằm trong vùng này, hãy cẩn trọng và nên học thêm về thống kê hoặc tư vấn chuyên viên thống kê khi làm nghiên cứu.

Vùng số 3 gồm những người học thống kê một cách bài bản như 1 nhánh của Toán ứng dụng, họ hiểu các khái niệm về xác suất, mô hình, thuật toán thống kê và biết cách thực hiện cũng như diễn giải chúng... Tuy nhiên dù giỏi đến đâu thì sức người vẫn có hạn... một ngày nào đó những nhà thống kê học sẽ đối diện vấn đề phức tạp đến mức họ không thể hình dung ra phương pháp giải quyết. Lúc này thế mạnh của vùng số 6 mới được chú ý: Vùng số 6 biểu thị cho sự giao thoa giữa Toán, thống kê, khoa học máy tính, lập trình và dữ liệu, một cách tổng quát, độc lập với chuyên ngành khác. Vùng này chính là thứ được gọi là Machine Learning.

Giao thoa giữa vùng số 1 và số 3 = vùng 5 chính là phần lớn thế giới học thuật truyền thống mà ta từng biết từ hàng trăm năm nay, nơi tập trung hầu hết các nghiên cứu sinh, thạc sĩ, tiến sĩ, giáo sư, ... các nhà khoa học chân chính vừa giỏi chuyên môn vừa có tư duy kiến thức về thống kê. Nếu bạn đang ở trong vùng số 5 này, đó là điều rất tốt; nhưng chưa đủ... vì khi không giỏi về thao tác lập trình và sử dụng máy tính, bạn không có khả năng tự thực hiện những ý tưởng, giả thuyết của mình mà phải phụ thuộc vào chuyên viên phân tích dữ liệu bên ngoài (những người ở vùng 2,4 hoặc 6)

Nếu bạn có đầy đủ cả 3 đặc tính: giỏi chuyên môn, giỏi thống kê, và giỏi lập trình: Bạn đã trở thành chuyên viên khoa học dữ liệu (vùng 7).","2016-07-14T19:35:53+0000","photo","https://www.facebook.com/photo.php?fbid=1242110732473695&set=gm.631005867054106&type=3","472656846222343_631005867054106",NA,124,15,66
"1530258666992232","Namlun Didong","Case study 17: Mục tiêu nghiên cứu: Phân loại nguy cơ của nhồi máu cơ tim dựa vào 5 tiêu chí :Tuổi, Mức Cholesterol máu : Thấp, TB, cao, Thói quen hút thuốc lá, Trình độ học vấn, Trạng thái cân nặng: bình thường/Cao. Trên một mẫu 1004 trường hợp
Chúng tôi ứng dụng mô hình cây với algorithm CART, kiểm chứng chéo 10x10 trên 80% dataset và kiểm định độc lập trên 20% còn lại
Mô hình kết quả có hiệu năng cao (95%CI độ chính xác từ 80.9 - 90.3%).
Kết luận: 
Mô hình cây phân loại (algorithm CART) là một phương pháp hữu ích cho nghiên cứu, thực hành y học: Nên phổ biến nó cho nhiều đồng nghiệp biết và ứng dụng vào thực tiễn ngay từ bây giờ
Kiểm chứng chéo cho phép tối ưu hóa hiệu năng của mô hình phân loại: Nên nghĩ đến phương pháp này khi xây dựng thiết kế nghiên cứu
Caret là 1 công cụ rất hữu dụng: Nên sử dụng caret làm giao thức để thực hành Machine learning
R mạnh và linh hoạt hơn rất nhiều so với các gói công cụ thống kê thương mại khác: Hãy học và dùng R nhiều hơn","2016-08-19T13:42:56+0000","photo","https://www.facebook.com/photo.php?fbid=1272837316067703&set=gm.647652595389433&type=3","472656846222343_647652595389433",NA,37,9,4
"1310556829011267","Trần Trọng Khải","Anh chị chỉ em với ạ.
Em muốn vẽ hình cấp phối hạt như bên dưới với R.
Với:
x=c(0, 0.002994, 0.003336, 0.00384, 0.004687, 0.006607, 0.009313, 0.022428, 0.034595, 0.046563, 0.059192, 0.063, 0.125, 0.25, 0.5, 1, 2)
y=c(0, 3.399694, 4.079633, 4.079633, 4.419602, 4.759572, 5.439511, 7.479327, 10.19908, 15.63859, 25.83768, 91.90929, 99.0305, 99.23825, 99.35367, 99.48063, 100)
Cách vẽ chi tiết thế nào ạ?","2016-08-25T08:40:01+0000","photo","https://www.facebook.com/photo.php?fbid=1132029526863999&set=gm.650507111770648&type=3","472656846222343_650507111770648",NA,4,2,2
"1530258666992232","Namlun Didong","Tuyệt, mới nhắc đến cây là sáng nay cây mọc lên rào rào trên Rbloggers. 

Package mới huấn luyện mô hình cây, cú pháp dễ như ăn kẹo. 

Không sâu bằng caret nhưng các bác sĩ có thể sử dụng dễ dàng hơn...

https://cran.rstudio.com/web/packages/FFTrees/index.html","2016-08-20T08:23:50+0000","photo","https://www.facebook.com/photo.php?fbid=1273692269315541&set=gm.648043288683697&type=3","472656846222343_648043288683697",NA,38,2,5
"1217928131648557","Hiệu Nguyễn","Dear all,
Nhờ anh, chị giúp giùm em lỗi này ạ.
Em lập phương trình tương quan giữa biến y và biến x theo, nó báo lỗi này ạ, mọi người giúp giùm em sửa lỗi này nhé.

""Error in nls(y ~ a * (1 - exp((-b * x)/a)), start = c(a = 1, b = 1)) : 
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562""

Cảm ơn mọi người nhiều, chúc mọi người một ngày làm việc vui vẻ.

Đây là phần code
> y<-c(12.00, 19.77, 41.89, 34.94,  9.18, 13.41, 29.18, 46.59, 38.47,  9.88,  8.47, 14.82, 36.53, 36.00,  8.47,  4.94,  9.18, 34.94, 31.77,  4.94)

> x<-c(0.01059, 0.01759, 0.04780, 0.04017, 0.00721, 0.01556, 0.02589, 0.05857, 0.04706, 0.01002, 0.00749, 0.01277, 0.04116, 0.03602, 0.00559, 0.00650, 0.01093, 0.03843, 0.03292, 0.00469)

> m<-nls(y~a * (1 - exp((-b * x)/a)),start=c(a=1,b=1))","2016-08-23T01:17:25+0000","status",NA,"472656846222343_649405435214149",NA,0,1,0
"10208725271269151","Dung Nguyen Chi","Sách hay

Cuốn Data Mining Applications with R là một tập hợp các research papers. Cái hay của nó là có cả Rcode lẫn data cho chúng ta thực hành.","2016-08-19T11:41:49+0000","photo","https://www.facebook.com/photo.php?fbid=10207154831129129&set=gm.647589392062420&type=3","472656846222343_647589392062420",NA,96,3,15
"10155121101283216","Nguyễn Hữu Đại","Tản mạn - ","2016-08-21T03:03:48+0000","link","http://tiasang.com.vn/Default.aspx?tabid=111&CategoryID=2&News=9931","472656846222343_648455258642500",NA,8,0,0
"10208725271269151","Dung Nguyen Chi","Hôm trước anh Namlun Didong làm cái mô hình cây. Em bổ sung thêm ít gia vị cho nó..đẹp. Mấy cái Graph với ggplot2 thì lung linh quá. Thành thử sơ đồ cây so với nó thì cứ như cho Thị Nở đứng cạnh Ngọc Trinh. Nên em vẽ lại: 

http://rpubs.com/chidungkt/203171","2016-08-20T14:23:25+0000","photo","https://www.facebook.com/photo.php?fbid=10207162507761040&set=gm.648159485338744&type=3","472656846222343_648159485338744",NA,29,2,1
"10208314748176383","Le Manh Hung","Mọi người cho hỏi lỗi phông chữ như này thì sửa kiểu gì, xin cảm ơn","2016-08-19T18:02:37+0000","photo","https://www.facebook.com/photo.php?fbid=10206813190918390&set=gm.647756032045756&type=3","472656846222343_647756032045756",NA,0,0,0
"1590214037658597","Phuc Nguyen Quang","Thống kê xã hội học

Chào các anh/chị/bạn

Mình là dân kỹ thuật muốn tìm hiểu những nghiên cứu về xã hội học, ví dụ như phương pháp sử dụng bảng câu hỏi Likert khảo sát, đánh giá,...
Bạn nào có tài liệu hướng dẫn sử dụng và các ví dụ mẫu trên SPSS hoặc Minitab cho mình xin nhé, mình rất gà món này.
Chân thành cảm ơn.","2016-08-18T14:09:24+0000","status",NA,"472656846222343_647206475434045",NA,2,1,0
"10207877287919574","Hung Vu","Chào cả nhà, mình là thành viên mới. Hiện mình đang tìm hiểu về R và thấy khá thú vị. Mình đang muốn kiểm định sự khác biệt giữa 3 quần xã (có thành phần loài và số lượng cá thể loài), bạn nào biết cách so sánh (post hoc) trong R thì chỉ giáo mình nhé. Thanks","2016-08-16T23:21:47+0000","status",NA,"472656846222343_646451988842827",NA,6,3,0
"1412242695487170","Linh Pham","Cả nhà cho mình hỏi một chút về adjust legend trong plot với.
Mình đang dùng lệnh plot để vẽ line graphs, tuy nhiên khi add legend vào thì 
+ hoặc là legend vào đúng vị trí bottom right như mình mong muốn nhưng chữ lại quá nhỏ không nhìn thấy gì
+ hoặc nếu chữ nhìn được thì legend frame lại phình to ra và chen vào graph.
như 2 attached images. 
Mình muốn legend vào vị trí bottom right trong ô màu đỏ và chữ to và nhìn được. Mong mọi người sửa code giúp mình với, mình để link download data và code phía dưới.
http://www.mediafire.com/download/445w5u87ye4gcw9/plot_question.rar
Thank mọi người nhiều!","2016-08-16T12:25:59+0000","photo","https://www.facebook.com/photo.php?fbid=1209845875726854&set=gm.646227395531953&type=3","472656846222343_646227395531953",NA,4,3,0
"1530258666992232","Namlun Didong","Thêm 1 trick mới trên ggplot2, mới học được sáng nay","2016-08-15T22:41:06+0000","photo","https://www.facebook.com/photo.php?fbid=1269159966435438&set=gm.645959632225396&type=3","472656846222343_645959632225396",NA,42,5,3
"1916473528585841","Tue Nguyen","[Cài đặt Rattle] Mọi người cho mình hỏi lỗi này với.
Mình cài mấy lần mà nó cứ báo lỗi  ""cannot open compressed file 'RGtk2/DESCRIPTION', probable reason 'No such file or directory' ""
Cám ơn mọi người nhiều","2016-08-16T14:54:21+0000","photo","https://www.facebook.com/photo.php?fbid=1819392244960637&set=gm.646289755525717&type=3","472656846222343_646289755525717",NA,0,1,0
"10208725271269151","Dung Nguyen Chi","Bỏ đi 18 trong số 61 biến số chất lượng dự báo của mô hình tăng lên. Hai loại biến số ""xấu"" được bỏ là: 

1. Biến có phương sai 0 hoặc gần không. 
2. Biến tương quan cao trên 0.7. 

","2016-08-14T13:18:04+0000","link","http://rpubs.com/chidungkt/201889","472656846222343_645297442291615",NA,23,7,0
"10208915968716100","Tran Ngoc Dang","Giới thiệu bài giảng mới ""P value và suy diễn Bayesian""
https://www.youtube.com/watch?v=Mgr9WASTZE0&feature=youtu.be
“Thống kê như một cô gái mặc bikini, cái mà cô ta phơi ra thì rất hấp dẫn nhưng cái mà cô ta che đậy mới quan trọng…” Bài giảng này sẽ giúp các bạn biết được P value là gì và các bí mật của nó. Cũng như sự khác nhau giữa trường phái tần số (dựa vào p value) và trường phái Bayesian. Bài giảng hơi dài nhưng là tổng hợp những điều cơ bản nhất của 2 trường phái này.","2016-08-15T10:43:27+0000","link","http://www.ohri.ca/newsroom/seminars/SeminarUploads/1829%5CSuggested%20Reading%20-%20Nov%203,%202014.pdf","472656846222343_645698552251504",NA,44,3,1
"1530258666992232","Namlun Didong","Case study đầu tiên trong dự án MLM, cái này đơn giản nhưng được đào khá sâu.

dataset ở đây: https://drive.google.com/open?id=0B1vaOU1uB8DPeHpOTGlxUUZmNnc

Hướng dẫn ở đây:
https://drive.google.com/open?id=0B1vaOU1uB8DPNkZZUnJMWERLS3c","2016-08-14T14:11:38+0000","photo","https://www.facebook.com/photo.php?fbid=1267736463244455&set=gm.645321695622523&type=3","472656846222343_645321695622523",NA,44,3,7
"10208725271269151","Dung Nguyen Chi","Support Vector Machine - SVM là một mô hình phân loại mạnh. Bài viết này thực hiện so sánh chất lượng dự báo – phân loại của mô hình này với mô hình phân loại truyền thống Logistic.

Số liệu sử dụng là GermanCredit được lưu trữ tại University of California, Irvine. Đây là dữ liệu về thông tin xin cấp tín dụng của 1000 khách hàng. Các hồ sơ sẽ được dán nhãn là Bad hoặc Good ( tương ứng với hồ sơ xấu và tốt, biến Class) để từ đó ngân hàng ra quyết định cho vay dựa vào các thông tin khác như thu nhập, tuổi tác, tình trạng công việc và một loạt thông tin khác.

Tiêu chí để đánh giá chất lượng của hai mô hình là Accuracy và Kappa. Mô hình nào có những giá trị này cao hơn là mô hình tốt hơn trong phân loại. Tác giả thực hiện chạy 60 lần cho mỗi mô hình bằng phương pháp k-fold cross-validation với k = 10 và lặp lại vòng này 6 lần. Sử dụng các thông tin thu được từ 60 mô hình con này để đánh giá hai tiêu chí trên theo Bonferroni correction (tương tự kiểm định t) nhằm đưa ra bằng chứng thống kê cho sự khác biệt trong chất lượng dự báo – phân loại của hai mô hình.

","2016-08-13T01:11:39+0000","link","http://rpubs.com/chidungkt/201866","472656846222343_644652885689404",NA,31,1,0
"793086327525661","Trần Quý","Mọi người ơi, cho mình hỏi khi đọc data vào R. Nếu data mình có dấu tiếng việt thì làm sao để R đọc được vậy mọi người??? Mình toàn bị lỗi front khi đọc data có dấu tiếng Việt.","2016-08-11T08:33:05+0000","status",NA,"472656846222343_643809585773734",NA,2,6,1
"10208725271269151","Dung Nguyen Chi","Đổi tên biến số. 

Chào các bạn. Mình muốn đổi 4 biến số (ứng với 4 cột đầu tiên của bộ số liệu iris ) thành từ V1 đến V4. Nhưng code sau đây (như trong hình) là không hoạt động. Câu hỏi là: 

1. Sử code này như thế nào? 
2. Có cách nào khác thực hiện việc đó? 

Cảm ơn các bạn nhiều lắm.","2016-08-12T12:21:34+0000","photo","https://www.facebook.com/photo.php?fbid=10207104477430318&set=gm.644392052382154&type=3","472656846222343_644392052382154",NA,10,4,0
"10208725271269151","Dung Nguyen Chi","Data Mining with Rattle and R

Với những ai còn lưu luyến với kiểu giao diện cửa sổ của những phần mềm thương mại truyền thống như SPSS, STATA và bắt đầu thực hành Data Mining, Machine Learning, Statistics thì gói Rattle -  tương tự Rcommander -  là một lựa chọn tốt: tất cả các phân tích đều được thực hiện ở giao diện cửa sổ. Hiện tại, nó cung cấp các phân tích và mô hình sau: 

1. Regression, Support Vector Machine, Random Forest, Neutral Networks, Bagging...
2. Kmeans, Hierarchical...
3. Các test phổ biến
4. Và nhiều thứ khác.

Khá tiện dụng vì chúng ta có thể thực hiện được ĐỒNG THỜI hoặc LẦN LƯỢT nhiều mô hình khác nhau và so sánh giữa chúng với nhau dựa trên các tiêu chí như ROC, Accuracy...

http://www.springer.com/us/book/9781441998897","2016-08-11T07:50:20+0000","photo","https://www.facebook.com/photo.php?fbid=10207096106301045&set=gm.643798052441554&type=3","472656846222343_643798052441554",NA,56,4,7
"1102544753188585","Hung Nguyen","Xin hỏi anh/chị nào có tài liệu hướng dẫn về phân tích dự báo tình hình dịch bệnh hay vẽ đường ngưỡng cảnh báo dịch bằng R (hoặc các  phần mềm khác) không ạ","2016-08-09T13:30:17+0000","status",NA,"472656846222343_642909449197081",NA,0,0,0
"10208725271269151","Dung Nguyen Chi","KNN vs. Logistic: Tình huống nghiên cứu với bộ số liệu Caravan  

###############################################################

Trong bài viết trước (http://www.mediafire.com/download/cy7ywdyy84dtcyg/KNNvsLogistic.pdf) , biến được phân loại là Class có hai giá trị là Good và Bad. Good chiếm 70% và Bad là 30%. Có thể nói sự kiện một hồ sơ được phân loại là Bad không hiếm. Với bộ số liệu này kết quả chỉ ra rằng mức độ phân loại của mô hình Logistic là tốt hơn. 

Tuy nhiên, theo James et al. (2013), mức độ chính xác trong phân loại của các mô hình là nhạy sự bất đối xứng của biến được phân loại. Để làm sáng tỏ điều này chúng ta xét bộ dữ liệu Caravan được tích hợp cùng gói ISLR. Biến được phân loại ở đây là Purchase trong đó quan sát sẽ được xếp là Yes nếu anh ta mua sản phẩm bảo hiểm Caravan – một kiểu sản phẩm bảo hiểm mà rất ít người mua, và sẽ được xếp là No nếu ngược lại. Vì là một sản phẩm bảo hiểm mà rất ít người mua nên số người mua sản phẩm này chỉ xấp xỉ 6% trong khi số người không mua là 94%. Tình huống này, biến Purchase được nói là có sự bất đối xứng cao giữa hai cấp độ (Yes và No). 

Với những bộ dữ liệu như thế, các bằng chứng thực nghiệm cho thấy rằng KNN sẽ là mô hình phân loại tốt hơn Logistic. 
Bài viết dưới đây tạp một vòng lặp 50 lần để đưa ra bằng chứng thống kê chỉ ra rằng có sự khác biệt về mức độ chính xác trong phân loại của hai cách tiếp cận với thống kê t. 

http://www.mediafire.com/download/2lmmfgl9i0zcj8t/KNNvsLogisticCaravan.pdf

PS. Tranh thủ chờ ăn sáng. :v","2016-08-06T00:08:29+0000","photo","https://www.facebook.com/photo.php?fbid=10207059618908883&set=gm.641171589370867&type=3","472656846222343_641171589370867",NA,23,4,8
"1398499446838965","Duong Duc Pham","Chào cả nhà
Tôi có một dataset với 7 biến (trong đó biến X7 là biến với số nguyên trong khoảng từ 1 đến 6) ==Dataset 1
Tôi muốn chọn mỗi hàng với số cột từ 1 đến giá trị X7 của hàng đó (VD. row1 X7=3--> chọn giá trị ở cột X1, X2, X3) để tạo Dataset 2 
Tôi muốn dùng for loop function với code tương tự như sau:
data2<-NULL
for(i in 1:nrow(data)){
     n<-data[i,7]
     print(data2[i]<-data[i,c(1:n)])
}
        X1       X2       X3
1 9.373546 13.02356 12.75693
        X1       X2       X3       X4
2 10.18364 10.77969 12.34641 9.588849
        X1       X2
3 9.164371 8.757519
        X1     X2       X3
4 11.59528 5.5706 4.031945
        X1       X2       X3       X4       X5
5 10.32951 12.24986 11.85948 4.491762 6.556222
        X1       X2       X3       X4       X5      X6
6 9.179532 9.910133 9.831614 8.340022 6.462524 21.8824
        X1       X2       X3
7 10.48743 9.967619 9.532613
        X1       X2       X3       X4       X5
8 10.73832 11.88767 5.587743 9.762746 13.84266
        X1       X2      X3      X4
9 10.57578 11.64244 8.56555 14.4001
         X1      X2
10 9.694612 11.1878

Làm thế nào để tạo dataset 2 hoàn chỉnh giống trong ảnh?

Nhờ ACE có kinh nghiêm chỉ giúp. Trân trọng cảm ơn.
P/S code cho dataset 1
set.seed(1)
X1=rnorm(10,10,1)
X2=rnorm(10,10,2)
X3=rnorm(10,10,3)
X4=rnorm(10,10,4)
X5=rnorm(10,10,5)
X6=rnorm(10,10,6); X7=c(3,4,2,3,5,6,3,5,4,2)
dataset1=data.frame(X1, X2, X3, X4, X5, X6,X7)","2016-08-08T07:28:42+0000","photo","https://www.facebook.com/photo.php?fbid=1200431003312478&set=gm.642292402592119&type=3","472656846222343_642292402592119",NA,1,4,0
"10210845468545723","Vịt Trần","pipeline này mình muốn viết mãi nhưng chẳng bao giờ rành, thôi cứ tập tành từ từ. Gửi các bạn tham khảo.","2016-08-08T14:22:55+0000","link","http://seananderson.ca/2014/09/13/dplyr-intro.html","472656846222343_642416209246405",NA,5,1,0
"1205787479527610","Diệp Phong","Một người bạn đáng để học tập :D","2016-08-08T16:43:04+0000","link","http://blog.revolutionanalytics.com/2016/08/interactive-illustrator-quality-graphics-with-r.html","472656846222343_642463069241719",NA,7,0,0
"10208725271269151","Dung Nguyen Chi","Trong bài viết này, bài viết sẽ so sánh chất lượng phân loại của hai cách tiếp cận KNN và Logistic  căn cứ vào chỉ tiêu Accuracy bằng cách so sánh mean (trung bình) từ 50 trường hợp khác nhau của dữ liệu kiểm định và dữ liệu huấn luyện bằng kiểm định t. Kết quả chỉ ra rằng có sự khác biệt về mức độ chính xác trong phân loại giữa hai mô hình này và chỉ ra kết luận ngược lại: Logistic có khả năng phân loại tốt hơn.  

http://www.mediafire.com/download/cy7ywdyy84dtcyg/KNNvsLogistic.pdf","2016-08-05T16:58:10+0000","photo","https://www.facebook.com/photo.php?fbid=10207057281970461&set=gm.641016556053037&type=3","472656846222343_641016556053037",NA,21,1,3
"10208725271269151","Dung Nguyen Chi","Quá trình tái chọn mẫu khi dùng  gói caret của thánh M. Kuhn: 

","2016-08-07T12:44:33+0000","link","http://rpubs.com/chidungkt/200854","472656846222343_641828745971818",NA,18,1,0
"794006744086825","Lau Tay Nguyen","Chào ACE, tôi đùng ggplot2 vẽ đồ thị như hình đính kèm, nhưng không biết cách để add legend với các shape khác nhau. Nhờ ACE nào biết chỉ giúp, cám ơn.","2016-08-04T02:03:07+0000","photo","https://www.facebook.com/photo.php?fbid=678088589011975&set=gm.640262882795071&type=3","472656846222343_640262882795071",NA,7,6,1
"10208725271269151","Dung Nguyen Chi","Lựa chọn số Notron tối ưu cho mạng ANN

Trong bài viết trước chúng ta đã so sánh khả năng dự báo của ANN và cách tiếp cận truyền thống OLS và đã chỉ ra rằng khả năng dự báo của ANN là tốt hơn khi xét trên cả hai khía cạnh là sai sót huấn luyện và sai sót kiểm định. Phần này chúng ta sẽ khảo sát sự biến đổi của đồng thời sai sót kiểm định và sai sót huấn luyện khi số Notron thay đổi. Chúng ta vẫn sử dụng chính bộ số liệu ở bài viết trước nhưng với ba điều chỉnh nhỏ:

1. Biến phụ thuộc (hay thông tin ra) là prate, tất cả các biến còn lại là biến độc lập (hay số biến đầu vào). Như vậy số lượng biến đầu vào là 7.

2. Để tiết kiệm thời gian tính toán cho máy tính tôi chỉ chọn 500 quan sát và phân chia theo tỉ lệ 70 : 30 cho bộ số liệu huấn luyện và kiểm định.

3. Số Hidden Layer lựa chọn là 1.

Số Notron ở mỗi lớp ẩn (Hidden Layer) là nhân tố ảnh hưởng đến chất lượng của Artifical Neutral Network (ANN). Khi xây dựng ANN chúng ta thường cố gắng tìm kiếm số Notron sao cho, chẳng hạn, sai sót huấn luyện và sai sót kiểm định đồng thời thấp nhất có thể được. Trong một số tình huống, chẳng hạn với mục đích là dự báo thì chúng ta có thể thể ưu tiên cho sai số kiểm định hơn. Các nghiên cứu thực chứng cũng như lý thuyết đã chỉ ra rằng số Notron tối ưu là một số nguyên nằm đâu đó từ 1 và số lượng biến thông tin đầu vào. Như vậy với những giả thiết vừa mô tả ở trên thì số Notron nằm trong đoạn từ 1 đến 7.

Có thể thấy xu hướng chung là cả hai loại sai sót này giảm khi số Notron tăng. Tuy nhiên cần lưu ý là khi tăng số Notron thì cái giá phải trả về mặt thời gian là rất đắt. Hơn nữa trong tình huống của chúng ta cả hai tỉ lệ sai sót giảm không đáng kể khi số Notron tăng từ 4 đến 7. Do vậy, với điều kiện máy tính cùi tốc độ chậm chúng ta nên chọn số Notron tối ưu là 3 là có thể cân bằng được tất cả các yếu tố : thời gian, các tỉ lệ sai sót thấp. 

http://www.mediafire.com/download/wl5sj6kauc5gv4y/S%E1%BB%91_Notron_cho_m%E1%BA%A1ng_ANN.pdf","2016-08-04T04:33:26+0000","photo","https://www.facebook.com/photo.php?fbid=10207047374922791&set=gm.640309926123700&type=3","472656846222343_640309926123700",NA,23,3,1
"10208725271269151","Dung Nguyen Chi","Chào  các bạn, 

Mình chạy một vòng lặp 10 lần, và cứ mỗi lần mình có một  data frame có ba biến cố định là x,y, và z với chỉ 1 quan sát (tức là data frame kích thước 1 nhân 3 theo kiểu ngôn ngữ ma trận). Làm thế nào để mình ""cộng""  tất cả 10 data frame này thành một data frame duy nhất có ba biến số x,y, và z với 10 quan sát? 

Mấu chốt ở đây có lẽ là tạo một data frame trống thì phải. 

Cảm ơn câu trả lời của mọi người ạ.","2016-08-05T15:09:12+0000","status",NA,"472656846222343_640977779390248",NA,5,3,0
"10208725271269151","Dung Nguyen Chi","Tỉ lệ người tham gia quỹ lương hưu - so sánh khả năng dự báo của OLS với Artificial Neural Network với data từ nghiên cứu của Papke & Poterba (1995): 

","2016-08-03T09:11:44+0000","link","http://rpubs.com/chidungkt/200116","472656846222343_639945886160104",NA,13,1,1
"10208357389116300","Nguyen Le Xuan Bach","Giải trí cuối tuần. Gởi cả mọi cùng test thử công cụ BERT này. Công cụ này giúp đem R vào sử dụng chung với Excel.
Từ đây ta có thể nhập liệu từ R vào Excel và ngược lại.
Vẽ đồ thị ggplot2 trực tiếp từ các cột trong Excel
Ngoài ra ta có thể dùng R để viết các hàm mới, và dùng trực tiếp hàm trong Excel cho bảng tính của mình (đỡ phải dùng VBA).
Tìm hiểu tại link: ","2016-07-30T02:03:33+0000","link","https://bert-toolkit.com/","472656846222343_637855393035820",NA,43,4,0
"1530258666992232","Namlun Didong","Gửi các bạn bài thực hành số 6 trong series Caret: Data Preprocessing (hay transformation). Có kèm hướng dẫn làm maki sushi.","2016-07-31T17:53:22+0000","photo","https://www.facebook.com/photo.php?fbid=1255221661162602&set=gm.638665569621469&type=3","472656846222343_638665569621469",NA,45,4,5
"1310556829011267","Trần Trọng Khải","quý thầy cô, anh chị chỉ bảo em với ạ.

nếu em xây dựng một mô hình hồi quy đa biến thì cơ sở nào để em xác định số mẫu cần khảo sát. em có thể dẫn nguồn tài liệu nào để bài viết có cơ sở ạ.

em đọc đâu đó thì tác giả viết cứ thêm 1 biến thì cần thêm 10 mẫu. nhưng em quên tài liệu đó mất rồi.

em xin cảm ơn quý thầy cô, anh chị ạ.","2016-07-25T23:17:13+0000","status",NA,"472656846222343_636007039887322",NA,7,6,1
"602628663279498","Jim Hurts","Chào cả nhà, 
Hiện tại em đang cần vẽ biểu đồ Particle-size distribution, tuy nhiên, em chỉ vẽ được 50% biểu đồ (vẽ được trục x (ECD stage), hình bên trái) so với biểu đồ hình bên phải với công cụ R. Anh chị nào từng có kinh nghiệm vẽ (bằng R hay Excel hay phần mềm nào khác có thể), rất mong anh chị hướng dẫn.
Dữ liệu:
Trục x (ECD satge (µm)): 5.9, 4.8, 3.6, 2.1, 1.1, 0.46, 0.31 
lần lượt với: 
Trục y (Cumulative Weight (%)): 100%, 89.55%, 76.12%, 59.70%, 40.30%, 23.88%, 10.45%
và MMAD = 1.40 µm (tại 50%)
Em cảm ơn mọi người rất rất nhiều.","2016-07-30T05:35:35+0000","photo","https://www.facebook.com/photo.php?fbid=511368649072167&set=gm.637910289696997&type=3","472656846222343_637910289696997",NA,2,1,0
"1600062113344015","Minh Nam Nguyen","Em chào cả nhà. Cho em hỏi cách dùng facet trong package survival với ạ?","2016-07-28T05:30:10+0000","status",NA,"472656846222343_637008913120468",NA,1,0,0
"1253920847996458","Alon Tran","Em đang sử dụng ggplot2, geom-bar và geom_errorbar, anh chị nào biết packages nào chạy cùng với ggplot2 có thể fill cho bars bằng textiles (hoặc patterns) thay vì fill bằng colors. Em sử sụng scale-fill-brewers(grays) nhưng thấy chưa ổn lắm.","2016-06-17T12:14:09+0000","photo","https://www.facebook.com/photo.php?fbid=1002009019854310&set=gm.618851621602864&type=3","472656846222343_618851621602864",NA,3,3,0
"1863450633902607","Jung Nguyen","Chào cả nhà, em đang  vẽ psychometric curve cho số liệu, tuy nhiên vẫn chưa tìm ra cách vẽ. Anh chị nào từng có kinh nghiệm vẽ psychometric curve (bằng R hay Excel hay phần mềm nào khác có thể), rất mong anh chị hướng dẫn. Cái hình em cần cũng tương tự như hình đình kèm. Trục y = percent correct, trục x = intensity level. Yều cầu của hình là một figure cho 6 curves (mỗi curve là một word stimulus. Facebook không kèm được excel file nên em chỉ kèm một ít để cho dễ hình dung. Rất cần cả nhà giúp. Xin cảm ơn rất rất nhiều. Quốc Dũng","2016-07-26T18:09:06+0000","photo","https://www.facebook.com/photo.php?fbid=1759686660945672&set=gm.636347576519935&type=3","472656846222343_636347576519935",NA,4,1,1
"10208357389116300","Nguyen Le Xuan Bach","Xin chào cả nhà, xin giới thiệu package ""docxtractr"" dùng để trích các table từ file word vào R khi cần nhé","2016-07-26T02:37:33+0000","link","http://rpubs.com/nlxbach/198471","472656846222343_636062899881736",NA,21,4,0
"1407695769272648","VU Ngoc-Hai","Xin chào các anh chị và các bạn. Em có câu hỏi nhờ mọi người giải đáp giúp ạ.
Em đang tìm mối liên quan giữa biến ""Flow2"" và ""Year"", em đã tính được Pearson's coefficient r=0.80 và p=0.001975; và vẽ scatter plot như trong hình. Bây giờ để kết luận flow2 tăng theo year là ""CÓ Ý NGHĨA"" hay không thì em phải tính thêm ""correlation coefficient beta- và p"" phải không ạ? Nếu đúng thì cách tính beta- và p-value này trong R như thế nào ạ?
Mong anh chị và các bạn chia sẻ kinh nghiệm, em cảm ơn rất nhiều :)","2016-07-26T13:12:13+0000","photo","https://www.facebook.com/photo.php?fbid=1145449395497288&set=gm.636242336530459&type=3","472656846222343_636242336530459",NA,4,4,1
"1356519944399387","Lê Khắc Linh","Sắp xếp Bar graph theo thứ tự mong muốn trong ""ggplot 2""
====================================================
- Dear mọi người, em thấy khi vẽ bar graph, ""ggplot 2"" đảo lộn linh tinh thứ tự các tên biến, không theo trình tự sắp xếp như trong file excel, làm sao để mình sắp xếp lại theo ý mình ạ?
- Trong hình, em mong muốn thứ tự sẽ là Toan, Ly, Hoa, Sinh, Van, Su, Dia, nhưng R lại cho kết quả như mọi người thấy.","2016-07-26T11:10:33+0000","photo","https://www.facebook.com/photo.php?fbid=1156125444438839&set=gm.636202466534446&type=3","472656846222343_636202466534446",NA,5,2,2
"1378688192195864","Hoa Ngoc Nguyen","Chào mọi người, em mới tập tọe làm thống kê. E muốn hỏi ý kiến của các anh chị ạ. Công việc của em là interaction designer (hay nói hẹp hơn là UX designer).

Cho những ai chưa hiểu lắm về ngành này, thì đại loại là tối ưu hóa website, app,... để người dùng có trải nghiệm dễ dàng hơn. Ví dụ đi, một trong những phương pháp đánh giá sản phẩm của mình là làm A/B testing. Làm ra 2 website A và B, chia traffic ra 50-50 cho mỗi website trong một thời gian, thu thập lượng click ""sign up"" (trong trường hợp này lấy lượng click làm KPI), rồi lấy data trả về làm phân tích xem website nào hiệu quả hơn thì mình sẽ quyết định chạy website đó. Đây là 1 ví dụ để mọi người hiểu vì sao ngành thiết kế tương tác lại cần thống kê, phân tích data. Ngoài ra còn có nghiên cứu khách hàng hay nhiều thứ khác trong ngành em cần phân tích data.

Bởi vậy statistical test là rất quan trọng đối với em và em đang tìm hiểu về nó. Nhưng em ko biết bắt đầu từ đâu. Em đã học qua 1 khóa học trên coursera và biết là công việc của mình cần áp dụng những test gì như chi-square test, g-test, fisher test, t-test,... Nhưng học xong em vẫn mơ hồ không biết mình có áp dụng sai test và viết sai công thức ko (thậm chí em còn ko biết test nguyên lí hoạt động như thế nào, trừ pearson chi-square thì em biết công thức) Em cần tìm hiểu thêm gì? Có khóa học nào offline ở ngoài dạy không?

Xin các anh chị cho em một lời khuyên được không ạ? E xin cảm ơn.","2016-07-22T04:43:05+0000","status",NA,"472656846222343_634224453398914",NA,11,6,4
"1620795571268747","Hue Nguyen","Luyện tập R

","2016-07-24T02:07:46+0000","link","http://r-exercises.com/","472656846222343_635073976647295",NA,43,2,0
"1530258666992232","Namlun Didong","Dự án: Machine learning in Medicine using R: tìm đồng đội trợ chiến.

Machine learning in Medicine là một bộ sách hiếm hoi cho phép hình dung được Ứng dụng của Machine learning trong Y học (gồm 7 quyển, trong đó có 3 quyển CookBook thực hành). Mỗi quyền trình bày tới 20 thí dụ, mỗi thí dụ tương ứng với 1 tình huống thực tế và 1 loại algorithm.

Đáng tiếc là toàn bộ thí dụ và phương pháp trong bộ sách này dựa trên nền tảng SPSS, là 1 phần mềm đắt tiền và giới hạn về tính năng.

Mình có ý tưởng mô phỏng và tái hiện lại kết quả trong bộ sách sử dụng R và những gói công cụ thích hợp. Ý tưởng này khả thi (toàn bộ dataset CSV có thể tải về từ ExtraSpringer.com, SPSS syntax viết sẵn cũng có luôn); Công việc mình sẽ làm chỉ là chọn package phù hợp (hay sử dụng caret), viết code cho R và cho thi hành. Tuy nhiên mình không có thời gian nhiều, do đó công việc sẽ trở nên nặng nề khó khăn vô cùng. 

Do đó mình muốn mời gọi sự hợp tác của tất cả các bạn 

1) Là bác sĩ Y khoa hoặc chuyên viên thống kê đang công tác trong các chuyên ngành Y học 

2) Biết sử dụng R

3) Hứng thú với Machine Learning

để cùng trợ chiến trong dự án này. Các bạn nào có hứng thú gia nhập nhóm và phiêu lưu cùng với mình thì xin liên hệ qua mail: bacsinam81@gmail.com hoặc PM. Khi có đủ người chúng ta sẽ chia nhau công việc để làm chung.

Dự án này rất quan trọng đối với mình (hơn cả cuộc phiêu lưu phù phiếm về Bayes mà mình đang làm). Mong các bạn Bác sĩ trẻ yêu khoa học ủng hộ.","2016-07-21T20:57:13+0000","photo","https://www.facebook.com/photo.php?fbid=1247661151918653&set=gm.634084730079553&type=3","472656846222343_634084730079553",NA,70,6,5
"1849942691933972","Nguyen","Kính mong các anh chị ngó nghiêng giúp em vụ này với ạ.

Em có 1 file dữ liệu excel vừa download được từ WorldBank. File này gồm 2 sheet: Export và Data. 

Tại sheet Data: tổng hợp các indicators của các nước (ví dụ: 5-bank asset concentration/ code: GFDD.OI.06). Giá trị của indicator được sắp sếp theo chuỗi thời gian.

Tại sheet Export, em có nhu cầu sắp xếp lại dữ liệu- nhưng dạng panel ạ.
Em có thử hàm index và match trong excel nhưng chưa tìm ra giải pháp. Anh chị có cách thức nào chuyển đổi (bằng R hoặc Excel) trong trường hợp này xin vui lòng chỉ em với ạ.

Em xin cảm ơn mọi người.","2016-07-23T05:41:30+0000","status",NA,"472656846222343_634659080022118",NA,7,3,1
"1530258666992232","Namlun Didong","Springer lại xuất bản sách mới: lần này là về chủ đề Survival analysis. Cuốn này tập trung bàn về phân tích xác suất sự kiện theo thời gian, nó trình bày ngắn gọn lý thuyết về các mô hình nonparametric và parametric, với thí dụ và code thực hành trên R. 

P.S: Xin phép không phổ biến link tải sách tại đây nhé. Nếu nhanh tay các bạn sẽ tìm thấy nó trên http://avxhome.in/ebooks","2016-07-21T09:51:15+0000","photo","https://www.facebook.com/photo.php?fbid=1247265481958220&set=gm.633865346768158&type=3","472656846222343_633865346768158",NA,54,2,12
"1530258666992232","Namlun Didong","Sách mới xuất bản trong tháng nè anh em:

Phương pháp phi tham số trong thống kê Y Sinh, sử dụng R. Sách về R thì rất nhiều nhưng phi tham số thì mới thấy cuốn này là hoàn chỉnh. (Có 1 cuốn khác của John Kloke bên CRC Press publisher năm 2014 nhưng không chi tiết bằng quyển này).

Khoảng 300 trang, nói về tất cả các loại test và mô hình phi tham số.","2016-07-17T13:40:20+0000","photo","https://www.facebook.com/photo.php?fbid=1244277072257061&set=gm.632256410262385&type=3","472656846222343_632256410262385",NA,128,11,15
"1310556829011267","Trần Trọng Khải","Quý thầy cô, anh chị giúp em với ạ.

Bảng số liệu của em gồm 34 biến x và 8 biến y (8 cột cuối trong bảng dữ liệu đính kèm). Biến x có loại liên tục, có loại nhị phân và có loại phân nhóm. Biến y là chi phí điều trị gồm nhiều giá trị 0.

Trước tiên, em xử lý missing value bằng package Hmisc theo như bài http://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/ gợi ý.
Em sử dụng lệnh aregImpute thì được thông báo như vầy:
 
fewer than 3 unique knots.  Frequency table of variable:
x
  1   2  3 
91 37  2 
Error in rcspline.eval(z, knots = parms, nk = nk, inclx = TRUE) : 
In addition: Warning messages:
1: In rcspline.eval(z, knots = parms, nk = nk, inclx = TRUE) :
  could not obtain 3 interior knots with default algorithm.
 Used alternate algorithm to obtain 3 knots
2: In rcspline.eval(z, knots = parms, nk = nk, inclx = TRUE) :
  3 knots requested with 3 unique values of x.  knots set to 1 interior values.

Em chưa rõ trong câu lệnh trên, em chỉ cần liệt kê các biến có NA hay là liệt kê tất cả các biến ạ. Em có thể khắc phục bằng cách nào ạ.

Tiếp đến, do biến y có quá nhiều giá trị 0 nên em được gợi ý sử dụng two-part model để xử lý. Hiện em chưa biết package nào có tính năng cho model này. 

Mong quý thầy cô, anh chị chỉ bảo ạ.","2016-07-21T06:45:33+0000","status",NA,"472656846222343_633817666772926",NA,0,0,2
"10210845468545723","Vịt Trần","Những ai thích chăm chút cho đồ thị của mình, hẳn không thể bỏ qua được gói ggplot2 của Hadley Wickham. So với cuốn sách gốc của Hadley Wickham thì cuốn R graphics Cookbook, nxb O'reilly, tác giả Wiston Chang là một cuốn sách có cách giải thích rất đơn giản và trực tiếp, có thể gọi là một dạng cheetsheet cho ggplot2.

Sách này chắc mọi người cũng đã biết cả rồi, giới thiệu cho những ai chưa có.

Nếu không tìm được bản pdf, mọi người có thể xem trực tiếp trên website của Winston Chang 

""http://www.cookbook-r.com/Graphs/""","2016-07-19T15:32:47+0000","photo","https://www.facebook.com/photo.php?fbid=10208832526623433&set=gm.633149993506360&type=3","472656846222343_633149993506360",NA,55,3,6
"10208314748176383","Le Manh Hung","Chào các bạn, mình muốn hỏi về cách vẽ hiển thị legend trong ggplot2. Có cách nào để điều chỉnh kính cỡ của linetype và shape  (point) khác nhau được không. Ví dụ như hình của mình, kích cỡ của line là o,k, rồi nhưng mình muốn tăng cỡ của shape lên. Xin cảm ơn!

File dữ liệu :
https://drive.google.com/open?id=0B6ZINDS0znc5enhWbTVmRlJISUU

Code của mình:

dat = read.table(""SPEI.PCIS.txt"",header = T)

order = c(""Lagged SPEI"",""Lagged Rainfall"",""Lagged EMI"",""Lagged NINOW"", ""Lagged NINO4"",""Lagged NINO3.4"",""Lagged SOI"",""Lagged BEST"",""Lagged MEI"", ""Lagged PDO"")
library(""plyr"")
dat <- arrange(transform(dat,
                 Varnames=factor(Varnames,levels=order)),Varnames)

textSize = 9
require(ggplot2)
 ggplot(data = dat,aes(x = Type, y = mean, ymin = mean - se, ymax = mean +se))+
  geom_line(aes(group = Varnames,linetype = Varnames, color = Varnames),size = 0.3) +
  geom_point(aes(color = Varnames, shape = Varnames),size = 1)+
  geom_errorbar(aes(color = Varnames,linetype = Varnames),width=0)+
  scale_linetype_manual(values = c(1,2,3,4,5,6,1,2,3,4))+
  scale_shape_manual(values = c(0,1,2,13,4,5,6,5,4,13,2))+
  scale_color_manual(values = c(""#0033cc"",""#0000ff"",""#800033"",""#b30047"",""#e6005c"",                               ""#ff1a75"",""#ff4d94"",""#ff80b3"",""#ff99c2"",""#226600""))+
  ylab(""Number of Variables"")+
  xlab("""")+
  theme_bw()+
  guides(shape=guide_legend(override.aes=list(size=0.2)), 
         ncol = 4)+
  theme(  axis.text.x = element_text(size=textSize),
          axis.title.x = element_text(face = ""bold"",size = textSize),
          axis.text.y = element_text(size=textSize),
          axis.title.y = element_text(face = ""bold"",size = textSize),
          legend.title = element_blank(),
          legend.key = element_blank(),
          legend.key.width = unit(0.65, ""cm""),
          legend.key.height = unit(0.45, ""cm""),
          legend.text = element_text(size= textSize),
          legend.position= ""bottom"" ,
          panel.grid.major.y= element_line(colour = ""grey50"",size = 0.3),
          panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank())","2016-07-19T14:44:48+0000","photo","https://www.facebook.com/photo.php?fbid=10206590243584846&set=gm.633133393508020&type=3","472656846222343_633133393508020",NA,2,3,1
"10208725271269151","Dung Nguyen Chi","Xử lý số liệu thiếu (Missing Data): 

http://rpubs.com/chidungkt/197118","2016-07-18T23:04:28+0000","photo","https://www.facebook.com/photo.php?fbid=10206939502866057&set=gm.632862026868490&type=3","472656846222343_632862026868490",NA,59,1,4
"10210845468545723","Vịt Trần","Chào các anh chị, mình có một câu hỏi này khá tổng quát, xử lí missing values luôn là vấn để nhức đầu và mang tính thoả hiệp, theo kinh nghiệm cá nhân của mọi người, mọi người xử lí các NA này ra sao?","2016-07-18T07:32:54+0000","status",NA,"472656846222343_632577876896905",NA,5,10,1
"10211433339445727","Loi Luu","Chào các bạn, cho mình hỏi về vấn đề liên quan đến beta-binomial conjugate trong bayseian statistics.  Nếu mình bỏ qua variation của replicate thì mình có đường CpG#1 (màu đen). Nếu mình tính luôn cả variation giữa replicates thì có đường màu đỏ CpG#2, rõ ràng thí nghiệm 2 lặp lại (của thí nghiệm 1) hoàn toàn mâu thuẫn với thí nghiệm lần 1 nên mình có bimodal như trong hình. Còn trường hợp CpG#3 thì có vẻ như normal distribution. Nếu mình tăng replicates từ 2 lên 3 thì có thể làm giảm variation của posterior distribution như trong CpG#4. Mình đã lặp lại thí nghiệm bằng R nhưng không biết cách mix 2, 3 replicates ~ beta(alpha_i,beta_i) vào một distribution như hình vẽ một. Hình hai và hình ba là hình vẽ của mình tương ứng với con số trong hình vẽ 1, nhưng ko mix được các replicates (Code R của mình bên dưới stt). Mong các bạn giúp đỡ. Xin cảm ơn các bạn.

## R code
x <- seq(0,1,by=0.001)

# plot 1
png(""hinh2.png"")
plot(x,dbeta(x,25,36))
points(x,dbeta(x,10,22), col='green')
points(x,dbeta(x,16,16), col='green')
points(x,dbeta(x,3,29), col='red')
points(x,dbeta(x,23,9), col='red')
points(x,dbeta(x,7,15), col='blue')
points(x,dbeta(x,9,13), col='blue')
points(x,dbeta(x,11,11), col='blue')
dev.off()

# plot 2
png(""hinh3.png"")
plot(x,dbeta(x,25,36))
points(x,(dbeta(x,10,22)+dbeta(x,16,16))/2, col='green')
points(x,(dbeta(x,23,9)+dbeta(x,3,29))/2, col='red')
points(x,(dbeta(x,7,15)+dbeta(x,9,13)+dbeta(x,11,11))/3, col='blue')
dev.off()
###","2016-07-18T08:06:07+0000","photo","https://www.facebook.com/photo.php?fbid=10209243956392519&set=gm.632586256896067&type=3","472656846222343_632586256896067",NA,6,0,0
"1412242695487170","Linh Pham","Hi cả nhà,
Mình là bigginer về R. Mình đang định dùng hàm tryCatch như sau:
x=c(1,2,-1,-2)
y=matrix(nrow=1, ncol=4)
for (i in seq(1:length(x)))
{
  tryCatch(expr={y[i]=log(x[i])}, error={y[i]=log(-x[i])})
}

Ý tưởng là nếu x>0 thì sẽ tính log(x), nếu x<0 không tính được log(x) thì mình sẽ tính log(-x).
Mong mọi người correct script trên giúp mình với. Mình chạy nhưng nó chỉ tính 2 giá trị đầu và omit 2 giá trị cuối.
Thank cả nhà nhiều!","2016-07-14T14:59:42+0000","status",NA,"472656846222343_630912670396759",NA,2,5,0
"1595146587166138","Hai Nguyen","Chào các anh/chị,

Mình revise lại một mẫu code trình bày về giới hạn của logistic regression khi cỡ mẫu nhỏ, tức với n<750, chúng ta sẽ thấy sự giao động không ổn định trên graph beta coefficient qua phương pháp maximum likelihood xa với beta coefficient của population và cho ra graph sau, nhưng hiện tại chạy lại mẫu code này thì báo lỗi, loay hoay vẫn chưa chỉnh lại được, nhờ cả nhà giúp một tay. Cảm ơn rất nhiều.

Coding:

# http://www.surefoss.org/
# http://www.surefoss.org/tag/graphics/
# Note replace original `' with '', simple single quotes, not curved.

# EVOLUTION OF LOGISTIC REGRESSION
# Run and plot the development of logistic regression

# Define eval_reg function
eval_reg<-function(model){
  mod<-model
  dat<-mod$data[sample(nrow(mod$data)),]
  vars<-names(coef(mod))
  est<-data.frame(matrix(nrow=nrow(dat), ncol=length(vars)))
  pb <- txtProgressBar(min = 50, max = nrow(dat), style = 3)

  for(i in 50:nrow(dat)){
    try(boot_mod<-update(mod, data=dat[1:i,]))
    try(est[i,]<-exp(coef(boot_mod)))
    setTxtProgressBar(pb, i)
  }

  est$mod_nr<-1:length(dat[,1])
  names(est)<-c(vars, 'mod_nr')
  return(est)
}

# Simulate data, fit a model
set.seed(29012001)

x<-rbinom(1000, 1, .5)
y<-rbinom(1000, 1, .5)
z<-rbinom(1000, 1, .5)

data<-data.frame(x, y, z)

# Usual logistic regression
model_1<-glm(z~x+y, family=binomial, data = data)

# Permutation-based logistic regression
#library(logregperm)
#

# Call the model evaluation function eval_reg()
mod_eval<-eval_reg(model_1)

# Plot the result of eval_reg() stored in mode_eval
library(reshape2)
library(ggplot2)

tmp<-melt(mod_eval,id='mod_nr')
tmp2<-tmp[tmp$variable!='(Intercept)',]

ticks<-c(seq(.1, 1, by =.1), seq(1, 10, by =1), seq(10, 100, by =10))

ggplot(tmp2, aes(y=value, x=mod_nr, color = variable)) +
  geom_line() +
  geom_hline(y=1, linetype=2) +
  labs(title = 'Evolution of Logistic Regression', y = 'OR (log10)', x = 'Number of Participants') +
  scale_y_log10(breaks=ticks, labels = as.character(ticks)) +
  theme_bw()","2016-07-17T05:20:35+0000","photo","https://www.facebook.com/photo.php?fbid=1351331941547605&set=gm.632119463609413&type=3","472656846222343_632119463609413",NA,7,3,1
"1264476596972172","Tom Duong","Cho phép em xin được hỏi ý kiến các anh (chị) trong nhóm ạ:
Hình ảnh dưới là một bảng liệt kê thành phần phương sai cho phân tích , tác giả sử dụng phần mềm JMP (SAS). Em xin phép tóm tắt bài báo: Mục tiêu tác giả kiểm định Density (Khối lượng thể tích gỗ). Tác giả thu thập cây gỗ tại 4 địa điểm (S=4), mỗi địa điểm lấy 5 cây (T=5), mỗi cây lấy mẫu ở 3 cấp chiều cao (L=3) và mỗi cấp chiều cao lấy mẫu 3 vị  từ tâm tới vỏ (P=3). Tại mỗi vị trí đó tác giả đo được Density. Tác giả kiểm định ảnh hưởng của các nhân tố Site, Tree, Height level and Radial position tới Density.

Câu hỏi của em là: Chúng ta có thể sử dụng ngôn ngữ R để kiểm định như ở trên được không ạ?. Rất mong nhận được sự chỉ dẫn của anh (chị).","2016-07-15T05:55:37+0000","photo","https://www.facebook.com/photo.php?fbid=1056038591149308&set=gm.631178860370140&type=3","472656846222343_631178860370140",NA,1,5,0
"756125924536548","Đào Nhân","Em đang là sinh viên mới bắt đầu tìm hiểu về thống kê và R. Em muốn học thống kê một cách bài bản để có kiến thức nền chắc chắn. Các anh chị có thể giới thiệu cho em một cuốn sách nào đó (tiếng Việt/ tiếng Anh) hoặc một khóa học online ở các trang như edx/cousera về chủ đề thống kê mà dễ hiểu được ko ạ? Em chỉ muốn học các kiến thức cơ bản cho chắc chắn thôi. Em cảm ơn mọi người nhiều ạ!","2016-07-15T07:45:25+0000","status",NA,"472656846222343_631204477034245",NA,22,10,9
"1620795571268747","Hue Nguyen","Free Data Science Program

","2016-07-16T02:14:56+0000","link","http://www.informationweek.com/big-data/big-data-analytics/microsoft-launches-online-data-science-degree-program/d/d-id/1326276?_mc=RSS_IWK_EDT&utm_content=buffera0001&utm_medium=social&utm_source=facebook.com&utm_campaign=buffer","472656846222343_631614530326573",NA,29,0,0
"1312822895463256","Ninh Van Nguyen","Chào các anh / chị,
Em hiện đang gặp phải vấn đề phân tích dữ liệu R, em dùng survival.
Code vẽ 2 biểu đồ theo code hướng dẫn trên mạng.
# xác suất không xảy ra
autoplot(fit, xlab=""Time (weeks)"", ylab=""Survival probability"")
#xác suất xảy ra, dùng option fun=""event"":
autoplot(fit, xlab=""Time (weeks)"", ylab=""Survival probability"", fun=""event"")
Nhờ anh / chị giải hướng dẫn giúp 2 biểu đồ này khác nhau với ạ!
Xin chân thành cảm ơn!
NVN","2016-07-13T03:07:40+0000","photo","https://www.facebook.com/photo.php?fbid=1087128384699376&set=gm.630256567129036&type=3","472656846222343_630256567129036",NA,2,5,0
"1398499446838965","Duong Duc Pham","Những người mới bắt đầu làm quen với học máy thường rất bối rối trước các khái niệm decision tree (cây phân loại), hoặc phương pháp láng giềng gần nhất (K-nearest neighbours). Thẻ sau đây giới thiệu cách hiểu đơn giản nhất về phương pháp suy luận của kNN","2016-07-14T05:19:18+0000","photo","https://www.facebook.com/photo.php?fbid=1180425248646387&set=gm.630729583748401&type=3","472656846222343_630729583748401",NA,68,1,11
"10208725271269151","Dung Nguyen Chi","Dự báo chính xác 92% biến động về giá cổ phiếu của Vinamilk?

Mình sử dụng KNN cho dự báo biến động về giá cổ phiếu của Vinamilk. Lần này mình chia nhỏ biến động giá cô phiếu thành các khoảng nhỏ (như tăng từ 0% đến 1%)... thì kết quả thật khó tin: mô hình dự báo chính xác tới 96% tất cả các quan sát trên tập testing. 

Mời các bạn thẩm và bình luận. Nó chính xác cao quá đâm mình thấy hoang mang. 

http://rpubs.com/chidungkt/195783","2016-07-14T01:06:25+0000","link","http://rpubs.com/chidungkt/195750","472656846222343_630653410422685",NA,32,8,1
"1530258666992232","Namlun Didong","Diễn đàn Machine Learning R chính thức mở cửa hộm nay (trùng hợp với fete nationale Française)

http://machinelearningvn.freeforums.net/

Hiện nay nó mới là một căn nhà trống: Chúng tôi cần có thời gian để xây dựng nội dung của Thư viện sách, dữ liệu và bài giảng phong phú hơn; tuy nhiên các bạn đã có thể bắt đầu đăng nhập và viết bài.

Xin chân thành cảm ơn các bạn.","2016-07-14T10:53:16+0000","photo","https://www.facebook.com/photo.php?fbid=1241772249174210&set=gm.630827250405301&type=3","472656846222343_630827250405301",NA,94,1,9
"10208725271269151","Dung Nguyen Chi","Sử dụng cách tiếp cận KNN dự báo biến động của thị trường chứng khoán. 

Số liệu sử dụng là Smarket gồm các thông tin liên quan đến chỉ số S&P 500 từ đầu năm 2001 đến cuối năm 2005 (tất cả là 1250 quan sát). Mục tiêu của chúng ta là dự báo biến động của chỉ số S&P 500 dựa trên các thông tin đầu vào khác như mức gia tăng lợi tức của ngày hôm nay (Today), các biến trễ về lợi tức của năm phiên giao dịch trước đó (từ Lag1 đến Lag5), khối lượng giao dịch của ngày một ngày trước đó (Volume). Biến Direction được gán “up” nếu lợi tức ngày hôm nay là tăng và được gán “Down” nếu lợi tức ngày hôm nay giảm điểm.

Bộ dữ liệu này được sử dụng trong cuốn An Introduction to Statistical Learning with Applications in R. Với dữ liệu huấn luyện là 1000 quan sát, các tác giả đã xây dựng  mô hình Logistic để đánh giá mức độ chính xác trong dự báo của mô hình cho 250 quan sát còn lại. Kết quả chỉ ra rằng mô hình dự báo chính xác 58.2% biến động của chỉ số S&P. Các bạn có thể xem chi tiết tại trang 160 của cuốn sách này. 

Tuy nhiên, sử dụng gói caret của Kuhn (2013) với dữ liệu huấn luyện là 1000 quan sát, mô hình KNN cho thấy mức độ chính xác trong dự báo là cao hơn nhiều so với mô hình Logistic với mức độ chính xác là 86%. 

Tuy nhiên người viết bài này cảm thấy có gì khá bất thường trong đó. Thực vậy, đó chính là tỉ lệ chính xác trong dự báo quá cao. 

Các bạn thẩm và cho ý kiến phản hồi: 

","2016-07-13T22:04:12+0000","link","http://machinelearningvn.freeforums.net/thread/10/nghi-bi-ng-kho-knn","472656846222343_630602840427742",NA,30,3,0
"1530258666992232","Namlun Didong","Bài thứ 4 của series CARET sẽ hướng dẫn thực hành về Neural Network sử dụng phương pháp nnet. NN, còn gọi là mạng thần kinh nhân tạo, là một giải pháp thay thế cho logistic model. Nó có ưu thế cũng như nhược điểm riêng, nhưng rất đáng để thử nghiệm.

https://drive.google.com/open?id=0B1vaOU1uB8DPdmpGYXRDR3Q5Q1k","2016-06-10T16:47:07+0000","photo","https://www.facebook.com/photo.php?fbid=1216285698389532&set=gm.615803915240968&type=3","472656846222343_615803915240968",NA,45,7,3
"1530258666992232","Namlun Didong","Bài 5 trong series caret: so sánh khả năng dự báo của mô hình phân loại : đồ thị trực quan và kiểm định t.

https://drive.google.com/open?id=0B1vaOU1uB8DPUWxtVjBXTWJfd0k","2016-07-12T20:15:42+0000","photo","https://www.facebook.com/photo.php?fbid=1240373672647401&set=gm.630125920475434&type=3","472656846222343_630125920475434",NA,56,7,2
"10154630775082982","Duy Thọ Nguyễn","Rất nhiều presentation mình thấy rất hay cho ai trót lỡ đam mê R. 
Hi vọng ngày nào đó các anh chị em có thể tự tổ chức ở Việt Nam 1 workshop như vậy

","2016-07-06T03:24:10+0000","link","https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016?sort=status&direction=asc#tab_sortBy_status","472656846222343_627151767439516",NA,31,9,1
"10208725271269151","Dung Nguyen Chi","Chào các bạn, 

MỘT VẤN ĐỀ TƯỞNG ĐƠN GIẢN MÀ THÀNH RA KHÓ 

R rất mạnh cho các ứng dụng thống kê. Ai cũng đồng ý với điều này. Tuy nhiên hôm nay tự cho mình câu hỏi và cảm thấy rất lúng túng. Đó là vẽ Ogive Line (hay Cumulative Relative Frequency Graph). Để thống nhất câu trả lời, câu hỏi của mình là làm thế nào vẽ  Cumulative Relative Frequency Graph cho biến số Sepal.Length của bộ số liệu iris. 

Cảm ơn các bạn rất nhiều.","2016-07-12T12:50:13+0000","status",NA,"472656846222343_629989783822381",NA,14,6,0
"10208725271269151","Dung Nguyen Chi","Đếm chữ: Cuốn Macroeconomics của Mankiw có bao nhiêu từ?

","2016-07-07T08:49:16+0000","link","http://rpubs.com/chidungkt/194392","472656846222343_627655014055858",NA,22,4,0
"1354606104605414","Trang Tran Huyen","Em chào các Thầy cô, anh chị trong group ạ :)
Em học bên Sinh học và có vài câu hỏi muốn nhờ cả nhà giúp đỡ chút ạ.
Câu hỏi liên quan tới việc chuẩn hóa cho dữ liệu tỷ lệ/ phần trăm (normalize a data proportion/percentage).
Em đọc báo thì thấy rằng thông thường quy trình là chuyển đổi dữ liệu bằng ARSIN(SQRT(x)) (arcsine square root transformation). Tuy nhiên, có 1 bài báo (file đính kèm) chỉ ra rằng không nên dùng phương pháp trên. Do đó, em có 2 câu hỏi: Theo các thầy cô/ anh chị 1. Phương pháp nào thì tốt nhất để chuẩn hóa với dữ liệu phần trăm/ tỷ lệ?
2. Nếu việc chuyển đổi dùng Logit thì với các thông số là 0 ta sẽ xử lí như thế nào ạ?

Mặc dù câu hỏi của em có thể hơi ""thơ ngây"" với các nhà Thống kê học :) nhưng em mong được BQT phê duyệt nội dung, và cảm ơn sự giúp đỡ của cả nhà ạ :)","2016-06-17T05:29:09+0000","status",NA,"472656846222343_618691581618868",NA,3,8,0
"10212856936286631","Ho Le Phuong Thao","Một vấn đề mà em chưa thấy các anh chị nhắc đến, đó là dữ liệu ko cân bằng (với các bệnh hiếm gặp thì tỉ tệ cases/controls có thể cực thấp) . Đối với các mô hình bên thống kê, ta có thể dùng tất cả dữ liệu để đưa vào phân tích. Trong machine learning, em thấy người ta thường phải xử lí trước, vì dữ liệu ko cân bằng sẽ làm ảnh hưởng độ mạnh của mô hình dự báo/phân loại/.... Có rất nhiều thuật toán để cân bằng dữ liệu, tạo ra sample size khác nhau. Làm thế nào để biết dụng thuật toán nào là tối ưu nhất?

Em vừa phát hiện ra package unbalanced trong R có thể giúp giải quyết việc này. Code ví dụ như sau:

library(unbalanced)
#configure sampling parameters
ubConf <- list(type=""ubUnder"", percOver=200, percUnder=200, k=2, perc=50, method=""percPos"", w=NULL)
#load the classification algorithm that you intend to use inside the Race
#see 'mlr' package for supported algorithms

#method used for choosing best algorithm=random forest
library(randomForest)
results <- ubRacing(outcome ~., testdata, ""randomForest"", positive=1, ubConf=ubConf, ntree=500)
# method used for choosing best algorithm=svm
results <- ubRacing(outcome ~., testdata, ""svm"", positive=1, ubConf=ubConf)

# result : best algorithm=ubUnder

n<-ncol(testdata) #index of outcome variable
output<-testdata$outcome
input<-testdata[ ,-n]
data<-ubUnder(X=input, Y= output, perc = 50, method = ""percPos"")
newData<-cbind(data$X, data$Y)
names(newData)=names(testdata)","2016-07-08T03:06:16+0000","status",NA,"472656846222343_627982230689803",NA,13,0,2
"10212856936286631","Ho Le Phuong Thao","Chào các anh chị. Em đang bế tắc ý tưởng về việc sử dụng Neural Network để dự báo trên longitudinal data. Giả sử trong quá trình theo dõi, mỗi cá nhân gặp event tại các thời điểm khác nhau. bình thường bên phân tích thống kê thì có thể áp dụng Cox model để làm. Còn bên kĩ thuật thì qui về 1 time point hoặc time interval cố định như sau T time nào đó, event có xảy ra hay ko. 

Nếu dùng cách kĩ thuật thì em thấy bị mất thông tin nhiều. Các anh chị có biết cách nào có thể xử lí dữ liệu này bằng neural network mà ko qui về 1 time point hay time interval ko ạ?
Em cảm ơn anh chị nhiều!","2016-07-06T07:27:14+0000","status",NA,"472656846222343_627211160766910",NA,0,1,0
"10208314748176383","Le Manh Hung","Anh/chị/bạn cho mình hỏi, mình có một data set X1,X2,...Xn,Y, mình muốn sử dụng mô hình hồi quy tuyến tính để dự báo Y từ X1, X2,...,Xn. Cách thông thường với lệnh lm là
lm(Y ~ X1 + X2 + X3 +...+Xn,data = dat ).

Có cách nào để tự động tạo mô hình hồi quy như trên không với n lớn và mình không muốn gõ nhiều lần. Xin cảm ơn!","2016-05-30T09:48:54+0000","status",NA,"472656846222343_611321149022578",NA,2,4,0
"1530258666992232","Namlun Didong",NA,"2016-07-07T10:55:40+0000","photo","https://www.facebook.com/photo.php?fbid=1236118439739591&set=gm.627687504052609&type=3","472656846222343_627687504052609",NA,73,3,6
"1100581106718191","Tung Nguyen","Chào mọi người.
Mình có vấn đề nhờ mọi người giúp: Khi minh nhập dữ liệu từ Ms.Excel (2007) vào R thì R không nhận cột mà chỉ có hàng. Minh dùng lệnh din kiểm tra thì R báo chỉ 01 cột.
Cảm ơn!","2016-07-06T23:48:56+0000","status",NA,"472656846222343_627518414069518",NA,0,2,0
"1913258532222776","Tran Quy Phi","Một số bạn hỏi về kỹ thuật, liên quan đến dữ liệu cụ thể và lệnh trong R, các bạn nên đưa dữ liệu và lệnh của mình đã thực hiện thì mọi người mới biết đường mà giúp chứ.","2016-07-07T06:11:53+0000","status",NA,"472656846222343_627626664058693",NA,4,0,0
"1530258666992232","Namlun Didong","Ít người biết trước khi ggplot2 ra đời, ngữ pháp đồ thị đã được thiết lập hoàn chỉnh bởi tác giả Leland Wilkinson.","2016-07-06T12:44:43+0000","photo","https://www.facebook.com/photo.php?fbid=1235492783135490&set=gm.627280117426681&type=3","472656846222343_627280117426681",NA,55,4,3
"1312924752138295","Rainie Kenta","Em chào các anh chị ạ

Anh chị ơi cho em hỏi một chút. Tại sao có thể dùng cross validation để lựa chọn giá trị cho các tuning parameter ạ","2016-07-04T12:33:48+0000","status",NA,"472656846222343_626454390842587",NA,3,2,0
"10208725271269151","Dung Nguyen Chi","Sciencedirect - ""nhà kho"" tập hợp các nghiên cứu từ 2500 tạp chí vừa cho ra lò Research Elements Program theo đó các nghiên cứu sẽ cung cấp cả data, miêu tả data, và cả R code (nếu là nghiên cứu dùng R). Mục tiêu là làm cho nghiên cứu có thể được tái tạo lại (reproducible). ..

Cách lấy free các nghiên cứu này thì ai cũng biết rồi. Giờ chỉ còn data nữa... Các bạn ngâm cú và chia sẻ nếu phát hiện ra cái gì mới hơn thì post vào đây nhé để mọi người cùng hưởng lợi.

https://www.elsevier.com/authors-update/home/featured-article/How-new-article-types-help-make-science-more-reproducible?sf30004591=1","2016-07-01T01:03:15+0000","photo","https://www.facebook.com/photo.php?fbid=10206822503341142&set=gm.624843544337005&type=3","472656846222343_624843544337005",NA,39,1,9
"1530258666992232","Namlun Didong","https://sites.google.com/site/bayesforvietnam/home/bai-giang-slides/HoiquyBeta%20Bayes.pdf","2016-07-03T17:44:04+0000","photo","https://www.facebook.com/photo.php?fbid=1233236020027833&set=gm.626138404207519&type=3","472656846222343_626138404207519",NA,29,1,3
"1530258666992232","Namlun Didong","Bài mới nhất của serie Bayes: hồi quy nhị thức âm.

https://sites.google.com/site/bayesforvietnam/home/bai-giang-slides/Negbinomial%20Bayes.pdf?attredirects=0&d=1","2016-06-16T13:40:58+0000","photo","https://www.facebook.com/photo.php?fbid=1220406557977446&set=gm.618369061651120&type=3","472656846222343_618369061651120",NA,38,2,7
"1627919773889937","Nguyen Chi Thanh","Group có bạn nào có quyển ""Statistical and biometrical techniques in plant breeding"" của JR Sharma thì share lại hoặc bán lại cho mình. Thanks mọi người trước","2016-06-29T03:19:03+0000","status",NA,"472656846222343_624005807754112",NA,0,0,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn. Vấn đề của mình như sau. Mình có 1 file ảnh có tên bang2.png với đường dẫn là: 

D:/Data/bang2.png

(Tức là bang2.png để ở folder có tên Data, ở ổ D của máy tính)

MÌnh muốn chèn file ảnh này vào khi sử dụng Rmarkdown thì làm thế nào được? 

Cảm ơn các bạn nhiều.","2016-06-24T23:51:28+0000","status",NA,"472656846222343_622098334611526",NA,3,1,0
"1530258666992232","Namlun Didong","https://youtu.be/SrxdKqCo9v0","2016-06-22T12:11:03+0000","video","https://youtu.be/SrxdKqCo9v0","472656846222343_621070348047658",NA,31,0,1
"1695856590441259","Mong Tuyen Huy Vu","Dạ em xin phép Admin cho em giới thiệu bài viết này ạ:

","2016-06-20T05:57:58+0000","link","http://ibsgacademic.com/bioengineering/tin-sinh/phep-kiem-don-gian-den-ngac-nhien-de-kiem-tra-loi-trong-cac-bai-bao-khoa-hoc/","472656846222343_620122648142428",NA,10,0,0
"10208915968716100","Tran Ngoc Dang","Bài giảng video về ""hồi quy nhị thức âm theo Bayes"" do Bs Nam thực hiện. Đây là bài giảng thuộc dự án BAV ""Bayes for Vietnam"", một dự án nhằm phổ biến Bayes đến cộng đồng nghiên cứu Việt Nam. Nếu các bạn quan tâm xin mời ghé qua trang web:
https://sites.google.com/site/bayesforvietnam/

Trong bài giảng này có phần hướng dẫn thực hành dựng mô hình hồi quy nhị thức âm theo Bayes và phần  kiểm tra phẩm chất chuỗi MCMC thông qua giao diện tương tác Shiny theo mình là rất tuyệt!
https://www.youtube.com/watch?v=A8oO3Fn1TLI","2016-06-20T02:42:05+0000","video","https://www.youtube.com/watch?v=A8oO3Fn1TLI","472656846222343_620078314813528",NA,24,0,0
"1530258666992232","Namlun Didong","Nhóm BAV đã có website, cảm ơn anh Trần Ngọc Đăng

https://sites.google.com/site/bayesforvietnam/","2016-06-11T13:06:59+0000","photo","https://www.facebook.com/photo.php?fbid=1216919394992829&set=gm.616183708536322&type=3","472656846222343_616183708536322",NA,80,11,3
"10210592871410696","Hanh Le","Chào các cao thủ trong nhóm. Mình định dùng package BFAST trong link này http://bfast.r-forge.r-project.org/ để phân tích xu huớng (trend) và time seríe của dữ liệu. Trong nhóm mình đã có ai từng áp dụng package này thì cho mình biết, mình muốn xin chỉ giáo một số thứ. Thks","2016-06-14T09:57:15+0000","link","http://bfast.r-forge.r-project.org/","472656846222343_617480545073305",NA,1,0,0
"1530258666992232","Namlun Didong",NA,"2016-06-12T18:44:47+0000","photo","https://www.facebook.com/photo.php?fbid=1217809394903829&set=gm.616764968478196&type=3","472656846222343_616764968478196",NA,59,4,7
"1205787479527610","Diệp Phong","Hôm trước đọc được bài này ở 1 group khác :))
Cuối tuần xem phim mọi người coi xem có đúng không :))","2016-06-13T15:51:51+0000","link","https://medium.com/@kemyd/if-machine-learning-algorithms-were-movies-3b048771d61b#.gzpfd3v60","472656846222343_617184595102900",NA,3,0,0
"1530258666992232","Namlun Didong","Tóm tắt những chỉ số quan trọng khi diễn giải kết quả suy diễn BAYES.

Nhắc lại: Suy diễn Bayes dựa trên nền tảng: Mức độ khả tín, dựa vào tỉ trọng chứng cứ. Nó không ép buộc các bạn phải tin vào 1 giá trị p duy nhất, mà đưa ra bằng chứng cho các bạn tự quyết định.","2016-06-13T08:04:25+0000","photo","https://www.facebook.com/photo.php?fbid=1218194134865355&set=gm.617028181785208&type=3","472656846222343_617028181785208",NA,58,1,9
"1530258666992232","Namlun Didong","Chào các bạn. Lần này mình có một vấn đề cần đến sự trợ giúp của các bạn. Vì nó có liên quan tới time series data, là thứ mình chưa có nhiều kinh nghiệm. Vấn đề như sau:

Mình đang phân tích raw data của một thiết bị PSG. Data có 3 cột, cột thứ nhất có nội dung HH:MM:SS, chỉ thời điểm

Cột thứ 2 là categorical variable, nhận 1 trong nhiều giá trị là tên (label) của Event 

Cột thứ 3 là duration, độ dài của mỗi event, đơn vị là second.

Các bạn có thể gợi ý hướng đi nào cho phép khảo sát (kiểm định) tính chất Coincidence giữa 2 event, dựa theo độ dài và thời điểm khởi phát của chúng ? và tính nhân, quả (xét theo thứ tự) của 2 event ? Câu hỏi thứ 1 thì có 1 chuyên viên MATLAB đã tạo ra algorithm cho phép tính Sensitivity và Specificity cho coincidence, nhưng mình không sử dụng Matlab, và theo mô tả thì algorithm này bắt buộc phải dùng 1 giá trị tolerance cố định cho khoảng cách giữa 2 event, thí dụ +/- 5 giây. Mình không thích ý tưởng này cho lắm...","2016-06-08T18:09:43+0000","photo","https://www.facebook.com/photo.php?fbid=1214891168528985&set=gm.615069981981028&type=3","472656846222343_615069981981028",NA,18,4,1
"1530258666992232","Namlun Didong","Thông báo: Tìm đồng đội cho dự án BAV (Bayesian Analysis for Vietnameses).

Mình có ý định thực hành và biên soạn tài liệu hướng dẫn về phân tích Bayes bằng tiếng Việt, để dùng tại Việt Nam. Mục tiêu của dự án là góp phần phổ biến phương pháp Bayes và thay thế những công cụ thông kê truyền thống bằng phương pháp Bayes.

Trước kia, phân tích Bayes đòi hỏi người học phải biết lập trình (code mô hình) cho 1 sampler, ví dụ WinBugs, JAGs và STAN. Hiện nay, quy trình phân tích đã trở nên đơn giản hơn nhờ các giao thức nối R và các sampler này (ví dụ MCMCglmm, MCMCpack, brms, coda,...) tuy nhiên chưa có package nào thực sự đầy đủ và hoàn hảo. 

Trong tài liệu nổi tiếng : Doing Bayesian Analysis... của John Kruschke, tác giả đã viết sẵn rất nhiều mô hình Bayes để dùng với JAGs và coda; tuy nhiên để áp dụng nó đòi hỏi người học cũng phải có kỹ năng phân tích nhất định về R function, R code. Việc cải tiến và thay đổi nội dung của code càng khó khăn hơn nữa. 

Bản thân mình, tuy đã có thể bắt đầu sử dụng Bayes cho một số thiết kế nghiên cứu, nhưng vẫn chưa đủ khả năng và không có nhiều thời gian để phân tích nội dung, thay đổi tất cả code của Kruschke. Do đó mình mong tìm kiếm thêm bạn bè để cùng thực hành và biên soạn tài liệu.

Nếu bạn sử dụng R và có nhiều hơn 2 trong số khả năng sau đây:

1. Hiểu lý thuyết suy diễn Bayes
2. Có kinh nghiệm về functions trong R
3. Từng sử dụng (lập trình trực tiếp hoặc qua trung gian R) một trong 2 sampler : JAGs (Gibs method) và/hoặc STAN (Metropolis-Hastings method). 
4. Có kinh nghiệm sử dụng các package về phân tích Bayes trong R như MCMCpack, MCMCglm, coda, brms...

Xin trao đổi với mình qua PM hay email: bacsinam81@gmail.com
Với 1 nhóm khoảng 3-4 người, mình hy vọng là tài liệu sẽ sớm hoàn thành. Việc xin cấp giấy phép xuất bản thì không khó lắm.

Hy vọng sẽ sớm nhận hồi âm của các bạn có cùng niềm đam mê với Bayes.","2016-05-19T12:48:42+0000","status",NA,"472656846222343_606704446150915",NA,119,20,6
"1530258666992232","Namlun Didong","Bài thứ 3 trong series CARET sẽ giới thiệu về tập hợp Mô hình (có nơi dịch là Đồng diễn), một phương pháp tối ưu hóa khả năng dự báo bằng cách can thiệp lên variance và/hoặc bias.

https://drive.google.com/open?id=0B1vaOU1uB8DPRjVEdmhIbEdYOWM","2016-06-02T20:00:14+0000","photo","https://www.facebook.com/photo.php?fbid=1210623438955758&set=gm.612815832206443&type=3","472656846222343_612815832206443",NA,47,5,4
"1530258666992232","Namlun Didong","Đây là bài thứ 3 trong serie Bayes, trong bài này mình đã ráp nối được thành công những hàm phân tích ROPE và compare threshold của J.Kruschke vào output lớp brms. Các bạn có trong tay công cụ lý tưởng nhất hiện nay để làm phân tích tương quan giữa 2 biến định lượng. Đây cũng là cánh cửa mở ra mô hình hồi quy đa biến trong những bài tới.

https://drive.google.com/open?id=0B1vaOU1uB8DPc0JLdlRMYVAzWFU","2016-05-16T16:58:37+0000","photo","https://www.facebook.com/photo.php?fbid=1198696806815088&set=gm.605592892928737&type=3","472656846222343_605592892928737",NA,84,13,11
"1530258666992232","Namlun Didong","Đây là bài thứ 4 của series Bayes. Bài này sẽ bàn về mô hình Logistic theo Bayes. Mình đã viết thêm 1 số code cho phép khảo sát phân phối hậu nghiệm của Odds-ratio cũng như loại trừ giả thuyết H0 liên quan tới khoảng vô nghĩa (ROPE) và ngưỡng ý nghĩa (CompVal) theo cách của John Kruschke. 

https://drive.google.com/open?id=0B1vaOU1uB8DPclRaX1NXUE5haUk","2016-06-04T21:31:08+0000","photo","https://www.facebook.com/photo.php?fbid=1212069525477816&set=gm.613602298794463&type=3","472656846222343_613602298794463",NA,43,1,3
"10206482564502553","Thanh Le","Khóa học hè miễn phí về Computational Biology for Infectious Diseases tại Hà Nội, 18-25/9/2016.","2016-06-02T08:44:37+0000","photo","https://www.facebook.com/photo.php?fbid=10204805948308196&set=gm.612601258894567&type=3","472656846222343_612601258894567",NA,21,3,3
"1457163170961998","Viet Quoc Cao","Kính gửi các thành viên cộng đồng R. Em đang có một dự án nghiên cứu thuộc lĩnh vực hành vi người tiêu dùng. Mục đích của nghiên cứu này là khám phá và mở rộng lý thuyết cognitive appraisal of emotions theory (thuyết đánh giá mang tính nhận thức của cảm xúc). Em rất mong nhận được sự hoan hỉ của Quý Anh /chị giúp em khảo sát sau đây ạ. Ý kiến của Anh/chị là data quý giá giúp em có thể hoàn thành dự án nghiên cứu này. Em xin cảm ơn Quý Anh/chị. Link khảo sát của em: ","2016-06-03T00:22:17+0000","link","https://docs.google.com/forms/d/10fFawjmqjIQlH848DzeFqkfZFpHrIkHl6GzpiINzpnc/viewform","472656846222343_612872752200751",NA,0,0,0
"10206567252298972","Nguyen Huynh","Chào các bác, em mới tìm hiểu về PCA trên R. Em sửa đoạn mã PCA như trong link và chạy thành công trên bộ dữ liệu khác nhưng vẫn chưa hiểu ý nghĩa của các đồ thị. Nhờ các bác hướng dẫn em cách thuyết minh ý nghĩa các đồ thị hoặc giới thiệu tài liệu hướng dẫn thuyết minh đồ thị PCA giúp. Cảm ơn các bác
","2016-06-01T11:56:09+0000","link","http://quantlet.de/index.php?p=show&id=1110","472656846222343_612267128927980",NA,0,1,0
"1530258666992232","Namlun Didong","Bài này mở đầu series CARET. 

CARET là một giao thức tổng quát cho phép kết nối với hàng trăm package khác nhau trong R, với ứng dụng là Mô hình dự báo và Machine Learning.

CARET hỗ trợ 217 dạng mô hình khác nhau. Bài này sẽ ứng dụng mô hình cây kiểu CART vào chẩn đoán.

https://drive.google.com/open?id=0B1vaOU1uB8DPaWpWd3dzMnBSRHM","2016-05-26T16:17:11+0000","photo","https://www.facebook.com/photo.php?fbid=1205702676114501&set=gm.609850315836328&type=3","472656846222343_609850315836328",NA,56,11,6
"1530258666992232","Namlun Didong","Bài tiếp theo trong series BAYES bàn về cách thay thế test t Student bằng phương pháp Bayes (Thực ra cả 2 đều dựa trên phân phối t của Student và một mô hình tuyến tính). Một lần nữa bạn sẽ thấy là Bayes mạnh và linh hoạt hơn rất nhiều.

https://drive.google.com/open?id=0B1vaOU1uB8DPLWJLQjFkem5EY2M","2016-05-14T23:25:56+0000","photo","https://www.facebook.com/photo.php?fbid=1197532570264845&set=gm.604862823001744&type=3","472656846222343_604862823001744",NA,59,5,8
"1530258666992232","Namlun Didong","Bài thứ 2 trong series CARET.

Mục tiêu của bài này là hướng dẫn Huấn luyện và Kiểm định mô hình hồi quy trong caret.

5 kiểu mô hình khác nhau sẽ được thử nghiệm: GLM, GLM đa thức bậc cao, Cây hồi quy, GAM với spline và LASSO.

https://drive.google.com/open?id=0B1vaOU1uB8DPRHJtSUctVV9iaEk","2016-05-29T07:41:22+0000","photo","https://www.facebook.com/photo.php?fbid=1207445015940267&set=gm.610922612395765&type=3","472656846222343_610922612395765",NA,38,2,5
"10208725271269151","Dung Nguyen Chi","Sử dụng phân loại kNN xây dựng mô hình chẩn đoán ung thư. 

Trong group có nhiều bác sĩ, các nhà nghiên cứu y học nên cháu rất mong nhận được các phản hồi từ các bạn/anh/chị/cô/chú. Thuật toán này là một kiểu reproductive reseach dựa trên nghiên cứu của Street et al. (1993) và Lantz (2013). 

Cảm ơn các bạn nhiều. 

","2016-05-14T12:15:18+0000","link","http://rpubs.com/chidungkt/180844","472656846222343_604670229687670",NA,30,2,0
"10154630775082982","Duy Thọ Nguyễn","Cuối cùng thì cũng được tích hợp vào RStudio (phiên bản preview). Công cụ rất cần thiết để tối ưu mã nguồn R. 
","2016-05-24T07:35:10+0000","link","https://rstudio.github.io/profvis/","472656846222343_608841379270555",NA,11,2,0
"1530258666992232","Namlun Didong","Các cao thủ về machine learning có thể tư vấn cho mình câu hỏi như sau :

Mình muốn dựng classification model trên 1 data set khá lớn (khoảng 2000 observations), với Response variable và cả 2 predictors đều là binary variable.

Vậy theo các bạn trong các phương pháp sau đây, cái nào là tối ưu nhất (theo lý thuyết)  ?

1) Logistic regression
2) Logic regression
3) Binary discriminant analysis
4) Tree based models

Dĩ nhiên mình có thể làm nhiều model và so sánh chúng, nhưng không có thời gian.","2016-05-04T20:34:40+0000","status",NA,"472656846222343_600595366761823",NA,14,15,1
"1312924752138295","Rainie Kenta","Em chào anh chị ạ

Em muốn hỏi câu này ạ. Giả sử em có 1 biến nhị phân X. Trong 1 nghiên cứu, khi X = x1, tính được HR = a. Khi X = x2, HR = b (HR = hazard ratio of treatment versus control). Có cách nào để ước tính overall HR của cả nghiên cứu mà không cần chạy lại log rank test trên tất cả bệnh nhân không ạ","2016-05-22T15:11:03+0000","status",NA,"472656846222343_608024792685547",NA,0,4,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn, 

Khi mình xuất ra HTLM để Public thì T thông báo lỗi như sau (ảnh): 

Làm thế nào để xử lý vấn đề này nhỉ? 

Cảm ơn các bạn nhiều.","2016-05-21T04:22:34+0000","photo","https://www.facebook.com/photo.php?fbid=10206557908966448&set=gm.607430586078301&type=3","472656846222343_607430586078301",NA,5,7,1
"1223232297796071","Bang Chu Cai Bang","Chào cả nhà, em cần giúp đỡ
Em cần tìm m là số tự nhiên để minimize cái hàm được viết ra như sau:
crossValidation <- function(m,n,data)
{
h <- 1/m
#tim cac binwidth
binwidth <- matrix(0,1,m + 1)
binwidth[1] <- min(data)
binwidth[m+1] <- max(data)
for (i in 1:m)
{
binwidth[i+1] <- binwidth[i] + (max(data) - min(data))/m
}
binwidth
#tim cac p.hat
r <- hist(data, freq = 0, breaks = binwidth)
p.hat <- matrix(0,1,m)
for(i in 1:m)
{
p.hat[i] <- r$count[i]/214
}
#tinh crossValidation
J.hat <- 2/(h*(n-1)) - (n+1)*(sum(p.hat[1:m]^2))/(h*(n-1))
return(J.hat)
}
trong đó n là size của data, data là mảng 1 chiều.
Em dùng thử các hàm optimize, optim mà không được vì bị lỗi ngay lúc chia ra các bin, nếu m không phải là số nguyên thì sẽ có những phần tử không thuộc bin nào. Em cần chia đúng m bin. Mặt khác có anh chị nào biết cách để cái hàm hist() nó không vẽ đồ thị không ạ, tại vì em cần chạy nhiều lần mà nó cứ vẽ làm nặng máy lắm ạ. Cám ơn cả nhà.","2016-05-22T16:21:44+0000","status",NA,"472656846222343_608069306014429",NA,0,1,0
"1530258666992232","Namlun Didong","Skill set số 4: Một trong những trở ngại khó chịu khi phân tích Longitudinal data là định dạng của chúng. Có 2 kiểu định dạng phổ biến là Long data và Wide data. Một số package và thao tác chỉ tương thích với 1 trong 2: Long hoặc Wide. Sau đây là giải pháp chuyển đổi giữa chúng...","2016-05-21T18:54:33+0000","photo","https://www.facebook.com/photo.php?fbid=1202227853128650&set=gm.607699749384718&type=3","472656846222343_607699746051385",NA,47,3,4
"1999396396954442","Xuan Bui","Chào cả nhà, rất mong mọi người có thể hướng dẫn mình trong tình huống này.
1) Mình có 1 data với 2 biến chính là coral (CO) và environment quality (EQ). 
Biến CO có 3 mức độ 13%, 20% và 30%, được mã hóa là biến liên tục.
Biến EQ có 3 mức độ bad, med, and good, đã được mã hóa là biến dummy với bad là base level.
Nghĩa là trong data này mình có tổng cộng 3 biến: CO, med và good
2) Mong muốn của mình là tạo 1 data mới, trong đó:
- Vẫn có biến CO là liên tục, đồng thời có thêm biến CO được mã hóa dummy. Ví dụ: 13% là base level, 20% là small, 30% là large.
- Có thêm biến tương tác (interact) giữa CO và EQ, ví dụ: small*med, small*good, large*med, large*good.
Điều này có nghĩa là trong data mới sẽ có 9 biến: CO, small, large, med, good, small*med, small*good, large*med, và large*good.
3) Câu hỏi của mình là: mình sẽ viết code trong R như thế nào để có được các biến mới như mong muốn.
Rất cám ơn cả nhà đã chia sẻ những kiến thức quý báu!","2016-05-17T03:48:25+0000","status",NA,"472656846222343_605772489577444",NA,1,7,0
"1530258666992232","Namlun Didong","Skill set số 3: Thiết lập tương phản cho biến phân nhóm trong ANOVA

https://drive.google.com/open?id=0B1vaOU1uB8DPYzY4VXAyOTFvMlk","2016-05-18T14:08:47+0000","photo","https://www.facebook.com/photo.php?fbid=1199960300022072&set=gm.606374219517271&type=3","472656846222343_606374219517271",NA,43,4,3
"10208725271269151","Dung Nguyen Chi","Vui cuối tuần: Soi bài của anh Son Nghiem đăng trên PubMed: 

http://rpubs.com/chidungkt/181726","2016-05-17T16:46:29+0000","photo","https://www.facebook.com/photo.php?fbid=10206536193183567&set=gm.606013646219995&type=3","472656846222343_606013646219995",NA,21,4,1
"1675663279401142","Bao Dung","Thân chào các bạn, mình rất thích kiểu trình bày số liệu 2 nhóm như biểu đồ đính kèm (DOI: 10.1002/jbmr.2594) nhưng loay hoay mãi vẫn không tìm được cách vẽ lại. Mình đã thử plot 4 box trên cùng window, sau đó thêm text và vertical line nhưng cách này không chỉnh được khoảng cách giữa 2 box giáp nhau của 2 nhóm men và women như các tác giả đã làm. Xin các cao thủ trợ giúp với ạ!","2016-05-17T03:29:42+0000","photo","https://www.facebook.com/photo.php?fbid=1567670286867109&set=gm.605769712911055&type=3","472656846222343_605769712911055",NA,4,2,1
"1312924752138295","Rainie Kenta","Em chào các thầy cô và anh chị ạ. Em có một câu hỏi muốn nhờ mọi người giúp ạ.

Em đang đọc một bài báo dùng ""machine learning method"" để tìm ra một subgroup mà bệnh nhân đáp ứng với điều trị, trong một RCT mà điều trị không hiệu quả hơn nhóm chứng trên tất cả bệnh nhân (p-value>0.05 when testing on all patients). Phương pháp như này ạ:

- Chia bệnh nhân thành 2 nhóm: Development set và validation set.

- Trên development set: với mỗi covariate j, làm mô hình logit(p)=μ + λj*Treatment + βj*Treatment*xj. Ghi lại các covariate có interaction coefficient βj có ý nghĩa thống kê ở mức ε định trước.

- Trên validation set: phân loại bệnh nhân làm 2 nhóm (sensitive và non-sensitive). Một bệnh nhân được coi là sensitive nếu expected OR = exp(λj + βj*Treatment*xj) > R với ít nhất G covariate có βj có ý nghĩa thống kê đã xác định ở development set.

- So sánh điều trị với chứng ở các bệnh nhân sensitive xác định được trong validation set. Nếu p-value < 0.05 thì coi điều trị có tác dụng trên nhóm bệnh nhân sensitive này.

Em muốn hỏi là nhờ kết quả này, làm sao để có thể biết một bệnh nhân là sensitive trong thực tế ạ? Nói cách khác là làm sao để biết covariate nào cần đo lường để xác định 1 bệnh nhân là sensitive hay không trong thực tế ạ?

Em cảm ơn mọi người nhiều ạ","2016-05-15T13:30:34+0000","status",NA,"472656846222343_605078469646846",NA,2,13,0
"1999396396954442","Xuan Bui","Chào các anh, chị, em,
Hiện mình có một thắc mắc và rất mong mọi người giải đáp giúp.
Mình đang test 2 mô hình hồi quy logistic (các biến độc lập giống nhau): một có tính đến tác động tương quan (correlation) (mô hình 1) và một thì không (mô hình 2). Kết quả cho ra giá trị (gt tuyệt đối) các tham số của mô hình 1 luôn lớn hơn ở mô hình 2. Và mình không biết giải thích như thế nào, rất mong các anh/chị/em giải thích giúp. 
Chân thành cám ơn cả nhà!","2016-05-10T08:45:35+0000","status",NA,"472656846222343_602826056538754",NA,1,4,0
"1623119897702839","Anh Tuan","co mot trang web ve sach thong ke
","2016-05-14T09:38:44+0000","link","http://audipad.com/probability-statistics","472656846222343_604633796357980",NA,11,1,0
"380518235638520","Linh Phan","Em chào các anh chị trong nhóm, 
Em mới học thống kê và sử dụng R lần đầu, có câu hỏi này muốn nhờ các anh chị giải thích giúp ạ.
Giả sử em có 5 biến số f1, f2, f3, f4, f5 để tạo multiple regression line cho biến Y. Câu hỏi là nếu khống chế 2 biến f1 và f2 thì 3 biến số còn lại có thể dùng để predict Y được hay ko? 
Em không hiểu ""khống chế"" ở đây là như thế nào và nên dùng test nào để trả lời câu hỏi này.
Em xin cảm ơn.","2016-05-11T15:01:55+0000","status",NA,"472656846222343_603317119822981",NA,1,3,0
"10154630775082982","Duy Thọ Nguyễn","Khi gặp vấn đề với chương trình R, chưa tìm ra được giải pháp và cần sự hỗ trợ của người khác (đồng nghiệp hoặc từ các cộng đồng trên mạng), bạn cần cung cấp mã nguồn và dữ liệu cần thiết để có thể “tái hiện” lại 1 cách gần đúng nhất “bối cảnh” và “vấn đề” bạn cần giải quyết. Ví dụ khả lặp - reproducible example - chính là thông tin cần cung cấp này.

Cung cấp ví dụ khả lặp tốt giúp người đọc nhanh chóng “nhảy” vào vấn đề bạn đang gặp phải và nhờ đó, khả năng bạn tìm thấy câu trả lời sẽ nhanh hơn.

","2016-05-13T15:55:52+0000","link","http://rpubs.com/thonguyenduy/vi-du-kha-lap-voi-R","472656846222343_604379136383446",NA,7,1,0
"1530258666992232","Namlun Didong","Skill set số 2: các chiêu thức Trích xuất dữ liệu R","2016-05-12T13:55:07+0000","photo","https://www.facebook.com/photo.php?fbid=1195798520438250&set=oa.603732763114750&type=3","472656846222343_603732756448084",NA,65,5,7
"1312924752138295","Rainie Kenta","Em chào các thầy cô và anh chị ạ.

Trong bài báo dưới đây (http://linus.nci.nih.gov/techreport/ASD_CCR2005.pdf), có nhắc đến 1 nhóm phương pháp để phân loại bệnh nhân dựa trên dữ liệu quan sát được (a large variety of algorithms for developing a classification based on patients accrued during stage 1 could be envisionned). Mọi người cho em hỏi có tài liệu nào để đọc thêm về các classification-developing algorithm này (logic và dễ hiểu) không ạ?

Em cảm ơn mọi người ạ.","2016-05-04T22:10:03+0000","link","http://linus.nci.nih.gov/techreport/ASD_CCR2005.pdf","472656846222343_600623883425638",NA,1,2,0
"10206809901245983","Tran Van Thuc","Kính chào các anh, chị trong nhóm,

Hiện tại em đang có một vấn đề như sau nhờ anh/chị giúp đỡ ạ: em có hai thiết bị, thiết bị A và thiết bị B. Thiết bị A do em chế tạo ra, thiết bị B là thiết bị để so sánh.

Để thực nghiệm xem chất lượng của thiết bị em làm ra so với thiết bị so sánh em đưa một tín hiệu tuần hoàn vào cả hai thiết bị và đo tín hiệu đầu ra trong một chu kì. Thưc hiện công việc đó khoảng 10 lần, với tần số trích mẫu khoảng 1kHz.

Em có thể vẽ biểu đồ tín hiệu ra cho hai thiết bị để so sánh, nhưng nhìn biểu đồ khó thuyết phục.

Em muốn hỏi các anh/chị có thể dung phương nào để đánh giá xem liệu chất lượng tín hiệu ra của mình có bằng hay tốt hơn thiết bị đối chiếu không ạ (một cách định lượng ạ, ví dụ sai bao nhiêu phần trăm)? Em đã xem các bài giảng trực tuyến về R của gs Tuấn, nhưng (theo em hiểu) các lần lấy mẫu chỉ tại một điểm (do đó ta có mean và sd cho điểm đó) và so sánh, trong trường hợp so sánh nhiều điểm thì nên dung phương pháp nào ạ?

Em rất không rành về thống kê nên câu hỏi có phần ngô nghê mong anh chị trong nhóm thông cảm và giúp đỡ ạ.

Em xin chân thành cảm ơn ạ!","2016-05-09T08:11:38+0000","status",NA,"472656846222343_602450246576335",NA,3,19,0
"771400119684078","Hà Tuấn","Mình đang tìm cách tính cỡ mẫu cho đường biểu diễn ROC bằng R nhưng chưa được. Xin các bạn chỉ giúp. Thanks.","2016-05-08T17:13:09+0000","status",NA,"472656846222343_602225173265509",NA,0,0,0
"1205787479527610","Diệp Phong","Mọi người đã ai đọc bài báo này của Donoho chưa?
Bài báo rất hay về Data Science. Có lẽ sau 50 năm chúng ta đã có thể bắt đầu định nghĩa được Data Science là gì và tiếp theo đây nó sẽ phát triển như thế nào? :D","2016-05-08T11:35:21+0000","link","http://www.r-bloggers.com/50-years-of-data-science-by-david-donoho/","472656846222343_602099773278049",NA,8,0,0
"1356519944399387","Lê Khắc Linh","Em chào mọi người, em có câu hỏi liên quan đến vẽ biểu đồ thanh trên R (em đã google cả buổi sáng nhưng vẫn chưa ra được).
1)Khi tên biến  quá dài (nhiều chữ cái quá) , R cho ra biểu đồ nhưng bị che lấp mất một phần tên biến (trong hình của em tên biến lần lượt là ""Puplication"", ""Arwara or Hornors"", ""Experience"", ""GPA"", ""GRE""..., các anh chị có thể thấy tên biến mà dài như ""Puplication"", ""Experience""là bị che mất). Khắc phục như thế nào ạ?
2) Em muốn xoay tên biến một góc 45 độ, có thể là 30 hoặc bao nhiêu độ tùy ý (đe trang trí, và trong trường hợp tên biến quá dài thì xoay như vậy cũng là một giải pháp để R hiện hết chữ, anh chị chỉ hộ em.
3) Câu lệnh em dùng để vẽ: 
barplot(Percent, names.arg = c(""Pulication"",......), horiz = TRUE, xlab= ""......"", ylab = "".......,)
Em cảm ơn mọi người !","2016-05-08T09:31:30+0000","photo","https://www.facebook.com/photo.php?fbid=1107005049350879&set=gm.602068133281213&type=3","472656846222343_602068133281213",NA,1,8,0
"10208315019502040","Nam-Ky Nguyen",NA,"2016-04-07T04:01:00+0000","photo","https://www.facebook.com/photo.php?fbid=10205992271834800&set=gm.1002487533170341&type=3","472656846222343_588772847944075",NA,25,22,1
"1913258532222776","Tran Quy Phi","MÌnh đã delete một post và comment kèm theo của các bạn. Những gì các bạn bày tỏ rất đúng mực và chân thành, nhưng không đúng tôn chỉ của nhóm, đặc biệt là chuyện quan điểm cá nhân và những chuyện riêng tư, không phải ai cũng hiểu. Thành thật xin lỗi các bạn, nhưng phải vậy thôi. Mong các bạn thông cảm. Thân ái.","2016-05-04T13:19:03+0000","status",NA,"472656846222343_600419686779391",NA,11,0,0
"1530258666992232","Namlun Didong","Tại sao đồ thị biểu diễn phân phối chuẩn lại có hình chuông Úp ?

Trò chơi nhỏ sau đây sẽ giúp bạn trả lời câu hỏi này 

# 1) Trong R, bạn tạo 3 đối tượng x, mu và s như sau :
x=runif(100,-10,10)
s=sd(x)
mu=mean(x)

# Gọi package ggplot2

2) Ta bắt đầu với  y1 = (x-mu) bình phương

y1=(-(x-mu)^2)
qplot(x,y1)

3)# Tiếp tục với y2 = y1 chia cho 2 lần phương sai sigma của x

 y2=(-(x-mu)^2/(2*s^2))
qplot(x,y2)

4) Rồi y3 = exp(y2)

y3=exp(-(x-mu)^2/(2*s^2))
qplot(x,y3)

5) Cuối cùng là y4 : xác suất phân phối Gaussian đầy đủ
y4=(1/(s*sqrt(2*pi)))*exp(-(x-mu)^2/(2*s^2))
qplot(x,y4)

Nhận xét : Chính y1 quyết định hình dạng đồ thị của hàm phân phối chuẩn, nó có hình chuông úp vì y1 là hàm số bậc 2.

Tất cả những phần còn lại trong y3 và y4 chỉ là râu ria, vd: y3 dùng hàm exponential để đảm bảo giá trị xác suất dương, còn y4 để đảm bảo tổng xác suất =1","2016-03-15T09:31:32+0000","photo","https://www.facebook.com/photo.php?fbid=1147687761915993&set=gm.575790302575663&type=3","472656846222343_575790302575663",NA,49,4,7
"1530258666992232","Namlun Didong","Dạo này mình nhận thấy hoạt động của group bắt đầu bị phân tán và lạc quá xa so với ứng dụng hàng ngày. Trong khi nhiều bạn đặt những câu hỏi về code cơ bản thì các cao thủ lại ham thích những loại võ công kì dị bàng môn tả đạo khác nhau. Mình cũng có phần trách nhiệm khi đưa ra những chủ đề mang tính ngẫu hứng, cao xa và không có ứng dụng thực tế.

Do đó mình quyết định tạm ngừng series GLM và Bayes để quay trở lại với với những chủ đề thiết thực, cơ bản. Xin các cao thủ khác đừng chê cười nếu gặp lại những test thống kê rất cơ bản trong thời gian tới.

https://drive.google.com/open?id=0B1vaOU1uB8DPbnBRdVFRY2JFUFU","2016-05-02T20:22:41+0000","photo","https://www.facebook.com/photo.php?fbid=1188959527788816&set=gm.599667960187897&type=3","472656846222343_599667960187897",NA,81,5,3
"1849942691933972","Nguyen","Kính thưa các anh chị,
Em vừa vẽ biểu đồ này với ggplot nhưng muốn thêm ghi chú vào dưới biểu đồ thì có cách nào làm thay vì dùng annotation không ạ?","2016-05-03T01:44:29+0000","photo","https://www.facebook.com/photo.php?fbid=1719533218308254&set=gm.599759853512041&type=3","472656846222343_599759853512041",NA,1,3,0
"1312924752138295","Rainie Kenta","Em chào các thầy cô và anh chị ạ.

Mọi người cho em hỏi một câu ạ. Em đang mô phỏng (simulate) dữ liệu sống còn bằng phân phối Weibull, để sau đấy chạy mô hình Cox.

Trong trường hợp có 1 biến nhị phân duy nhất là Treatment thì sẽ đơn giản, dùng hàm rweibull 2 lần, 1 cho nhóm điều trị, 1 cho nhóm chứng, với thông số thích hợp

Giả sử giờ em cần thêm tác động của 3 biến, chẳng hạn 3 biomarker. Biến nhị phân và độc lập. Như vậy em phải dùng hàm rweibull 2^4=16 lần cho 16 ""nhóm"" khác nhau ạ?

Em muốn hỏi là có cách nào khác không ạ :)","2016-04-30T19:00:13+0000","status",NA,"472656846222343_598858010268892",NA,2,6,0
"1530258666992232","Namlun Didong","Propaganda...
(Sorry sir Ronald Fisher)","2016-04-29T14:15:40+0000","photo","https://www.facebook.com/photo.php?fbid=1186676001350502&set=gm.598360263652000&type=3","472656846222343_598360263652000",NA,16,6,1
"1913258532222776","Tran Quy Phi","Sau một thời gian chuẩn bị và hoàn tất thủ tục, Trường ĐH Kiên Giang đã phát thông báo về lớp học sắp tới ở Rạch Giá. Chi tiết kèm theo công văn, nhưng một vài thông tin chính như sau: 

Chủ đề: Phương pháp nghiên cứu khoa học và phân tích dữ liệu. 

Thời gian: 5 ngày, từ 20/7/2016 đến 24/7/2016. 

Địa điểm: Rạch Giá. Nhà khách Sài Gòn Phố, Đường Tôn Đức Thắng, TP Rạch Giá.

Chi phí: 1,5 triệu đồng. 

Liên lạc: Phương (0916-762-461), Thiện (0979-808-308), hoặc email: tthtqt@vnkgu.edu.vn. 

Nhờ các bạn chuyển thông báo đến các đồng nghiệp quan tâm. Hi vọng gặp các bạn ở Rạch Giá.","2016-04-30T13:36:07+0000","status",NA,"472656846222343_598754713612555",NA,21,1,2
"10155186029464497","Vipho Thita","Mọi người cho em hỏi dạng biểy đồ này gọi là gì ạ?","2016-04-29T04:44:14+0000","photo","https://www.facebook.com/photo.php?fbid=10154245911544497&set=gm.598188387002521&type=3","472656846222343_598188387002521",NA,1,2,1
"1302673403158448","Phúc Tấn Võ","[Cross Validation - Xử lý dữ liệu - CNTT]
Anh chị nào đã từng sử dụng cross validation rồi để xứ lý cho tập dữ liệu hơn 5000 dòng chưa ạ!?
Em đang xử lý với đống dữ liệu này, nhưng ngặt nỗi là nó ngốn quá, chạy lại lâu nữa, nên anh chị nào có kinh nghiệm giúp em với ạ!
Em cảm ơn nhiều","2016-04-27T16:46:01+0000","status",NA,"472656846222343_597603457061014",NA,0,6,0
"1640747595938853","Binh Thang","Em muốn hỏi các anh chị,
Em làm biểu đồ dưới, bây giờ muốn đổi tone màu cho từng nhóm (pop, male, female) với 95%CI (như trên hình đã có, nhưng lẫn 1 màu khó nhìn rõ.) thì phải làm thế nào?

command của em trong R

ggplot(tgc2, aes(x=year, y=pr, colour=id, group=id )) +
  geom_ribbon(aes(ymin=lr, ymax=ul),
              alpha=0.2) +
  geom_line()+geom_point( size=3, shape=21, fill=""white"") +  scale_y_continuous(breaks=0:20*4)+  theme_bw()+ ylim(10,40)

dataset em
(https://drive.google.com/open?id=0Bz4nSwuF86KAZlBEUDJMZmNwQnNwWlZVM1R5cEU5TkZmT2xV)

pr: tỷ lệ
lr: lower limit
ul: upper limit

Chân thành cảm ơn","2016-04-26T14:36:33+0000","photo","https://www.facebook.com/photo.php?fbid=1328013270545622&set=gm.597203680434325&type=3","472656846222343_597203680434325",NA,3,4,0
"906897349414053","Phúc Nguyễn ","Có thể gom 1 số câu hỏi thành một nhóm để tính hồi quy nhóm này với nhóm khác trong R được không ạ ?","2016-04-25T08:00:22+0000","status",NA,"472656846222343_596674877153872",NA,1,2,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn.

Mình đang dùng Rmarkdown. Mọi câu lệnh nếu chỉ chạy thôi thì không có vấn đề gì. Nhưng khi Knit HTML thì nó báo lỗi Object not found (như hình). EM phải khắc phục như thế nào ạ. 

Cảm ơn các bạn rất nhiều.","2016-04-24T13:33:51+0000","photo","https://www.facebook.com/photo.php?fbid=10206386095631222&set=gm.596361733851853&type=3","472656846222343_596361733851853",NA,4,1,0
"1249192251823862","Kevin Nguyen Vo","Vấn đề 00Lock hay lock directory'...' khi dùng install.packages().
Em gặp vấn đề này khi đang install package ""faraway"". E đọc 1 số trang trên stackoverflow thì thấy đây là giải pháp cho trường hợp này:","2016-04-23T23:03:17+0000","photo","https://www.facebook.com/photo.php?fbid=994694217273668&set=gm.596149233873103&type=3","472656846222343_596149233873103",NA,4,1,0
"408620806155776","Mai Thanh Nguyen","Cho em xin hỏi nhóm mình có ai dùng Mac không ạ, em dùng R studio trên Mac còn vướng, ai dùng confirm cho em hỏi với ạ. E cám ơn các anh các chị :>","2016-04-21T13:55:31+0000","status",NA,"472656846222343_595168557304504",NA,1,2,0
"1530258666992232","Namlun Didong","Phân chia dữ liệu là công đoạn phổ biến trước khi phân tích bằng mô hình, thông thường ta chia (ngẫu nhiên) data lớn thành 2 subset, một tên là training dùng để dựng mô hình, subset kia tên là testing, hay validation, dùng để kiểm định mô hình.

Mình xin chia sẻ với các bạn cách tạo 1 hàm duy nhất trong R để làm việc này, từ những lệnh cơ bản

splitdata=function(dataframe, seed=NULL,ratio=NULL) {
    if (!is.null(seed)) set.seed(seed)
    index <- 1:nrow(dataframe)
    trainid <- sample(index, trunc(length(index)*ratio))
    trainsubset <- dataframe[trainid, ]
    testsubset <- dataframe[-trainid, ]
    list(training=trainsubset,testing=testsubset)
}

Cách sử dụng hàm này:

1. Load data vào R: ví dụ data = read.csv(""dataset.csv"")

2. Áp dụng hàm splitdata trên data với cú pháp:

tên đối tượng split = splitdata(tên data, seed=con số tùy chọn, ratio=tỉ lệ mẫu train so với data ban đầu)

Ghi chú: tỉ lệ mẫu train tùy bạn chọn, nếu sample size đủ lớn bạn có thể đặt tỉ lệ này = 0.5; bằng không bạn có thể đặt tỉ lệ từ 0.7 tới 0.9 để đảm bảo đủ để dựng mô hình (quan trọng hơn).

con số seed tùy bạn chọn, để tái lập kết quả

Thí dụ: 

split=splitdata(data, seed=123, 0.7)

sẽ cắt data thành 2 phần, 70% dùng dựng mô hình, 30% còn lại dùng để kiểm định

3. Tạo đối tượng cho mẫu train và test

train=split$training
test=split$testing

Bây giờ bạn đã có 2 subset là train và test như ý rồi nha.","2016-04-21T19:34:48+0000","photo","https://www.facebook.com/photo.php?fbid=1180773038607465&set=gm.595270637294296&type=3","472656846222343_595270637294296",NA,55,9,10
"1651341764892571","Thanh Tuan Nguyen","Xin chào anh, chị và các bạn. MÌnh hiện nay đang đang sử dụng R để tính toán các chỉ tiêu biểu thị mức độ cạnh tranh (CI) giữa các cá thể láng giềng(neighbor trees) đối với mỗi cá thể trong lâm phần thông qua thước đo khoảng cách (Distance dependent competion measures). Để xác định mức độ cạnh tranh của cây láng giềng (competitor trees) đối với mỗi cây cá thể (subject tree) có thể sử dụng rất nhiều công thức. Ví dụ mình sử dụng công thức của Martin-EK để tính toán. 
CI=Σ Dj/Di×EXP (16×Lij/(Di+Dj))
Trong đó Dj là đường kính của các cây láng giềng competitor trees, Di là đường kính của  subject tree, Lij là khoảng cách từ mỗi competitor trees đến subject tree. Và những cây được coi là competior trees khi Lij<(Di+DJ)/8. Mục tiêu của mình là muốn xác định được tất cả các giá trị CI cho tất cả các cá thể của lâm phần. Trong đó CI được tính theo công thức của Martin-EK. MÌnh trước đã đọc tài liệu thì một số hướng dẫn có sử dụng gói spatstat trong R để tính toán.
neighbors<-applynbd(X,R=10,function(Y,…){Y$n-1})
Nhưng mình đang vướng mắc là trong gói này thì công thức applynbd R=10 là một số cố định, tức là người ta cố định Lij<10. Nhưng mục tiêu của mình là tính toán Lij thay đổi theo từng cá thể nghiên cứu: Lij<(Di+DJ)/8. 
Anh chị nào đã từng làm về vấn đề phân tích không gian trong R hoặc các phần mềm khác có thể chỉ dẫn dùm mình cách giải quyết được không? Xin cảm ơn diễn đàn.","2016-03-29T08:06:49+0000","status",NA,"472656846222343_584003525087674",NA,3,5,0
"1913258532222776","Tran Quy Phi","Giả lập trong R - Bài 2: Hàm replicate: lặp lại quá trình lấy mẫu
Trong thực tế nghiên cứu ta chỉ có 1 mẫu, và mọi kỹ thuật thống kê đều dựa trên cơ sở là mẫu đó sẽ được lặp lại vô hạn lần. Trong giả lập ta có thể tạo ra số lượng mẫu khá lớn từ quần thể để mô phỏng quá trình lặp lại đó. Có thể dùng lệnh sample với vòng lặp for nhưng cách đơn giản hơn trong R là dùng hàm replicate (lặp lại, tựa như repeat vậy)
#Lấy mẫu với cỡ là 3 từ tập 1,2,3,4,5. Lặp lại 8 lần
> replicate(8,sample(1:5,3))
[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,] 1 2 5 3 5 3 4 3
[2,] 4 3 4 4 3 4 5 5
[3,] 5 1 3 5 1 5 2 4
Để ý cách mà R cho ra kết quả. Ta có 8 cột là 8 mẫu. Mỗi mẫu có 3 số liệu.
Vì ta sẽ lưu ý đến các thống kê (tức là các kết quả từ mẫu) và phân bố của chúng, ví dụ phân bố của trung bình, độ lệch chuẩn… nên cú pháp sau là nên dùng:
# Lấy 8 mẫu, mỗi mẫu đều được tính mean và đưa các mean đó vào biến means.
> means <- replicate(8,mean(sample(1:5,3)))
#Kết quả các mean của các mẫu là:
> means
[1] 2.666667 2.000000 3.000000 3.666667 3.333333 2.666667 2.666667 2.666667
Có một cách khác là dùng hàm apply.
> samps <- replicate(5,sample(1:5,3))
> samps
[,1] [,2] [,3] [,4] [,5]
[1,] 2 2 2 5 2
[2,] 1 4 3 3 3
[3,] 4 1 1 1 5
muốn tính mean của các cột (tức là của 5 mẫu), ta dùng lệnh sau
apply(samps,2,mean)
[1] 2.333333 2.333333 2.000000 3.000000 3.333333
Lưu ý apply(samps,1,mean) tính theo hàng. 
Muốn tính sd của các mẫu ta dùng:
> apply(samps,2,sd)
[1] 1.527525 1.527525 1.000000 2.000000 1.527525
Ghi chú: ""replicate"" càng nhiều thì quá trình giả lập càng tốt, nhưng tùy thuộc vào máy tính bạn mạnh cỡ nào và bạn có kiên nhẫn không, có thể thử đến 10^4, 10^5... Nhưng nếu con chuột cứ xoay vòng vòng mà bạn không đợi nổi thì nên bấm phím esc (escape) và thử số lần lặp lại thấp xuống.","2016-03-28T04:18:43+0000","status",NA,"472656846222343_583314008489959",NA,19,5,1
"10155186029464497","Vipho Thita","Mọi người cho em thắc mắc chút ạ. Em có bảng như dưới đây, liệu có cách nào trực tiếp vẽ một cái grouped bar graph (trục x là vị trí) mà không cần đến dữ liệu gốc ko ạ?","2016-03-27T17:00:39+0000","photo","https://www.facebook.com/photo.php?fbid=10154154832524497&set=gm.582997971854896&type=3","472656846222343_582997971854896",NA,0,5,0
"1902396496656572","Huynh Kim An","xin anh/chị giúp: mình bị lỗi này 
library(car)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
  there is no package called ‘Rcpp’
Cách khắc phục ? cảm ơn !","2016-03-28T03:26:32+0000","status",NA,"472656846222343_583284615159565",NA,0,4,0
"1302673403158448","Phúc Tấn Võ","Chào anh chị!
Có anh chị nào đã hiện thực Markov trên R để phân tích chuỗi thời gian + dự đoán chưa ạ?
Nếu có rồi cho em được hỏi nhờ tí xíu. Vì thực ra em có đọc lý thuyết về Markov xong rồi đọc documentation của Markov trên R, Đọc xong thì hổng cảm nhận được nó giống nhau như nào :((
Thế nên hiện tại chưa hiện thực được Markov, nên có anh chị nào đã từng nhờ giúp em nó với :) 
Em cảm ơn nhiều
*PS: Em  hơi gà tiếng anh*","2016-03-26T09:13:10+0000","status",NA,"472656846222343_582100965277930",NA,0,0,0
"1277920608955066","Ngọc Quyên","Cả nhà gợi ý cho em với. Em có dữ liệu đo nước với thông số RPI là 3.3 6.3 5.3 4.6 7.5 2.1 5.2 6.3 7.2 0.5 0.6. Bây giờ em muốn tạo một biến mới là polluted status với điều kiện: nếu RPI <=2 thì gọi là ""non polluted"", nếu 2<RPI<3 là lightly polluted, nếu RPI>3 là severely polluted. Em nên dùng lệnh gì để tạo biến mới này ạ? Em cam on cả nhà.","2016-03-23T06:25:08+0000","status",NA,"472656846222343_580194092135284",NA,0,4,0
"1530258666992232","Namlun Didong","Trở lại cái data và mô hình hôm trước của bạn Dung Nguyen Chi về so sánh cân nặng những em bé giữa 7 ngày trong tuần. Đây là kết quả phân tích Bayes. Data quá bự (n=426.889) nên phải mất gần 4 giờ mới làm xong 4 chuỗi MCMC, mỗi chuỗi mất trung bình 1h. Kết quả không thay đổi","2016-03-12T15:54:01+0000","photo","https://www.facebook.com/photo.php?fbid=1145560145462088&set=gm.574161992738494&type=3","472656846222343_574161992738494",NA,43,10,1
"10154630775082982","Duy Thọ Nguyễn","Suy nghĩ thì nhiều nhưng càng viết càng thấy khó diễn đạt Y_Y. Link bài viết giới thiệu R trong việc phát triển data product trong doanh nghiệp.
Phần cuối demo 1 số interactive data visualization. Mọi người dùng R chắc hay dùng ggplot hay lattice để vẽ chart. Trong thực tế mình dùng  interactive data visualization nhiều hơn và nhờ nó mà mình dùng R thay thế các business intelligence tool luôn. 
Mọi người thấy chỗ nào chưa rõ thì mình trao đổi thêm nha. 
Nice weekend. <3

","2016-03-25T11:30:46+0000","link","http://rpubs.com/thonguyenduy/R-trong-doanh-nghiep","472656846222343_581514385336588",NA,24,4,0
"408620806155776","Mai Thanh Nguyen","Chào anh chị, E là Mai, học khoa Thống Kê toán Kinh tế Quốc Dân ạ.
Năm nay em có dự định qua Úc học chuyên ngành Business Dâta Analysis. Nhưng em cũng cũng chưa rõ lắm, anh chị tư vấn giúp em với ạ!
Em chân thành cám ơn anh chị ^^","2016-03-20T08:56:23+0000","status",NA,"472656846222343_578547652299928",NA,3,4,0
"10154630775082982","Duy Thọ Nguyễn","Với những template mới này thì anh chị em ai sử dụng rmarkdown để viết blog hoặc soạn thảo báo cáo khoa học sẽ dễ dàng và tiện hơn rất nhiều. <3
","2016-03-22T02:14:53+0000","link","http://blog.rstudio.org/2016/03/21/r-markdown-custom-formats/","472656846222343_579432048878155",NA,14,3,0
"10208725271269151","Dung Nguyen Chi","Chào các bạn. Vấn đề của mình như sau. Mình có một data frame có tên là love với 23 biến số từ Q01 đến Q23. Giá trị của mỗi biến ở dạng số nằm từ 1 đến 5 (dùng Likert 5). Mình muốn hỏi là có câu lệnh nào biến tất cả số 1 thành dạng biến kí tự, ví dụ, thành SD hay không?? Để mình đỡ phải làm tới 23 câu lệnh như ở mục ""Phân tích sơ bộ một số chỉ tiêu thống kê về các biến"" giống thế này: 

http://rpubs.com/chidungkt/164809

Cảm ơn sự quan tâm và chia sẻ với câu hỏi.","2016-03-24T19:36:46+0000","photo","https://www.facebook.com/photo.php?fbid=10206136181383522&set=gm.581137162040977&type=3","472656846222343_581137162040977",NA,10,7,1
"10208725271269151","Dung Nguyen Chi","Chào các Bác/chú/anh/chị/bạn (sau đây xin gọi chung là bạn). Vấn đề của mình như sau. Trước hết mình lấy bộ số liệu CPS1988 từ gói AER về 28155 lao động ở Hoa Kì năm 1988. Biến số mình quan tâm là mức lương theo tuần của mẫu nghiên cứu. 
>install.packages(""AER"")
>data(CPS1988,package=""AER"")

Mục tiêu của mình là xác định outliers - tức là bất kì giá trị nào mà: (1) hoặc là bé hơn Q1−1.5(IQR), (2) hoặc là lớn hơn Q3+1.5(IQR) theo tiêu chuẩn boxplot. Trong R chúng ta có thể liệt kê các giá trị này: 
>boxplot.stats(log(wage))$out
Chúng ta cũng có thể xác định số lượng % các outliers này so với toàn bộ mẫu quan sát: 
> length(boxplot.stats(log(wage))$out)/length(wage)
Kết quả tầm 1.56%. Nhưng con số này là bao gồm cả những người có mức lương cao bất thường và thấp bất thường. 

Câu hỏi của mình là: 

1. Cách nào để tìm ra số lượng các outliers bé hơn 4.334821 = Q1−1.5(IQR) và lớn hơn 8.061101 = Q3+1.5(IQR) hay không? 
2. Có lệnh nào hiện ra hai giá trị Q1−1.5(IQR) và Q3+1.5(IQR) một cách nhanh chóng để đỡ tính thủ công từng bước không? 

Cảm ơn các bạn rất nhiều.","2016-03-19T16:45:52+0000","status",NA,"472656846222343_578223055665721",NA,8,2,1
"10154630775082982","Duy Thọ Nguyễn","Chào mọi người 
Mình biết và dùng R từ năm 2010, tuy nhiên ở góc độ là người phát triển phần mềm phân tích sensory data chạy trên nền Windows desktop bằng ngôn ngữ C#, dựa vào 1 số hàm package đã có trên R. 

Hiện tại thì mình dùng R để phát triển Bussiness Intelligence dashboard trên nền Shiny (web framework của RStudio). Do tính chất công việc nên mình làm nhiều với nhiều món thuộc về phần mềm như database server, RStudio server, Shiny server .... 

Rất vui được làm quen với mọi người, đặc biệt là các bạn sử dụng R trong môi trường doanh nghiệp, phát triển các data product hỗ trợ cho business và marketing.","2016-03-21T08:32:01+0000","status",NA,"472656846222343_579016445586382",NA,25,3,0
"1530258666992232","Namlun Didong","Như dự kiến, mình xin giới thiệu bài đầu tiên trong serie glm; bài này có mục tiêu kép là: 

(1) Ngược = Sử dụng glm và AIC để xác định kiểu phân phối phù hợp nhất cho 1 biến liên tục;

 và (2) Xuôi =  Xác định kiểu phân phối cho Y trước khi tiến hành dựng bất kì model nào với Y là response variable.

Package được sử dụng là gamlss. Đây là package mạnh nhất mình từng biết về glm.","2016-03-13T16:56:38+0000","photo","https://www.facebook.com/photo.php?fbid=1146384792046290&set=gm.574763652678328&type=3","472656846222343_574763652678328",NA,51,4,5
"1454689051217234","Nguoi Giu Ki Niem","Kính gửi các thành viên.
Em có bộ số lieu và hướng phân tích như sau. Em có bộ số lieu về giám sát tỉ lệ nhiễm HIV ở tỉnh X như sau:
năm 2011: số người nhiễm 67, tổng số đối tượng xét nghiệm: 307
năm 2012: số người nhiễm 78, tổng số đối tượng xét nghiệm: 540
năm 2013: số người nhiễm 58, tổng số đối tượng xét nghiệm: 670
năm 2014: số người nhiễm 89, tổng số đối tượng xét nghiệm: 476
năm 2015: số người nhiễm 69, tổng số đối tượng xét nghiệm: 549
Câu hỏi: Em muốn nhận định Xu hướng (trend) như thế nào và tính or như thế nào (em lấy năm 2011 làm Ref)
Xin chân thành cảm ơn","2016-03-16T09:00:06+0000","status",NA,"472656846222343_576391872515506",NA,8,10,2
"10208725271269151","Dung Nguyen Chi","Phân tích trích dẫn. 

Cái này mình nghĩ rất hay. Mọi người xem và góp ý nhé. 

","2016-03-23T04:40:11+0000","link","http://rpubs.com/chidungkt/164445","472656846222343_580163095471717",NA,25,4,0
"1205401282846677","Duy Tran","Em chào các anh chị,
Hiện em đang sử dụng R để giải mô hình hồi qui logistic đa biến. Mô hình của em được code như sau:

> mydata$Choices.ids<-factor(rep(1:2,276),labels=c(""Yes"",""No""))
> mode.choice<-mlogit(Choices~Fee + Rate.h + Distance, data = mydata, shape=""long"", alt.var=""Choices.ids"")
Error in solve.default(H, g[!fixed]) : 
  system is computationally singular: reciprocal condition number = 9.28609e-22.

Ở đây, ""Choice"" là biến phụ thuộc với giá trị (0/1). Các biến độc lập còn lại được code dưới dạng numeric ạ. 
Sau khi thực hiện trên R thì gặp phải vấn đề như trên ạ. Trong trường hợp này em phải xử lí thế nào ạ? có phải data của em có vấn đề gì không ạ?
Mong mọi giúp em với, em chân thành cảm ơn ạ.","2016-03-21T08:41:08+0000","status",NA,"472656846222343_579017905586236",NA,0,1,0
"10211215571238655","Nguyen Thi Hanh Tien","LỖI VỚI Rmarkdown.
Khi tôi Knit thì báo lỗi như sau (góc dưới trái màn hình). 
Nhờ thầy cô và các bạn chỉ cách khắc phục giúp ạ. Cảm ơn mọi người!","2016-03-22T11:07:09+0000","photo","https://www.facebook.com/photo.php?fbid=10208133876078202&set=gm.579659148855445&type=3","472656846222343_579659148855445",NA,0,2,0
"1913258532222776","Tran Quy Phi","Giả lập trong R. Bài 1: Hàm sample
Ghi chú: Bài này mình viết cho statistics.vn, trong khi chờ ""phục dựng"" trang này xin post lên đây cho anh em đọc đỡ buồn
Bài 1: Hàm sample-Lấy ngẫu nhiên một mẫu
Có hai cách dùng hàm sample:
Bài này nói cách lấy ngẫu nhiên (đơn, simple random) một mẫu từ một tập số liệu
> x <- c(1,2,3,4,5)
#lấy ngẫu nhiên 2 số liệu từ x
> sample(x,2) 
[1] 2 5
#có thể dùng đơn giản hơn:
> sample(1:5,2) 
[1] 1 3
Để ý rằng có hai cách lấy mẫu ngẫu nhiên: lấy mẫu có hoàn lại và không hoàn lại. Tham số của sample phục vụ cho mục đích này là replace=TRUE hoặc FALSE. Mặc địch (không ghi ra, như  ví dụ trên) là FALSE.
# Lấy ngẫu nhiên có hoàn lại, kết quả có số 1 xuất hiện hai lần.
> sample(1:5,3,replace=TRUE) 
[1] 5 1 1
Lưu ý rằng với lấy mẫu ngẫu nhiên không hoàn lại thì cỡ của mẫu phải nhỏ hơn cỡ của tập số liệu mà từ đó ta lấy mẫu, nếu không R sẽ báo lỗi.
#Lấy một mẫu cỡ bằng 10 từ tập có 5 số liệu nhưng có không hoàn lại
> sample(1:5,10)
Error in sample(1:5, 10) : cannot take a sample larger than the population when 'replace = FALSE'
Trong khi đó thì:
> sample(1:5,10,replace=TRUE) 
[1] 4 5 4 3 3 3 5 2 2 1
Hàm sample có thể dùng để tạo một dãy số phục vụ cho việc lấy mẫu ngẫu nhiên đơn. Giả sử ta có danh sách để chọn mẫu với thứ tự mã là 1 đến 2000, ta cần chọn 100 mẫu ngẫu nhiên đơn từ danh sách này.
rand.list <- sample(1:2000,100)
# Xếp thứ tự để dễ lấy
sort(rand.list)
[1] 8 23 28 38 40 48 52 71 73 82 83 95 100 101 105
[16] 107 111 113 136 140 150 167 170 172 173 186 232 238 239 267
[31] 275 281 282 290 304 309 318 320 332 351 354 360 362 367 376
[46] 388 408 409 421 435 443 454 458 461 473 480 523 526 530 535
[61] 539 549 557 559 562 590 611 624 631 652 661 671 673 682 688
[76] 690 697 705 707 728 739 749 752 753 765 777 779 793 810 819
[91] 824 869 876 885 894 929 944 976 999 1000
#Giả_lập #sample","2016-03-22T09:15:19+0000","status",NA,"472656846222343_579597928861567",NA,23,3,1
"1772393016120376","Cao Nhật Linh","Các bạn cho mình hỏi, có lệnh nào trong R để xem lại các lệnh đã soạn thảo sau khi lỡ ấn Ctrl+L (clear màn hình) không? Xin cám ơn.","2016-03-22T14:13:49+0000","status",NA,"472656846222343_579761315511895",NA,0,5,0
"1590214037658597","Phuc Nguyen Quang","Hỏi về MANOVA

Kính chào các anh/chị,

Tôi đang xử lý MANOVA nhưng không hiểu s, m, và n là gì, ý nghĩa thế nào và đánh giá thế nào.
Ngoài ra các kiểm nghiệm theo Wilks', Lawley-Hotelling, Pillai's và Roy's thì dùng cái nào phổ biến hơn.
Kính nhờ các anh/chị chỉ giúp, cám ơn nhiều.

Ví dụ cho 1 phân tích MANOVA dưới đây
MANOVA for Loại BTN
s = 1    m = 0.5    n = 12.5

                       Test             DF
Criterion                      Statistic      F  Num  Denom      P
Wilks'                             0.55518  7.211    3     27  0.001
Lawley-Hotelling            0.80121  7.211    3     27  0.001
Pillai's                            0.44482  7.211    3     27  0.001
Roy's                             0.80121","2016-03-22T06:04:34+0000","status",NA,"472656846222343_579530078868352",NA,3,2,0
"1102544753188585","Hung Nguyen","Nhờ các anh/chị hướng dẫn mình cách tích cỡ mẫu (hoặc công thức tính) trong một nghiên cứu can thiệp cộng đồng (nghiên cứu này mình sẽ so sánh tỷ lệ mắc mới một bệnh trước và sau can thiệp).
Xin cảm ơn trước ạ","2016-03-21T03:31:11+0000","status",NA,"472656846222343_578936738927686",NA,1,13,0
"1459973230693320","An Corleone Vo","Cho em hỏi có cao thủ Z-tree nào không ạ? :D","2016-03-21T13:32:58+0000","status",NA,"472656846222343_579136298907730",NA,0,0,0
"1590214037658597","Phuc Nguyen Quang","Chào các anh/chị/bạn
Mình có vấn đề về đánh giá kết quả học tập cho 5 khóa liên tiếp K3, K4, K5, K6, K7 với 4 mức độ: Giỏi, Khá, Trung bình, Yếu.
Mình đã dùng Chi-square và kết quả là có sự khác biệt giữa các khóa về kết quả học tập với p<0.05 với xu hướng thấp dần.

Tiếp theo nhờ các anh/chị tư vấn giúp về mô hình nhé
Cám ơn mọi người nhiều.","2016-03-19T15:22:55+0000","photo","https://www.facebook.com/photo.php?fbid=1253585921321412&set=gm.578185342336159&type=3","472656846222343_578185342336159",NA,3,4,0
"1323806731019670","Vien Van Nguyen","Chào các anh chị,

Em có một file Stata. Em đọc file bằng R thì bị lỗi font chữ (như hình bên dưới).

Anh chị có thể giúp đỡ em để đọc file này không bị lỗi font như vậy không?

Em cảm ơn anh chị.","2016-03-15T13:03:51+0000","photo","https://www.facebook.com/photo.php?fbid=1025053840894962&set=gm.575855202569173&type=3","472656846222343_575855202569173",NA,2,4,0
"1753940828188796","Nguyen Phi Hieu","Chào các Bác/Chú/Anh/Chị/Bạn, mình tên là Nguyễn Phi Hiếu, hiện là sinh viên Đại học Ngoại Thương.
Trước hết cho mình xin xưng hô là mình và các bạn cho gọn, chữ không hề có ý bất kính nào đối với các bậc tiền bối trong nhóm.
Mình hiện đang sử dụng phần mềm R để viết luận văn tốt nghiệp, chuyên ngành tài chính ngân hàng. Mình sử dụng R chưa lâu, nhưng nhận thấy đây là một công cụ rất mạnh và có phần hơn hẳn Stata hay Eviews. Vì mới sử dụng nên mình có một vài thắc mắc nhỏ  rất mong sự chỉ bảo của các bạn. Cụ thể là:
1, Khi trình bày các kết quả phân tích từ R, mình có cần ghi dòng lệnh đã thực hiện hay không ạ?
2, Khi copy kết quả vào word thì các kết quả trong R nhảy lung tung hết cả lên, trong khi kết quả trình bày trong R thì khá đẹp. Liệu có cách nào truy xuất ra word mà vẫn mang tính khoa học và thẩm mỹ như trong R không ạ?
3, Trong quá trình làm luận văn, có một số gói hay câu lệnh mà mình chạy hoài không được, muốn nhờ sự giúp đỡ từ cộng đồng mình, nhưng ngại hỏi vì sợ cho là spam, hy vọng qua bài post này, thứ nhất là làm quen, thứ hai là tham khảo ý kiến từ các bạn để chạy mô hình tốt hơn, và thứ ba là sau này khi thực hiện nhiều nghiên cứu khác có thể nhờ các bạn tư vấn thêm cách giải quyết những trục trặc có thể phát sinh.
Cảm ơn các bạn đã quan tâm.
Chúc cả nhà một ngày tốt lành.","2016-03-09T02:49:32+0000","status",NA,"472656846222343_572732192881474",NA,2,9,0
"10208725271269151","Dung Nguyen Chi","Chào các Bác/chú/anh/chị/bạn (sau đây xin gọi chung là bạn). Vấn đề của mình như sau. Khi cài đặt gói hlfights, R cho ra thông báo là ""package ‘hlfights’ is not available (for R version 3.2.4)"" (như hình). Trong tình huống này cần xử lý thế nào ạ? 

Cảm ơn mọi người rất nhiều.","2016-03-20T20:27:45+0000","photo","https://www.facebook.com/photo.php?fbid=10206087376243424&set=gm.578809215607105&type=3","472656846222343_578809215607105",NA,4,3,0
"753069788203959","Thiên Thanh","1.124 Find some values of z. The Wechsler Adult
Intelligence Scale (WAIS) is the most common
“IQ test.” The scale of scores is set separately for
each age group and is approximately Normal with
mean 100 and standard deviation 15. People with
WAIS scores below 70 are considered mentally
retarded when, for example, applying for Social
Security disability benefits. What percent of adults
are retarded by this criterion?
làm giúp mình với các bạn ơi","2016-03-20T12:43:57+0000","status",NA,"472656846222343_578632375624789",NA,0,1,0
"1913258532222776","Tran Quy Phi","Số thành viên đã vượt con số 2k.
Các bạn thân mến, nhóm của mình đã đạt đến con số 2003 thành viên.
Mong nhóm được từng thành viên tích cực tham gia, sự chia sẻ ngày càng phong phú và bổ ích.
Chúc mọi người một ngày mới tốt lành.","2016-03-20T22:14:46+0000","status",NA,"472656846222343_578846525603374",NA,122,0,1
"1302673403158448","Phúc Tấn Võ","Xin chào anh chị, các bạn!
Em có đọc trong mô hình ARIMA, hiện có Khái niệm tự tương quan, trong đó có nói đến ""sự tương quan của một biến với chính nó theo độ trễ thời gian"".
Theo em hiểu thì độ trễ thời gian của một biến S là doanh số bán ra thì sẽ là số bán ra trong tháng đầu tiên là độ trễ k =1, rồi tháng tiếp theo sẽ là k = 2, 3, 4!
Theo em hiểu như vậy thì có đúng hay hông? Ai có thể giải thích kỹ hơn chút, em cảm ơn nhiều...!
PS: hiện e đang theo cái này cơ mà hơi mù mờ ạ :((","2016-03-18T12:09:51+0000","status",NA,"472656846222343_577614939059866",NA,1,2,0
"10208725271269151","Dung Nguyen Chi","Chào các Bác/chú/anh/chị/bạn (sau đây xin gọi chung là bạn). Vấn đề của  mình như sau. Mình lấy data từ: 

http://www.scimagojr.com/journalrank.php?category=0&area=0&year=2014&country=&order=t&page=0&min=0&min_type=cd&out=csv

Sẽ được một bảng Excel 22878 dòng. Khi cho R đọc dữ liệu, có vẻ như không đủ bộ nhớ vì R cho râ thông báo như sau: 

Mình muốn các bạn trả lời giùm mình hai câu hỏi sau: 
1. Liệu rằng có cách nào để R đọc file dữ liệu (cứ tạm gọi là lớn) này không? 

2. Việc download data từ website ở dạng .xlsx là bước trung gian rồi lại cho R đọc data này rất lằng nhằng. Liệu có cách nào cho R đọc data một cách trực tiếp từ website trên không? 

Cảm ơn các bạn rất nhiều.","2016-03-17T16:47:54+0000","photo","https://www.facebook.com/photo.php?fbid=10206058042070088&set=gm.577176252437068&type=3","472656846222343_577176252437068",NA,13,11,1
"736036339900784","Mai Anh Tuan","Xin chào các anh chị, em gặp tình huống về thiết kế nghiên cứu và tính cỡ mãu trong nghiên cứu lâm sàng mong các anh chị cho ý kiến. Bạn em muốn đánh giá hiệu quả của 1 phương pháp phẫu thuật mới điều trị dị tật lỗ  tiểu lệch thấp ở trẻ em. Trong hoàn cảnh NCS ở VN phải tự bỏ tiền nghiên cứu nên không thể thiết kế nhóm chứng ạ (tức là so sánh với một phương pháp mổ trước đó). Trên thực tế ước tính có  tầm 70 bệnh nhân mắc bệnh này vào viện/1 năm. sẽ mổ hết các bệnh nhân này sau đó mời bệnh nhân đến khám lại sau mổ 3 tháng, 6 tháng 12 tháng và 24 tháng để kiểm tra xem có các biến chứng dò (Y/N) qua đó gián tiếp đánh giá hiệu quả phẫu thuật. Tỷ lệ biến chứng dò theo nghiên cứu trước là 11%. Thông tin thêm là các GS trong hội đồng nói đây là mổ và ông này làm NCS nên phải thiết kế can thiệp. Với các dữ kiện trên, (trừ dữ kiện cuối). Xin các anh chị tư vấn cho thiết kế nào cò thể  phù hợp cho NC này.","2016-03-18T10:45:39+0000","status",NA,"472656846222343_577570362397657",NA,0,3,0
"10212790460500196","Hoang Viet Anh","Thêm 1 cách vẽ bản đồ hành chính đơn giản là dùng package raster

library(raster)
tinh <- getData('GADM', country = ""VNM"", level = 1) ## muốn lấy đến huyện thì để level=2
alt <- getData('alt', country = ""VNM"")
plot(alt)
plot(tinh, add=T)

Ngoài dữ liệu hành chính thì package raster còn có rất nhiều dữ liệu khác, như độ cao, bioclimate.","2016-03-06T18:01:50+0000","photo","https://www.facebook.com/photo.php?fbid=10209318274537717&set=gm.571821272972566&type=3","472656846222343_571821272972566",NA,11,4,3
"1454689051217234","Nguoi Giu Ki Niem","Nếu ai đã đọc sách Thống kê của thầy Tuấn sẽ thấy cụm từ phần dư (residual).  Tại sao phần dư (Residual) trong thống kê lại quan trọng? Thầy và các đồng nghiệp giải thích rõ giúp em hiểu them cặn kẽ với ạ.","2016-03-13T10:38:15+0000","status",NA,"472656846222343_574597272694966",NA,7,13,0
"1530258666992232","Namlun Didong","Mình xin chia sẻ một vài cách để vẽ đồ thị correlation matrix (hay còn gọi là correlation heatmap hay correlograms) bằng 4 packages khác nhau trong R.

Correlation plot rất hữu ích khi báo cáo kết quả nghiên cứu dưới dạng slides powerpoint hoặc poster, tuy nhiên không thích hợp cho bài báo khoa học.

","2016-03-06T12:05:28+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPX1FwVFRRWHF0c0E/view?usp=sharing","472656846222343_571706212984072",NA,69,5,0
"1849942691933972","Nguyen","Em đang thử vẽ một biểu đồ thanh để biểu diễn mức độ chi tiêu cá nhân qua từng tháng (trục hoành: tháng trong năm) và trục tung là số tiền chi tiêu.

Bên cạnh đó, em muốn thêm 1 line biểu diễn 1 chỉ tiêu khác (i.e số lần đi ăn đám cưới).

Như vậy trên đồ thị này, trục tung sẽ bao gồm 2 đơn vị (VND và số lần).

Anh chị có thể gợi ý giúp em vẽ biểu đồ này được không ạ?","2016-03-15T00:19:25+0000","status",NA,"472656846222343_575549432599750",NA,0,1,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-14T07:38:17+0000","photo","https://www.facebook.com/photo.php?fbid=1749262115289086&set=gm.575100345977992&type=3","472656846222343_575100345977992",NA,25,6,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-14T09:11:37+0000","photo","https://www.facebook.com/photo.php?fbid=1749276305287667&set=gm.575155229305837&type=3","472656846222343_575155229305837",NA,7,0,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-14T07:40:14+0000","photo","https://www.facebook.com/photo.php?fbid=1749262368622394&set=gm.575102242644469&type=3","472656846222343_575102242644469",NA,14,0,0
"10208314748176383","Le Manh Hung","Chào các anh chị, em có một câu hỏi như này, em có hai mô hình, một mô hình  dùng phương pháp thông thường, và một mô mình thêm một thuật toán để cải thiện hiệu quả. Như ở dưới forecast1 là kết quả đánh giá chất lượng của mô hình chưa cải tiến, forecast2 là kết quả đánh giá chất lượng của mô hình sau cải tiến. Nói thêm là giá trị càng cao thì hiệu quả mô phỏng các tốt.
forecast1 = c(0.626,0.571,0.606, 0.612,0.605,0.599,0.612,0.611,0.610) 
forecast2 = c(0.665,0.626,0.630, 0.645,0.666,0.615,0.678,0.658,0.677) 

Các giá trị này không theo luật phân phối chuẩn, vì thế em dùng kiểm định Wilcoxon để so sánh kết quả mô phỏng trung bình giữa hai mô hình.
wilcox.test(jitter(forecast1),jitter(forecast2))

Kết quả như dưới
Wilcoxon rank sum test

data:  jitter(forecast1) and jitter(forecast2)
W = 1, p-value = 8.227e-05
alternative hypothesis: true location shift is not equal to 0

Dựa vào kết quả này p-value < 0.05, em có thể khẳng định là mô hình sau khi cải tiến có kết quả tốt hơn mô hình chưa cải tiến được không ạ?

Em xin cảm ơn.","2016-03-11T14:33:44+0000","status",NA,"472656846222343_573717799449580",NA,3,2,0
"10202755255959930","Ngài Phạm","Mong được mọi người giúp đỡ!!!
Chào mọi người,thông qua Fb của thầy Tuấn thì e được biết và hiện tại đang tập làm quen với R. Khi thực hành đến phần đọc dữ liệu từ file excel thì khi e nhập lệnh read.xls thì liên tục gặp lỗi như thế này
""perl1 warning: Setting locale failed.
perl2 warning: Please check that your locale settings:
 LC_ALL = (unset),
 LANG = ""en_JP.UTF-8""
    are supported and installed on your system.
perl2 warning: Falling back to the standard locale (""C"").""
E tìm hiểu qua google thì có sử dụng lệnh 
""export LC_ALL=$LANG""
""echo ""export LC_ALL=$LANG"" >> ~/.zshrc""
để sửa nhưng tình trạng vẫn không đổi. 
E hiện dùng Mac OS X 10.7.5 còn R bản 3.1.2 còn gói gdata là bản 2.13.3.
Mong mọi người hỗ trợ để em sớm có thể được luyện tập tiếp.
E cảm ơn!","2016-03-13T14:18:26+0000","status",NA,"472656846222343_574693679351992",NA,1,8,0
"1530258666992232","Namlun Didong","Thông điệp của cái hình này đó là GLM cực kì quan trọng (càn khôn đại na di bí kíp) trong thống kê.

Mình sẽ bàn sâu về Generalized linear model trong vài ngày tới, thông qua thí dụ. Và nhận thêm chỉ giáo từ các cao thủ trong này. Bạn nào có data và câu hỏi nghiên cứu cứ chia sẻ, ta sẽ chuyển chúng thành ngôn ngữ model xem sao...","2016-03-11T10:19:12+0000","photo","https://www.facebook.com/photo.php?fbid=1144634028888033&set=gm.573642309457129&type=3","472656846222343_573642309457129",NA,49,5,4
"1530258666992232","Namlun Didong","Xin chào các bạn. 

Mình là Nam, làm trong ngành kỹ thuật Y học, cụ thể là sinh lý hô hấp và giấc ngủ. Khác với nhiều người, mình bị bắt buộc phải học và sử dụng thống kê (không có sự chọn lựa). 

Trước năm 2009, kiến thức thống kê của mình chỉ hơn Zéro 1 chút còn kỹ năng thì chỉ gói gọn trong menu của SPSS và Medcalc. Năm 2010, mình « được » học lại toàn bộ lý thuyết thống kê sơ cấp trong chương trình dự bị Y khoa tại Paris, Pháp. Trong 5 năm sau đó, mình buộc phải làm bạn đồng hành với thống kê, sử dụng nó liên tục, hằng ngày như một phương cách để sống còn. Cụ thể, từ năm 2012 đến nay mình giống như 1 contract hitman, vô danh, vô hình. Mình phân tích dữ liệu cho một số khách hàng là bác sĩ, nghiên cứu sinh, nhóm nghiên cứu độc lập (non academic)…, đổi lại bằng thù lao, hoặc mối quan hệ. 

Do đó, mỗi ngày mình đều dành 1-2 h để đọc sách, viết code và thử nghiệm các phương pháp thống kê trên nhiều phần mềm khác nhau. Thống kê đối với mình vừa là công cụ kiếm sống, vừa là vũ khí mềm dẻo, đa dụng để chuẩn bị cho mình khả năng thích nghi cao cho mọi hoàn cảnh, lĩnh vực chuyên môn ; con đường duy nhất cho phép mình hòa nhập trở lại nghiên cứu dòng chính thống sau nhiều năm lang thang trên giang hồ. 

Mình sử dụng R từ năm 2012, ban đầu chỉ xem nó như một công cụ thay thế để làm những việc mà các commercial package không thể làm, tuy nhiên với sự phát triển nhanh chóng của R, bắt buộc mình phải khai thác nó sâu rộng hơn trong thời gian tới. 

Như 1 con kiến tìm ra cái tổ mới, mình rất vui được tham gia nhóm của các bạn, chắc chắn mình sẽ được học hỏi rất nhiều từ mọi người, và từ phía mình, hy vọng có thể chia sẻ với các bạn những viên kẹo cái bánh nho nhỏ mà mình nhặt được. Chúc các bạn thành công.","2016-03-04T08:01:47+0000","status",NA,"472656846222343_570854503069243",NA,81,2,0
"10206482564502553","Thanh Le","Ngoài rmarkdown dùng để trình bày, tạo báo cáo đẹp với R, có một package khác - ReporteRs -  cũng rất hữu ích, đặc biệt là trình bày bảng biểu theo chuẩn hay được trình bày trong các bài báo và  hỗ trợ export ra word/powerpoint. Hướng dẫn và các ví dụ minh họa có thể tham khảo tại ","2016-03-10T05:01:31+0000","link","http://davidgohel.github.io/ReporteRs/flextable_examples.html","472656846222343_573144226173604",NA,29,4,0
"10208915968716100","Tran Ngoc Dang","Vấn đề thứ 5 của trị số P (tiếp theo bài viết Bốn vấn đề của trị số P của thầy Tuấn).

Ở post trước thầy Tuấn đã nêu ra 4 vấn đề của trị số P. Nay mình xin chia sẻ vấn đề thứ 5 được đề cập ở chương 11 trong sách Doing Bayesian Analysis, mà theo anh Namlun Didong là kinh thánh của trường phái Bayes ^.^ mong được thảo luận thêm với mọi người.

Vấn đề 5: trị số P phụ thuộc vào ""intention stoping rule"" tạm dịch là ""ý định dừng thử nghiệm""

Ví dụ: chúng ta muốn kiểm định xem một đồng xu có bị sai lệch hay không (H0: theta=0.5). nghiên cứu viên A tung đồng xu và quan sát được kết quả 7 heads trong 24 lần tung xu: TTHHTTHTTTTTTTTTHTTHHTTH

Có 3 trường hợp có thể xảy ra khi ncv A kết thúc thử nghiệm và cho ra kết quả như trên:
1. TH1: ncv A dừng thử nghiệm sau khi số lần tung xu đủ 24 lần
2. TH2:  ncv A dừng thử nghiệm sau khi có đủ 7 lần heads xuất hiện
3. TH3: ncv A dừng thử nghiệm sau một khoảng thời gian nào đó, ví dụ trong trường hợp này sau 2 phút

Thật ngạc nhiên, dù kết quả thử nghiệm là giống nhau, nhưng p value 2 đuôi ở mỗi trường hợp là khác nhau. P value lần lượt là 0.064, 0.034, 0.048 tương ứng TH1, 2, 3 (cách tính cụ thể xin xem trong sách). Như vậy ở TH1 chúng ta chấp nhận Ho, ở TH2 chúng ta bác bỏ Ho, còn trường hợp 3  thì hơi khó kết luận vì p value gần bằng 0.05...

Theo mình đây là điểm chí tử của p value. Vì nếu một chỉ số phản ánh khách quan thì nó không nên phụ thuộc vào ý định của người nghiên cứu. Mình cũng có một thắc mắc muốn thảo luận với mọi người là tại sao trong các bài báo nghiên cứu thì người ta chỉ báo cáo chỉ số p mà không đề cập gì đến intention stoping rule này nhỉ???","2016-03-12T14:55:19+0000","status",NA,"472656846222343_574140516073975",NA,8,1,0
"1753940828188796","Nguyen Phi Hieu","Chào các anh/chị/chú/bác,
em/con có một câu hỏi về CUSUM test trong R. Đầu tiên là em/con có 1 chuỗi dữ liệu và dùng mô hình AR(5)-GARCH(1,1) để ước lượng, sau đó dùng CUSUM test cho phần dư thu được. Code trong R của em/con như thế này ạ:
library(fGarch)
fit.garch11=garchFit(~arma(5,0)+garch(1,1),data=ret,cond.dist = ""sstd"")
res.garch=residuals(fit.garch11)
form.garch=formula(fit.garch11)
library(strucchange)
data.test=fit.garch11@data
data.test=cbind(data.test, res.garch)
data.test.mts=ts(data.test)
cusum.test=efp(form.garch,type=""Rec-CUSUM"",data=data.test.mts)
Kết quả R trả về như thế này ạ:
Error in if (N <= 0) NULL else seq(N) : 
  missing value where TRUE/FALSE needed
Em/con cũng có tham khảo về câu lệnh này trong R và cũng bắt chước làm, để xem class của các ""biến"" trong câu lệnh của họ như thế nào (link: http://epub.wu.ac.at/1124/1/document.pdf), nhưng kết quả là class các biến đều giống nhau, con so sánh 2 data thì thấy data em/ con có 5 số không trong res.garch, em/ con không nghĩ nó là missing value vì có giá trị là bằng 0, con sử dụng lệnh na.omit để loại bỏ các biến NA nhưng R trả về không loại bỏ giá trị nào.
Em/con thật sự không hiểu vấn đề đang đối mặt ở đây là gì, mong các anh/chị/chú/bác giúp ạ.
Em/con xin cảm ơn các tiền bối rất nhiều ạ.","2016-03-12T07:17:08+0000","link","http://epub.wu.ac.at/1124/1/document.pdf","472656846222343_573979209423439",NA,1,1,0
"1530258666992232","Namlun Didong","R 3.2 đã cập nhật phiên bản mới nhất (và cuối cùng) là 3.2.4, ""Very Secure Dishes"" hôm qua. Mình đã install bản 64 bit và update tất cả packages thành công trong R studio. 

Phiên bản 3.3 dự kiến ra mắt ngày 14/4 sắp tới.

","2016-03-12T10:13:05+0000","link","http://www.r-bloggers.com/r-3-2-4-released/","472656846222343_574037759417584",NA,56,0,0
"10203062627643544","Son Nghiem","Nghỉ giải lao, thử trò đếm chữ yêu thích của GS Nguyễn Tuấn với bài nói gần đây của tổng Trọng. Chưa ưng ý lắm, xin mời mọi người góp ý :) 
---
library(XML)
# Đọc từ HTML
doc.html <- htmlTreeParse('http://vov.vn/chinh-tri/dang/toan-van-phat-bieu-cua-tong-bi-thu-khai-mac-hoi-nghi-tu-2-khoa-xii-487616.vov',useInternal = TRUE)
# Chuyển thành ký tự
doc.text <- unlist(xpathApply(doc.html, '//p', xmlValue))

# Thay một số chữ và ký tự không có nghĩa
doc.text <- gsub('\\n', ' ', doc.text)
doc.text <- gsub('\\r', ' ', doc.text)
doc.text <- gsub('\\t', ' ', doc.text)
doc.text <- gsub('-', ' ', doc.text)
doc.text <- gsub('và', '', doc.text)
doc.text <- gsub('của', '', doc.text)
doc.text <- gsub('các', '', doc.text)

# Nối tất cả thành môt chuỗi
Trong <- paste(doc.text, collapse = ' ')
# Tách ra từng từ
Trong<-strsplit(Trong, "" "")
#Tạo dataframe
df<-data.frame(sort(table(Trong), decreasing = TRUE))
colnames(df) <- ""SoCau""
# Xem thử
head(df,30)

#Cần loại bỏ cái đầu tiên (ký tự rỗng và lấy các từ xuất hiện ít nhất 3 lần)
df<-subset(df, SoCau<250&SoCau>3)

#Vẽ đám mây chữ
library(wordcloud)
require(RColorBrewer)
pal <- brewer.pal(9, ""YlGnBu"")
pal <- pal[-(1:4)]
wordcloud(words = row.names(df), freq = df$SoCau, min.freq=3, random.order = F, colors = pal)

#Vẽ biểu đồ (nhưng tiếng Việt không nhìn ra, tìm hiểu sau)
library(ggplot2)
df2<-subset(df, SoCau>10)
ggplot(df2, aes(x = rownames(df2), y = SoCau)) + geom_bar(stat = ""identity"") +xlab(""Chữ"") + ylab(""Số lần"") + coord_flip()
---- Hình thu được như sau","2016-03-11T01:38:14+0000","photo","https://www.facebook.com/photo.php?fbid=10201603875775659&set=gm.573511272803566&type=3","472656846222343_573511272803566",NA,35,23,2
"1618030694879752","Tai Chau HO","Chào anh chị, em có một bảng như trong hình và muốn vẽ plot nó dạng như heatmap nhưng thay vì là scale màu thì nó sẽ hiện chữ số có giá trị bằng value ở ô tương ứng, các biến categorical thì để ở hai trục x và y thì làm như thế nào nhỉ? Em mò mãi không ra...","2016-03-11T13:24:28+0000","photo","https://www.facebook.com/photo.php?fbid=1274059459276879&set=gm.573696256118401&type=3","472656846222343_573696256118401",NA,1,0,0
"1277920608955066","Ngọc Quyên","Em chao ca nha! Em co bai toan dang phan van the nay a. Em lấy mẫu nước trước khi xử lý phan tich 1 chi tieu A có kết qua la 4.3 4.5 4.8 4.9 4.2 4.6 4.7 4.0 4.1 4.10. Sau khi xu lý em lay mau nuoc tai 3 vi tri khac nhau va co ket qua: Site 1: 6.7 6.8 6.9 6.10 6.11 6.3 6.2; site 2: 5.6 5.2 5.10 5.18 5.2 5.6 5.1; site 3: 4.7 4.8 6.8 9.4 6.2 6.7 8.4. Vấn đề là em muốn đanh giá hiệu qua cua viec xu ly nuoc. Em nen danh gia yeu to nao a? Trong R thi su dung goi package nao a? Em cam on nhieu a!","2016-03-11T03:15:58+0000","status",NA,"472656846222343_573537949467565",NA,3,1,0
"10203062627643544","Son Nghiem","Lược dịch bài hát về số P sáng nay. Bài này châm biếm và cảnh báo phải cẩn thận khi giải thích kết quả từ số P. Theo tôi thì nếu P cao cũng là một kết quả và không có gì đáng ngại. Một số biên tập và đồng nghiệp bình duyệt cũng biết vậy. Bản thân tôi cũng có hai bài với số P cao được đăng trên tạp chí A*! Dưới đây là phần lược dịch. Một số chữ không rõ tiếng Việt giọi thế nào nên mở ngoặc tiếng Anh. 
----
Theo tôi thì thống kê
Vận tải hay sinh học
Đều có một điểm chung
Là nguyên tắc khoa học

Các giáo sư-tiến sỹ
Kinh tế đến Sinh-Y
Đều cần có bằng chứng
Cho lý thuyết từng ly

Một ký tự chủ chốt
Không phải B, G, V
Chìa khoá vạn năng đó
Chính là chữ cái P

Không có con số nào
Tôi từng biết và mê
Như con số đặc biệt
Có tên là số P

Muốn chứng minh gì đó
Phải lập 'giả thuyết không' (null hypothesis)
Rủi gặp số P lớn
Thì coi như mất công

May gặp số P bé
Coi như đời lên tiên
Nghiên cứu được xuất bản
Được công danh, được tiền

Đừng quá buồn nếu gặp
P trên năm phần trăm
Hãy thử tăng cỡ mẫu
Nên gấp đôi, gấp năm!

Điều gì cũng có thể
Nếu bạn cung như tôi
Đặt niềm tin, hy vọng
Vào số P cho rồi

Các phép thuật kiểm tra
Như F, Z, K, T
Và các chiêu thức khác
Đều phải luỵ số P

ANOVA, hồi quy
Kiểm tra phi phân phối
Đều cần P bảo hành
Nếu không đều hấp hối

Chẳng may bạn tìm thấy
Cỡ tác động (effect size) tý hon
Cũng chỉ cần che đậy
Bởi số P vàng son

Nếu bạn chọn phương pháp
Phe 'tần xuất' (frequentist) hay dùng
Thì số P thần thánh
Đáng được là anh hùng

Khi dữ liệu trục trặc
Hay thống kê bị điêu
Bạn phải cần bảo bối
Để xuất bản, không tiêu

Để các tạp chí biết
Công trình mình cực siêu
Tất cả là nhờ có
Cái số P - tuyệt chiêu

https://m.youtube.com/watch?v=yy4nsEvKh2E","2016-03-09T12:44:51+0000","status",NA,"472656846222343_572882179533142",NA,32,7,7
"1300238133378519","Xuân Hiền","http://www.r-bloggers.com/its-not-the-p-values-fault-reflections-on-the-recent-asa-statement-relevant-r-resources/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29","2016-03-11T00:00:12+0000","link","http://www.r-bloggers.com/its-not-the-p-values-fault-reflections-on-the-recent-asa-statement-relevant-r-resources/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29","472656846222343_573493046138722",NA,4,0,0
"1415555318495878","阮利","Chào cả nhà hiện tại mình đang làm một nghiên cứu về hút thuốc lá thụ động ở học sinh cấp 3, mình đặt câu hỏi phỏng vấn như ảnh, nhưng mình muốn hỏi các bạn mình là có thể so sánh  sự khác biệt giữa các địa điểm hút thuốc bằng kiểm đinh k square không? hoặc mối quan hệ giữa địa điểm hút và  tình trạng hút được không? vì mình hoàn toàn không có biến danh định địa điểm hút nên rất khó chạy kiểm định trong spss
nếu chạy kiểm định được thì làm thế nào?","2016-03-08T17:45:03+0000","photo","https://www.facebook.com/photo.php?fbid=1106370089414404&set=gm.572597796228247&type=3","472656846222343_572597796228247",NA,6,9,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-03T09:05:11+0000","photo","https://www.facebook.com/photo.php?fbid=1745282799020351&set=gm.570462216441805&type=3","472656846222343_570462216441805",NA,20,6,0
"1454689051217234","Nguoi Giu Ki Niem","Góc Phần tư thứ nhất bị lỗi. Giải quyết như thế nào Binh Thang","2016-03-10T09:06:31+0000","photo","https://www.facebook.com/photo.php?fbid=1148736508479158&set=gm.573213129500047&type=3","472656846222343_573213129500047",NA,1,0,0
"10206740887835617","Hoang Van Hai","Mong cac ban chi giup ung rung R trong lam nghiep.","2016-03-09T16:13:04+0000","status",NA,"472656846222343_572944286193598",NA,2,4,0
"1913258532222776","Tran Quy Phi","Thông báo: Về việc chia sẻ ebook trên nhóm này
Chuyện này chúng ta cứ theo thông lệ mà làm. Nên tôn trọng bản quyền. Việc trao đổi, chia sẻ ebook ""chùa"" các bạn cứ thoải mái liên hệ với nhau theo email hay sao đó, không nên đưa đường link tải công khai trên nhóm. Trân trọng.","2016-03-10T00:12:54+0000","status",NA,"472656846222343_573072586180768",NA,50,6,0
"1245895802184304","Dinh Tien Tai","Mô hình ảnh hưởng hỗn hợp phi tuyến tính ( Nonlinear mixed effects model - NLME) và mô hình sinh trưởng.
Mô hình NLME được ứng dụng nhiều trong các nghiên cứu về sinh trưởng của động thực vật, sinh thái quần thể và các nghiên cứu mang tính "" dynamics"". Mình sẽ giới thiệu cho các bạn 1 ví dụ về NLME dựa trên đường cong sinh trưởng logistic (có dạng S-shape và tiệm cận).
### Đường cong sinh trưởng logistic có 3 tham số (như hình). Với ""phi 1"" là tiệm cận trên, ""phi 2"" là thời gian để đạt 1 nữa giá trị của tiệm cận trên (điểm uốn) , ""phi 3"" là thời gian từ điểm uốn đến xấp xỉ 75% của tiệm cận trên. Biến y trong ví dụ của mình là chiều dài của cá thể, biến "" t "" là biến thời gian. Cả 3 tham số đều được cấu tạo từ "" fixed effects"" ( Bi) và ""random effects"" (bi).
### Mục đích của chúng ta là xem xét ảnh hưởng của biến độc lập lên 3 tham số của mô hình. Để đơn giản thì trong ví dụ này biến độc lập mình sử dụng là ""DBH"" và mình chỉ xem xét ảnh hưởng của DBH lên tham số ""phi 1"". Dưới đây là code:
###
library(nlme)
dat1=read.csv(""Growth.csv"")
dat=groupedData(length~time|individual,data=as.data.frame(dat1))
## Xác định giá trị tham số bằng phương pháp ""nonlinear least square"".
fm.nls=nls(length~SSlogis(time,Asym,xmid,scal),data=dat)
summary(fm.nls)

## Tính toán giá trị của 3 tham số cho từng cá thể.
fm.lis=nlsList(length~SSlogis(time,Asym,xmid,scal),data=dat)
summary(fm.lis)

## Sử dụng mô hình NLME
fm.nlme=nlme(fm.lis)
summary(fm.nlme)

## Trích xuất giá trị ""fixed effects"" của mô hình ""fm.nlme"".
fm.nlme.fix=fixef(fm.nlme)
fm.nlme.fix

## Xem xét ảnh hưởng của biến DBH lên ""phi 1"".
fmA.DBH=update(fm.nlme, fixed=list(Asym~DBH,xmid+scal~1),start=c(fm.nlme.fix[1],0,fm.nlme.fix[2:3]))
summary(fmA.DBH)

## Kết quả từ hàm "" summary"" cho chúng ta biết về độ lệch chuẩn ""random effects""  của 3 tham số, ""fixed effects"" của 3 tham số và ảnh hưởng của DBH lên tham số ""phi 1"" ( Asym.DBH =  - 0.71474 ). 
## Như vậy chúng ta thấy rằng biến DBH có mối tương quan nghịch với giá trị của tham số ""phi 1"". 
## Quá trình phân tích và kiểm tra mô hình cần có nhiều bước vì nó phụ thuộc vào đặc điểm của dữ liệu và giả định của mô hình. Ở ví dụ này chỉ mang tính "" giới thiệu"" về mô hình. Hẹn các bạn trong các bài post sau mình sẽ trình bày kĩ càng hơn.","2016-03-09T09:44:50+0000","photo","https://www.facebook.com/photo.php?fbid=949117835195437&set=gm.572828029538557&type=3","472656846222343_572828029538557",NA,19,4,4
"435089270155904","Đặng Vũ Văn Thanh","Mình chưa biết gì về R cả, các bạn có thể cho mình biết R là gì và những vấn đề cơ bản của nó.","2016-03-09T11:22:16+0000","status",NA,"472656846222343_572861102868583",NA,1,7,0
"1656925974323978","Meo Acma","Xin nhờ mọi người giúp,

Hiện mình đang cần thực hiện Leave one out of cross validation (LOOCV)/ K-fold cross validation trên R programming để đánh giá regression equation được thiết lập từ dữ liệu nghiên cứu của mình và regression equation có sẵn của 1 nghiên cứu khác.  Trước giờ mình chỉ quen làm việc với SPSS, tuy nhiên trong SPSS hình như không có chương trình này. Mình cũng đã đọc 1 số tài liệu về R và coi 1 số video hướng dẫn trên Youtube và thực hiên theo, tuy nhiên khi mình gõ lệnh để chạy LOOCV thì R programming báo không tìm được lệnh phù hợp.  Vì mình không có nhiều thời gian để tiếp tục mày mò về R program, nên hy vọng mọi người có thể giúp mình cách thực hiện LOOCV tren R programminh hoặc SPSS (hy vọng là SPSS có thể thực hiên được vì mình quen vớin ó nhiều hơn)

Cám ơn mọi người rất nhiều.","2016-03-09T11:03:53+0000","status",NA,"472656846222343_572857542868939",NA,2,1,0
"10208725271269151","Dung Nguyen Chi","Ví dụ dưới đây minh họa khía cạnh thực hành trong R. Tuy nhiên,  bản chất của vấn đề mình suy nghĩ mãi vẫn chưa hiểu tại sao. Được biết Group quy tụ rất nhiều người trong lĩnh vực Y - Sinh nên mình muốn nhờ các bạn giải thích.  

Trước hết, số liệu được thu thập từ 427,323 ca sinh ở Hoa Kì năm 2006 (một con số rất lớn, có thể coi như toàn bộ population về các ca sinh ở Mĩ năm đó) với 13 biến số trong đó có thông tin về trọng lượng của các bé (biến DBWT), ngày sinh của các bé (DOB_WK) và được sử dụng lại ở rất nhiều sách về thống kê Y - Sinh. Tên file dữ liệu là births2006.smpl. Chúng ta có thể khai thác rất nhiều thông tin bổ ích (và cũng rất hứng thú) từ bộ dữ liệu này như sau: 

>install.packages(""nutshell"")
> data(births2006.smpl)
> library(ggplot2)

Trước khi phân tích, chúng ta  kì  vọng rằng không có lí do gì để một bé sinh vào một ngày nào đó trong tuần lại có trọng lượng nặng hơn các bé sinh vào ngày khác. Tuy nhiên qua boxplot thì rõ ràng có sự khác biệt về trọng lượng của các bé ứng với các ngày sinh khác nhau: 
> ggplot(births2006.smpl,aes(factor(DOB_WK),DBWT,colour=factor(DOB_WK)))+geom_boxplot()+coord_flip()

Căn cứ boxplot thì rõ ràng điều này ngược với kì vọng của chúng ta về trọng lượng trung bình của các bé. Chúng ta cần đưa ra bằng chứng thống kê cho nhận định trên: 
> summary(lm(data=births2006.smpl,DBWT~factor(DOB_WK)-1))

Call:
lm(formula = DBWT ~ factor(DOB_WK) - 1, data = births2006.smpl)

Residuals:
    Min      1Q  Median      3Q     Max 
-3053.0  -298.6    41.1   370.2  4892.0 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
factor(DOB_WK)1 3218.913      2.966    1085   <2e-16 ***
factor(DOB_WK)2 3279.761      2.376    1381   <2e-16 ***
factor(DOB_WK)3 3279.973      2.253    1456   <2e-16 ***
factor(DOB_WK)4 3275.612      2.245    1459   <2e-16 ***
factor(DOB_WK)5 3273.009      2.247    1457   <2e-16 ***
factor(DOB_WK)6 3265.838      2.276    1435   <2e-16 ***
factor(DOB_WK)7 3229.506      2.785    1160   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 594.9 on 426882 degrees of freedom
  (434 observations deleted due to missingness)
Multiple R-squared:  0.9679, Adjusted R-squared:  0.9679 
F-statistic: 1.837e+06 on 7 and 426882 DF,  p-value: < 2.2e-16

Kết quả chỉ ra rằng: có bằng chứng thống kê cho thấy, ví dụ, trọng lượng của các bé sinh vào thứ ba (factor(DOB_WK)3) là nặng nhất vì các hệ số hồi quy có ý nghĩa ở mức cao 1%. 

Nếu đây là một tình huống trong kinh tế thì có thể mình có thể trả lời được. Nhưng mình vẫn chưa hiểu, liệu có lý do gì để giải thích cho sự khác biệt (mà đáng lẽ ra là không nên có) này? 

Cảm ơn các bạn.","2016-03-08T20:51:03+0000","photo","https://www.facebook.com/photo.php?fbid=10205993616259483&set=gm.572653729555987&type=3","472656846222343_572653729555987",NA,6,3,0
"10208725271269151","Dung Nguyen Chi","Vẽ đồ thị thị phần của R giai đoạn 1995 - 2011

Do là một phần mềm miễn phí nên chúng ta không thể có thông tin về doanh thu của R. Tuy vậy chúng ta có thể nghiên cứu thị phần của R (cũng như của bất kì phần mềm nào khác) theo một cách khác: căn cứ vào mức độ sử dụng R cho các nghiên cứu khoa học được đăng trên các tạp chí chuyên nghành chẳng hạn. Dữ liệu về các truy vấn tìm kiếm các nghiên cứu khoa học sử dụng 6 phần mềm phổ biến giai đoạn 1995 – 2011 được thu thập từ cơ sở dữ liệu của Google Scholar và được lưu ở file scholarly_impact_2012.4.9.csv.

> dulieu<-read.csv(""http://librestats.com/wp-content/uploads/2012/04/scholarly_impact_2012.4.9.csv"")
> library(reshape2)
> library(scales)
> hello <- c(""JMP"",""Minitab"",""Stata"",""Statistica"",""Systat"",""R"")
>  nghiyeu <- dulieu[ , hello]
> Year <- rep(dulieu$Year, length(nghiyeu))
> loveyou <- melt(nghiyeu)
> names(loveyou) <- c(""PhanMem"", ""MucDoTimKiem"")
> loveyou <- data.frame(Year, loveyou)
> ggplot(loveyou, aes(Year, MucDoTimKiem, group=PhanMem)) + geom_smooth(aes(fill=PhanMem), position=""fill"")","2016-03-09T08:31:48+0000","photo","https://www.facebook.com/photo.php?fbid=10205996402689142&set=gm.572813512873342&type=3","472656846222343_572813512873342",NA,24,1,2
"10208725271269151","Dung Nguyen Chi","Giới thiệu sách hay. 
Link sách (PDF+Epub): http://www.mediafire.com/download/g5u5h4pkzpt2fpz/StatisticsUsingR.NguyenChiDung.rar
Data + Rcode các bạn có thể lấy tại: 
http://studysites.sagepub.com/dsur/study/default.htm","2016-03-09T02:18:02+0000","photo","https://www.facebook.com/photo.php?fbid=10205994990493838&set=gm.572725362882157&type=3","472656846222343_572725362882157",NA,28,4,5
"1530258666992232","Namlun Didong","Hôm nay mình giới thiệu với các bạn cách dùng package plot3D để vẽ đồ thị 3 chiều khá đẹp.

Đồ thị 3 chiều, nhất là dạng tương tác, có thể ứng dụng để thể hiện quan hệ giữa 3 biến X,Y,Z theo mô hình Z = Y + X. 3D scatter plot cũng hữu ích khi phân tích hiệu ứng moderation","2016-03-08T14:46:15+0000","photo","https://www.facebook.com/photo.php?fbid=1142788635739239&set=gm.572525102902183&type=3","472656846222343_572525102902183",NA,57,4,6
"10208725271269151","Dung Nguyen Chi","Chào các Bác/Chú/Anh/Chị/Bạn. Mình là Nguyễn Chí Dũng, học ở Đại Học Kinh Tế Quốc Dân Hà Nội. Chuyên ngành Tài Chính -  Ngân Hàng. Trước khi đến với R mình sử dụng Eviews, Stata, SPSS - AMOS. Mình biết đến R (dù chỉ là nghe nói) từ hồi mình học năm thứ ba đại học, cũng có download tài liệu về R (của TS Nguyễn Văn Nguyễn Tuấn) từ hồi ấy và in ra nhưng nhìn qua thấy nó..chán quá nên ngừng ý định học về R và cũng quên luôn cả tập tài liệu. Sau này mới nhận ra đó là một quyết định sai trái. 

Sau này, do một sự tình cờ may mắn mình ""gặp lại R"" ở hai tình huống là từ cuốn sách về kinh tế lượng tài chính của Tsay ở trường Booth Chicago và tập tài liệu về R mà ngày trước mình đã quên lãng - giờ đã thành một cuốn sách 500 trang. Mình mua ngay về và nghiên cứu. Đó là cuối tháng 11 của năm 2015. Và minh thực sự thấy R rất mạnh và có tiềm năng rất lớn. R là một kiểu công cụ mà khi ta đã biết nó ở mức tối thiểu, ta chỉ muốn học hỏi nhiều thêm nữa. R thực sự..bí ẩn và hấp dẫn. 

Mình cũng may mắn nữa là được gặp gỡ, trao đổi với các bạn (mình dùng từ này không có ý bất kính vì có rất nhiều người hơn tuổi) ở Group này về R. Mong muốn của mình là được học hỏi nhiều hơn nữa từ những người giỏi hơn (vì mình đến với R đến thời điểm này cũng chỉ mới tháng thứ 4 và cũng tự nhận thấy còn chưa biết gì). Ngoài ra mình cũng mong muốn tồn tại một cộng đồng sử dụng R rộng lớn hơn ở VN, và cho ở nhiều lĩnh vực chứ không chỉ chuyên về thống kê Y - Sinh- Môi trường (Biostat). Do vậy, mình rất vui được làm quen với và học hỏi từ các bạn. Lĩnh vực quan tâm hiện tại của mình là: 

1. Econometrics/Financial Econometrics/ Financial Risk Management
2. Data Visualization/ Data Mining with applications in Business and Economics/Finance.","2016-03-08T20:09:54+0000","photo","https://www.facebook.com/photo.php?fbid=10205993402774146&set=gm.572641556223871&type=3","472656846222343_572641556223871",NA,25,2,1
"1530258666992232","Namlun Didong","Bạn đang dao động trước những hình vẽ rất đẹp và sức mạnh đáng sợ của R. 

Nhưng bạn vẫn còn lưu luyến với GUI của SPSS, và chưa sẵn sàng chuyển qua dùng R ?

bạn có nhu cầu đơn giản về phân tích số liệu ?

Xin giới thiệu với bạn 1 giải pháp tạm thời : đó là giao diện đồ họa Jaguar và  Deducer. 

Công cụ này rất thích hợp cho các bạn mới chuyển từ SPSS sang R, vì Jaguard vừa có giao diện nút bấm, menu như SPSS, vừa là code editor nhu R console, nó cho phép dùng thao tác trên GUI, xuất nội dung code, và cho phép bạn viết code tự do như SAS hay STATA, nên theo thời gian bạn sẽ dần dần học nâng cao R.

Jaguar làm được thống kê mô tả, test so sánh, ANOVA, GLM và nhiều thứ khác.

Nhưng điểm nổi bật nhất là Deducer tích hợp ggplot2. Ngữ pháp đồ thị trong ggplot2 được chuyển thành nút bấm trên giao diện tương tác, bạn sẽ vẽ được những đồ thị đẹp mà không cần biết gì về cú pháp của ggplot2.

Như vậy giao diện JGR (Jaguar) + Deducer trên cho phép sử dụng R như 1 công cụ thống kê tương đương SPSS, STATA nhưng hoàn toàn miễn phí.","2016-03-07T16:43:09+0000","photo","https://www.facebook.com/photo.php?fbid=1142209892463780&set=gm.572177042936989&type=3","472656846222343_572177042936989",NA,88,8,26
"1530258666992232","Namlun Didong","ggplot2 là một package đồ họa rất tinh tế, vì nó dựa vào « Ngữ pháp đồ thị ». Sử dụng được ggplot có nghĩa là bạn hiểu ngữ pháp của một ngôn ngữ. Tuy nhiên, cũng như môn ngữ văn, việc hiểu ngữ pháp và đặt được câu không đảm bảo là bạn viết được một văn bản hay

Vì vậy mới có những bài văn mẫu …

Package ggfortify chính là một quyển văn mẫu như vậy. 

ggfortify cho phép bạn tạo dễ dàng, nhanh chóng một số dạng đồ thị chuyên dụng, trong khi vẫn « cá biệt hóa » được tính mỹ thuật dựa vào kiến thức ngữ pháp đồ thị (cú pháp ggplot2)

Ggfortify hỗ trợ graph cho rất nhiều phân tích như :
+ Lượng giá phẩm chất mô hình GLM
+ Mô tả data bằng heatmap
+ PCA
+ Cluster analysis
+ Survival analysis (Kaplan Meier curve)

","2016-03-07T14:02:09+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPM3M3MTFheTlEUU0/view?usp=sharing","472656846222343_572127049608655",NA,58,5,0
"10208725271269151","Dung Nguyen Chi","Chào các anh/chị/bạn. Nhằm cổ vũ cho phong trào sử dụng R trong nghiên cứu, mình vừa hoàn thành một tập tài liệu về sử dụng R cho phân tích kinh tế lượng với định hướng dành cho bạn đọc học khối kinh tế và thực hành: 

http://www.mediafire.com/download/3lg8bsfbu6csq8d/KinhTeLuongUngDungVoiR.rar

Rất mong nhận được sự đóng góp và phản hồi của các bạn.","2016-03-07T00:56:15+0000","photo","https://www.facebook.com/photo.php?fbid=10205981805924232&set=gm.571923939628966&type=3","472656846222343_571923939628966",NA,35,5,3
"10203062627643544","Son Nghiem","Viết báo cáo với RStudio
Rstudio là một công cụ tuyệt vời.. Ngoài việc tiện viết lệnh và chạy R, bạn có thể sử dụng Rstudio làm công cụ để viết báo cáo cực dễ.
Trước hết bạn tải Rstudio về và cài đặt nó từ trang https://www.rstudio.com/home/
Để viết báo cáo bạn cần làm quen với ngôn ngữ Rmarkdown. Có thể tìm hiểu từ http://rmarkdown.rstudio.com/
Sau đây là một ví dụ đơn giản.
1) Từ RStudio, bạn chọn File->New File->RMarkdown…
2) Copy đoạn sau đâyn (giữ hai hàng  !!!, chọn cả dấu ---)  và dán vào, gọi tập tin này là Test.Rmd, nhớ save nó ở dạng Unicode (Từ RStudio bấm File->Save with Enconding… rồi chọn UTF-8) 

!!!
---
title: Báo cáo nghiên cứu
author: ""ABC & XYZ""
date: ""23 tháng 2 năm 2016""
output:
  word_document: 
    reference_docx: easychair.docx
    #Download: cdn.elsevier.com/promis_misc/rgo_template.docx
  pdf_document: default
bibliography: TestRef.bib
---
#1. Giới thiệu
Đây là tài liệu giới thiệu về viết báo cáo trên R Markdown document.Xem <http://rmarkdown.rstudio.com> để biết thêm chi tiết.

#2. Dữ Liệu
##2.1 Nguồn dữ liệu
Thu thập ở nguồn 1, 3, 3...

##2.2 Thống kê cơ bản
Mô tả thống số cơ bản của dữ liệu...
```{r, echo=FALSE, message=FALSE, warning=FALSE}
  a<-rnorm(100, m=1, sd=1)
  b<-rnorm(100, m=2, sd=1)
  c<-rnorm(100, m=0, sd=1)
  mydat<-as.data.frame(cbind(a,b,c))
  library(psych)
  library(knitr)
  kable(describe(mydat, range=F), digit=3, format = ""markdown"", padding = 4,row.names = FALSE)
```

Bạn cũng có thể vẽ đồ thị  về dữ liệu cho thêm sinh động
```{r plot, echo=FALSE, message=FALSE}
  plot(a, b)
```

#3 Phương pháp
Mô tả phương pháp
có thể viết phương trình như lệnh LaTx ví dụ như công thức tính trung bình $\frac{1}{n}\sum_{i=1}^{n}x_{i}$,và độ lệch chuẩn được tính bằng cách lấy $\frac{\mu}{\sigma^2}$ chia cho  $\sqrt{\gamma}$.

#4. Thảo luận
Mô tả kết quả, 
Trích dẫn từ tài liệu: 
Không dùng ngoặc  @OngA2001
Dùng ngoặc [@BaB2009]
#4. Kết luận
Tóm lược lại báo cáo

#Tài liệu tham khảo

!!!

3) Tạo ra một file tài liệu tham khảo bằng cách mở một text edior (như notepad) rồi copy đoạn dưới đây (giữa hai hàng !!!) và đặt tên nó là TestRef.bib vào nơi bạn đặt file Test.Rmd

!!!
@Article{OngA2001,
  Title                    = {Bài hay nhất của ông A},
  Author                   = {Nguyễn, Văn A},
  Journal                  = {Tạp chí vườn},
  Year                     = {2001},
  Number                   = {13},
  Pages                    = {1923--1957},
  Volume                   = {36}
}

@article{BaB2009,
  title={Bài hay của bà B},
  author={Lê, Thị B},
  journal={Tạp chí đỉnh},
  volume={373},
  number={9682},
  pages={2234--2246},
  year={2009}
}
!!!
4) Tải về một mẫu báo cáo, ví dụ cdn.elsevier.com/promis_misc/rgo_template.docx và cất nó vào nơi bạn cất 2 tập tin kia

5) Bấm vào Knit Word (chạy lần đầu bạn sẽ cần cài một số package theo hướng dẫn) và bạn sẽ có bản báo cáo tên là Test.docx với bảng biểu và đồ thị
Lưu ý là bạn cần cài các packages đã liệt kê trong file ví dụ để dùng","2016-03-04T06:42:14+0000","link","https://www.rstudio.com/home/","472656846222343_570842329737127",NA,21,4,0
"1201674239950763","Thao Trang Nguyen","Mọi người cho em hỏi:

Thường thì chúng ta hay làm điều tra chọn mẫu, có tham số mẫu rồi thì chúng ta dùng phép thống kê suy diễn để suy ra lại cho tổng thể, chẳng hạn như kiểm định sự khác nhau của hai trung bình. Nhưng trong trường hợp mình điều tra tổng thể, vậy có cần làm phép kiểm định nữa hay không?
Ví dụ như: điều tra tổng thể nếu ta có kết quả trung bình hai nhóm A và B lần lượt là: 5.98 và 6.00. Như vậy, trong trường hợp ta không kiểm định, thì kết luận 2 trung bình này là khác nhau. Tuy nhiên, nếu ta thực hiện kiểm định, rất có thể hai trung bình của hai nhóm là như nhau! Vậy thì ta nên kiểm định hay không kiểm định, trong trường hợp điều tra tổng thể!!","2016-03-08T03:47:22+0000","status",NA,"472656846222343_572345736253453",NA,0,10,0
"1913258532222776","Tran Quy Phi","Jitter
Giả sử ta có số liệu như sau
x=c(1,1,1,1,5)
y=c(2,2,2,2,6)
Scatter plot :
plot(x,y,pch=16)
(hình 1)
Chỉ có 2 điểm được vẽ. Đó là điểm (1,2) và (5,6). Nó không phản ánh đúng tập số liệu (khi nhìn vào biểu đồ).
R cho phép ta thêm một chút nhiễu (noise) vào số liệu để có thể phân biệt các điểm (trên biểu đồ) bằng hàm jitter.
plot(jitter(x),jitter(y),pch=16)
(hình 2)
Nhưng nó nhiễu nhiều quá, thay đổi bằng cách thêm vào tham số (amount, lượng nhiễu) trong hàm jitter:
plot(jitter(x,0.1),jitter(y,0.1),pch=16)
(hình 3)","2016-03-08T01:49:15+0000","photo","https://www.facebook.com/photo.php?fbid=1746915555523742&set=gm.572316072923086&type=3","472656846222343_572316072923086",NA,23,2,1
"10208725271269151","Dung Nguyen Chi","Cách lấy và xử lý số liệu từ World Bank với phần mềm R

Trong nhiều nghiên cứu khoa học, nhất là các nghiên cứu Vĩ Mô thì việc lấy được các dữ liệu về nền kinh tế là rất quan trọng. Một trong các nguồn tin cậy mà chúng ta có thể khai thác là bộ gồm 1288 chuỗi số liệu theo thời gian – thường được gọi là bộ Chỉ Số Phát Triển Thế Giới WDI (viết tắt của cụm từ World Development Indicator) được Ngân Hàng Thế Giới (WB) cung cấp cho gần 200 quốc gia và vùng lãnh thổ. 

Sở dĩ có 20 nhóm dữ liệu này nhưng lại có tới gần 1300 chuỗi dữ liệu khác nhau là bởi vì mỗi một nhóm này lại được phân thành các nhóm nhỏ hơn (gọi là SubTopic). Chi tiết các bạn có thể xem tại: 
http://data.worldbank.org/data-catalog/world-development-indicators

Để lấy chính xác các dữ liệu cho các nghiên cứu vĩ mô chúng ta trước hết cần lấy chính xác các mã số liệu khi thu thập từ R. Ngoài ra chúng ta cũng cần biết chính xác mã ISO-2 của các quốc gia được cung cấp ở cột A2 dưới đây: 

http://www.vas.com/Tnotes/Country%20Codes.htm

Bằng R chúng ta có thể dễ dàng lấy và xử lý các số liệu được cung cấp bởi WB với sự trợ giúp của gói WDI được viết bởi Vincent Arel-Bundock (University of Michigan). Tại cửa sổ lệnh của R chúng ta gõ install.packages(“WDI”) để cài đặt gói này.

Giả sử rằng chúng ta muốn nghiên cứu tác động của thu nhập đầu người (GDP) lên tuổi thọ (Life Expectancy) của 6 nước Asean gồm Lào, Cambodia, Việt Nam, Malaysia, Philippine, Indonesia từ năm 1986 đến 2014. Trước hết chúng ta cần lấy các thông tin cần thiết như sau: 

> library(WDI)
> dung=WDI(country=c(""LA"",""KH"",""VN"",""MY"",""PH"",""ID""), indicator=c(""NY.GDP.PCAP.CD"",""SP.DYN.LE00.IN""), start=1986, end=2014, extra=TRUE, cache=NULL)
> dung=edit(dung) # đổi các tên biến SP.DYN.LE00.IN và NY.GDP.PCAP.CD thành LS và GDP cho dễ hiểu. 

Kết tiếp ta viết hàm có tên noicacgraph nối các graph lại: 

> noicacgraph <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  if (is.null(layout)) {
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    for (i in 1:numPlots) {
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
> love=ggplot(data = dung, aes(year,LS, color=country))+geom_line(size=1)
> you=ggplot(data =dung, aes(year,GDP, color=country))+geom_line(size=1)
> noicacgraph(love,you,cols=1)","2016-03-08T04:35:51+0000","photo","https://www.facebook.com/photo.php?fbid=10205989900566593&set=gm.572363392918354&type=3","472656846222343_572363392918354",NA,9,0,1
"1530258666992232","Namlun Didong","Đây là một đồ thị kết hợp giữa scatter dot plot và 2 density plot.

Công thức chế biến ""cái bánh "" này như sau:

# Nguyên liệu:
data = read.table('http://www.ats.ucla.edu/stat/data/hsb2.csv', header=T, sep="","")

# Sơ chế
data$race=as.factor(data$race)

# Đốt lò
library(ggplot2)
library(""gridExtra"")

#Làm bánh = scatter plot

scatter=ggplot(data,aes(x=read,y=math,color=race))+geom_point(size=2)+theme_bw(base_size=15)+theme(legend.position=""none"")

#Làm mứt : 2 density plot

mathdensity=ggplot(data,aes(x=math,fill=race))+geom_density(alpha=0.5)+theme_bw()+coord_flip()

readdensity=ggplot(data,aes(x=read,fill=race))+geom_density(alpha=0.5)+theme_bw()+theme(legend.position=""none"")

# Tạo 1 layer rỗng phân cách

blank<- ggplot()+geom_blank(aes(1,1))+
theme(
plot.background = element_blank(), 
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), 
panel.border = element_blank(),
panel.background = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank(), 
axis.text.y = element_blank(),
axis.ticks = element_blank(),
axis.line = element_blank()
)

# Trộn tất cả lại:

grid.arrange(readdensity, blank, scatter, mathdensity, ncol=2, nrow=2, widths=c(4, 3), heights=c(2, 4))

# Như vậy là hoàn tất.","2016-03-06T16:43:26+0000","photo","https://www.facebook.com/photo.php?fbid=1141615012523268&set=gm.571794646308562&type=3","472656846222343_571794646308562",NA,65,10,9
"1850090598539238","Hung Quang Phung","Em kính chào quý thầy cô, quý anh chị,
Hiện tại em đang dùng phiên bản R 3.2.3 và em đang tìm cách tạo 1 bảng thống kê mô tả như trong hình dưới đây mà em chưa biết cách tạo. Kính mong quý thầy cô, anh chị giúp em với. Em xin gửi mọi người file ảnh của bảng thống kê và file dữ liệu ạ, mong mọi người hướng dẫn em với. Em cám ơn quý thầy cô, quý anh chị nhiều","2016-03-06T13:46:31+0000","status",NA,"472656846222343_571737212980972",NA,2,2,0
"1343500979006100","Hồ Quan Bằng","Xin kính chào các Thầy, cô và các anh chị! Hi vọng sẽ hoc hỏi được thêm nhiều điều thú vị, rất mong nhận được sự giúp đỡ của các Thầy, cô và anh chị.","2016-03-06T12:28:37+0000","status",NA,"472656846222343_571714109649949",NA,3,0,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-06T06:34:23+0000","status",NA,"472656846222343_571613109660049",NA,38,1,0
"1913258532222776","Tran Quy Phi","Độ đậm nhạt của màu trong R, alpha
Khi dùng màu muốn thay đổi độ đậm nhạt ta dùng tham số alpha. Tuy nhiên, lúc đó màu phải được đặt theo kiểu rgb, chứ không phải tên tường minh (“red”, “black”) như thường nữa. rgb là red, green, blue ba màu phối nhau.
Name = c(""Hoa"", ""Mai"", ""Tam"", ""Nguyet"", ""Hai"")
Weight = c(54, 57, 61, 75, 77)
barplot(Weight,col=rgb(0.2,0.4,0.5))
(hình 1)
Mặc định alpha bằng 1, muốn nhạt hơn (thực ra là trong suốt hơn (độ transparency)), ta đặt nhỏ hơn 1,
 barplot(Weight,col=rgb(0.2,0.4,0.5,alpha=0.5))
(hình 2)
Muốn vẽ cùng một màu nhưng có độ đậm nhạt khác nhau, ta đặt tham số alpha bằng một dãy số (vector) như sau (lấy ví dụ):
 alp=c(0.1,0.2,0.3,0.4,0.5)
 barplot(Weight,col=rgb(0.2,0.4,0.5,alpha=alp))
(hình 3)
#(palette)","2016-03-03T11:50:56+0000","photo","https://www.facebook.com/photo.php?fbid=1745325439016087&set=gm.570509789770381&type=3","472656846222343_570509789770381",NA,43,1,5
"1913258532222776","Tran Quy Phi",NA,"2016-03-06T06:23:07+0000","status",NA,"472656846222343_571604206327606",NA,2,0,0
"10155012910242145","Diễm Vy","Hi all, cám ơn thầy Tuấn và các anh chị em bạn bè đã post rất nhiều bài hay. Em thường xuyên theo dõi và học được nhiều điều mới. Tuy nhiên tốc độ post bài khá nhanh, bài post lên rất nhiều. Nhiều lúc muốn tìm lại một post cũ để đọc cũng hơi khó. Không biết các chủ topic có thể add thêm # (keywords) để classify topics cho dễ tìm bài cũ trong group ko? Thank you.
P.S.: Em có dùng ""search this group"" nhưng em nghĩ có keywords thì vẫn dễ tìm hơn.","2016-03-06T01:58:33+0000","status",NA,"472656846222343_571537069667653",NA,11,1,0
"1249192251823862","Kevin Nguyen Vo","Dùng %>% của package magrittr để xâu chuổi các function lại với nhau. Cách viết các dòng code thông thường khi đọc thường đọc theo thứ tự từ bên trong ra đến bên ngoài của các dấu ngoặc đơn. Cách làm này thường khó viết và đôi khi rất khó đọc nếu nhiều function lồng vào nhau. 

-Cách để hiểu ký hiệu %>%:

x %>% f tương đương với f(x)
x %>% f(y) f tương đương với f(x, y)
x %>% f %>% g %>% h f tương đương với h(g(f(x)))

-Ví dụ:

library(magrittr)
# Tạo 1 vector tên là errors
errors <- c(1.9,-2.6,4.0,-9.5,-3.4,7.3)

# Tính tổng giá trị tuyệt đối của các số làm tròn trong vector errors
# Cách làm thông thường
sum(abs(round(errors)))
[1] 29
# Dùng %>% để xâu chuổi các phép tính:
errors %>% round() %>% abs() %>% sum()
[1] 29","2016-03-06T02:42:17+0000","photo","https://www.facebook.com/photo.php?fbid=961037070639383&set=gm.571543413000352&type=3","472656846222343_571543413000352",NA,4,0,0
"10208641252417754","Nguyen Thinh","Hiển thị dữ liệu không gian trên R
Mình hiện đang sử dụng R vào mục đích biểu diễn các dữ liệu về môi trường theo các toạ độ điểm (spatial data). Bởi vậy, cũng có chút kinh nghiệm nhỏ muốn chia sẻ cùng các bạn quan tâm. 
Chiều nay có đọc qua thấy thày Tuấn có đặt câu hỏi về việc ứng dụng R vào mục đích tương tự, nhưng khi đọc kỹ, thấy có chút khác biệt với các thông tin mình định up lên đây. Vì lý do đặc thù, các số liệu của mình thường gắn với các điểm với toạ độ cụ thể, nên mình hoàn toàn không có kinh nghiệm trong việc mô phỏng dữ liệu theo vùng địa lý. Qua đây, em rất xin lỗi thày Tuấn, vì chưa đọc kỹ câu hỏi của thày, hi vọng thày đã không chờ đợi!
Tuy nhiên, như anh Son Nghiem có giới thiệu phần tổng hợp (theo mình là rất công phu) của anh Manhtai (https://github.com/manhtai/r-vietnam-map). Hiện tại, theo mình biết, buộc lòng phải làm thủ công như vậy (trên R) để có bản đồ cấp tỉnh ở Vietnam. Các bạn chỉ cần download các file: VNM_adm2.RData, và geo63.rds về là có thể chạy được đoạn code như trong link trên.

Còn file pdf dưới đây là một số bước ban đầu để có thể sử dụng các dữ liệu không gian trên R. Rất mong các bạn có thêm ý kiến đóng góp.

https://drive.google.com/file/d/0B5DUIWl0RgpSUENFMzhCUzJIM2M/view?usp=sharinghttps://drive.google.com/file/d/0B5DUIWl0RgpSUENFMzhCUzJIM2M/view?usp=sharing

Trân trọng cảm ơn!","2016-03-05T15:52:54+0000","link","https://drive.google.com/file/d/0B5DUIWl0RgpSUENFMzhCUzJIM2M/view?usp=sharing","472656846222343_571357403018953",NA,12,1,0
"1139492789512585","Trang Tran","Ban nao quan tam den PCA, sparse Partial Least Squares variants (sPLS),...thi co the dung mixOmics. Thich hop cho MultiOmics Data Integration va van de n<<p. Xem bai trinh bay cua tac gia o day:","2016-03-05T04:03:48+0000","status",NA,"472656846222343_571182143036479",NA,7,0,0
"1530258666992232","Namlun Didong","Package brms là một công cụ rất mạnh hiện nay để làm thống kê Bayes trong R. brms có lõi là bộ code C++ tên là STAN, và giao diện (cú pháp lênh) bên ngoài gần giống như những package về GLM khác như lme, gamlss … Nó hỗ trợ gần như tất cả distribution family, cho phép dựng trực tiếp nhiều mô hình bằng cú pháp đơn giản, tự xác định prior. Ngoài ra brms còn lợi dụng ggplot2 để vẽ đồ thị. Tóm lại, brms vừa dễ sử dụng, vừa mềm dẻo, vừa đẹp mắt. 

Trong thí dụ nhỏ dưới đây mình ứng dụng brms để làm hồi quy logistic theo Bayes cho 1 nghiên cứu trong ngành sleep medicine.

","2016-03-04T08:08:54+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPbWIwRDhuaUtHVjQ/view?usp=sharing","472656846222343_570855676402459",NA,10,2,0
"1530258666992232","Namlun Didong","Chào các bạn, đây là một thí dụ khác để thử nghiệm khả năng của package brms, một công cụ tiện dụng cho phép dựng mô hình GLM theo phương pháp Bayes trong R. Trong thí dụ này mình đặt ra một nhiệm vụ cao hơn cho brms, đó là dựng 1 linear model, có đồng thời mixed và random effect (tương ứng với MANOVA , repeated measure theo truyền thống). 
Để kiểm chứng, mình sẽ so sánh kết quả brms làm ra với 2 package GLM khác (nlme và gamlss). 

","2016-03-04T09:24:19+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPaWxBcVo4S0xJR2s/view?usp=sharing","472656846222343_570866389734721",NA,26,3,0
"1530258666992232","Namlun Didong","Như đã giới thiệu lần trước, mình rất hứng thú với việc thử nghiệm package brms để làm lại một số phân tích truyền thống theo trường phái Bayes. Gần đây nhất, mình ứng dụng package này cho một thân chủ để làm poster cho hội nghị ATS. Nội dung là ứng dụng negative binomial model cho repeated measure, theo Bayes, để thay thế cho t test hoặc Wilkoxon sign rank test. 

Nghiên cứu này đặt ra một cửa hẹp cho mình, cỡ mẫu thấp, nhiều outliers và biến số nghiên cứu thực chất là count data, nên mình bắt buộc phải đi đến giải pháp này, chứ hoàn toàn không phải lạm dụng Bayesian analysis.

","2016-03-04T08:17:18+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPNU9TbURaU2dXdWc/view?usp=sharing","472656846222343_570856869735673",NA,50,5,0
"1530258666992232","Namlun Didong","Chúng ta đều biết về package boot trong R cho phép làm bootstrap. Gần đây, một package khác cũng cho phép làm bootstrap nhưng theo phương pháp Bayes, mình xin chia sẻ với các bạn một minh họa về khả năng của package này.

","2016-03-04T08:12:23+0000","link","https://drive.google.com/file/d/0B1vaOU1uB8DPRzZuQlhNYkY5Mkk/view?usp=sharing","472656846222343_570856189735741",NA,45,0,0
"10202957412092433","Giang Sơn","Trình bày association của outcome với yếu tố ảnh hưởng cũng thường sử dụng.

Thay vì trình bày số liệu OR/RR với khoảng tin cây 95% thì có thể dùng chart này rõ ràng và dễ hiểu.

Code dưới đây là đặt hàng cho Anh Nguyên (hình như mất cả buổi thì phải và không nhớ trả tiền cho hợp đồng này chưa) Giờ share lại cho các bạn

Copy và past trong R thì thấy ưng ý liền

rr  <- c(1.10,1.05,1.04,0.98)
l95 <- c(1.05,0.96,0.96,0.88)
u95 <- c(1.15,1.15,1.12,1.10)
y = c(0:4)
x <- c(seq(0.2, 1.6, 0.5))
y2 <- c(1:4)

o <- par(fg=""blue"", col.lab=""blue"", col.axis="" blue"", cex=1.5)
plot(range(x), range(y), type=""n"", yaxt=""n"", bty=""n"",
                          xlim=c(0.8,1.2),
                          xlab= "" "",
                          ylab= "" "",
                          lab=c(8,5,5))
segments(1,0,1,7,lwd=2, lty=3, col=""red"")
segments(l95, y2, u95, y2, lwd=3.5,col=ifelse(l95 < 1 & u95> 1, "" yellow"","" blue""))
points(rr,y2, pch=20, cex=1.5, col=ifelse(rr > 1, ""red"",""black""))
par(o)","2016-03-03T15:26:14+0000","photo","https://www.facebook.com/photo.php?fbid=10201474464339666&set=gm.570577279763632&type=3","472656846222343_570577279763632",NA,3,1,0
"10203062627643544","Son Nghiem","Gửi cả tài liệu tham khảo ví dụ luôn. Chưa biết cách gửi tất cả các file nên cứ gửi từng cái một :(","2016-03-04T07:00:50+0000","status",NA,"472656846222343_570845289736831",NA,3,0,1
"10203062627643544","Son Nghiem","Gửi file ví dụ, không cần template mẫu nếu bạn thấy báo cáo mặc định của RStudio OK","2016-03-04T06:56:34+0000","status",NA,"472656846222343_570844859736874",NA,5,0,0
"1398499446838965","Duong Duc Pham","Statistic Infographics
Kính chào thầy Tuấn và các bạn trong group.
Tiếp nối những nỗ lực không mệt mỏi của thầy Tuấn và các đồng nghiệp, tôi xin đóng góp một bài cho trang nhà của chúng ta. 
Ai cũng biết là thống kê thường rất khô khan, khó hiểu, trừu tượng. Việc nhớ các cách tính toán thường cần những diễn giải phức tạp. Tuy các bài giảng của thầy Tuấn cũng rất dễ hiểu, tôi muốn làm cho nó dễ hiểu hơn (em xin phép thầy ^^) bằng hình thức Infographic.
Tôi xin khởi đầu bằng hai khái niệm Phương sai (variance) và Độ lệch chuẩn (SD), khái niệm mà bất cứ ai học và làm thống kê cũng dùng đến nhưng không phải ai cũng hiểu một cách cặn kẽ. Với hình thức Infographic, tôi xin không diễn giải mà chỉ cung cấp các lệnh của R. Nếu các bạn nào chưa bao giờ nghe nói đến các khái niệm này mà sau khi xem Infographic hiểu được khái niệm Phương sai (variance) và Độ lệch chuẩn (SD) biểu thị cái gì, tính như thế nào bằng tay hoặc bằng phần mềm R là tôi thành công.
Mong thầy và các bạn đóng góp về nội dung và hình thức thể hiện để Infographic sau được tốt hơn. Trân trọng cảm ơn.
------------------
Dữ liệu: Đo bằng 3 máy, mỗi máy 10 lần đo
#Số lượt đo mỗi máy 
Time=c(1,2,3,4,5,6,7,8,9,10) 
#Đo bằng 3 máy, mỗi máy 10 lượt đo 
x1=c(9,10,10,9,10,9,11,11,12,9)  
x2=c(12,14,12,2,4,15,9,12,12,8)  
x3=c(19,4,7,1,22,10,7,11,14,5) 
Vẽ hình phân bố của dữ liệu
# Vẽ cho giá trị x1 
plot(Time,x1,ylim=c(0,25),    
      xlim=c(0,10),pch=16,col=""green"", 
      bty=""l"",ylab=""Giá tri X "") 
#Vẽ  đường trung bình = 10 
abline(h=10) 
# Vẽ cho giá trị x2 
par(new=TRUE) 
plot(Time,x2,ylim=c(0,25),xlim=c(0,10),  
      pch=18,col=""darkorange"",bty=""l"",ylab="" "") 
# Vẽ cho giá trị x3 
par(new=TRUE) 
plot(Time,x3,ylim=c(0,25),xlim=c(0,10),    
      pch=17,col=""red"",bty=""l"",ylab="" "")
Vẽ đường phân phối mô phỏng cho x1, x2, x3 với SD tương ứng
x1=rnorm(10000,mean=10,sd=1.05)
x2=rnorm(10000,mean=10,sd=4.24)
x3=rnorm(10000,mean=10,sd=6.68)
plot(density(x1),bty=""l"",xlab="""",col=""green"",lwd=2,xlim=c(-18,37),ylim=c(0,0.4))
abline(v=10, col=""grey"",lty=5)
par(new=TRUE)
plot(density(x2),bty=""l"",xlab="""",col=""darkorange"",lwd=2,xlim=c(-18,37),ylim=c(0,0.4))
par(new=TRUE)
plot(density(x3),bty=""l"",xlab="""",col=""red"",lwd=2,xlim=c(-18,37),ylim=c(0,0.4))","2016-03-04T02:59:52+0000","photo","https://www.facebook.com/photo.php?fbid=1074362812585965&set=gm.570802486407778&type=3","472656846222343_570802486407778",NA,14,0,2
"10208939795155255","Nguyễn Huy Toàn","Xin chào các anh, chị. Em đang học môn giải thuật đồ thi nâng cao. Gv co yeu cầu code giai thuat prim trong igraph trên r. Em đã tim hiêu ma chua códe ra. Cac a chi giup em voi","2016-03-03T16:21:00+0000","status",NA,"472656846222343_570593733095320",NA,0,1,0
"10203062627643544","Son Nghiem","Ai mới học R có thể tự học qua package swirl
Trước hết tải nó về
install.packages(""swirl"", dep=T)

Sau đó khởi động nó
require(swirl)

Rồi bắt đầu học bằng cách go
swirl()

Xem thêm chi tiết tại
http://swirlstats.com/","2016-03-02T12:16:09+0000","status",NA,"472656846222343_570174756470551",NA,19,3,0
"1913258532222776","Tran Quy Phi","Đặt màu cho biểu đồ nhanh chóng, palettes trong R
Nhân có bạn hỏi trong một post của Anh Tuấn về cách đặt màu. Xin giới thiệu cách đặt màu biểu đồ bằng palette (bảng màu?) như sau (dữ liệu lấy trong post của anh Tuấn)
barplot(Weight,col=grey.colors(5))
kết quả là hình 1.
tham số để đặt là col=[palettes], ví dụ các palettes sau:
rainbow
heat.colors
terrain.colors
topo.colors
cm.colors
Tham số cơ bản là số màu, ví dụ:
barplot(Weight,col=grey.colors(5)) #chọn 5 màu trong palette grey.colors.
barplot(Weight,col=heat.colors(5)) #chọn 5 màu trong palette heat.colors (phổ màu nhiệt, rất chói chang!).
Cách dùng palettes vừa nhanh vừa có ""chuẩn"" về màu sắc.","2016-03-03T09:36:38+0000","photo","https://www.facebook.com/photo.php?fbid=1745287135686584&set=gm.570472386440788&type=3","472656846222343_570472386440788",NA,40,0,2
"1245895802184304","Dinh Tien Tai","Hi @Quach Hoa Xiem, vấn đề định dạng trục tọa độ thì còn tùy thuộc vào loại biểu đồ và package bạn sử dụng để vẽ. Ví dụ nếu bạn sử dụng package ggplot2 thì cách định dạng trục tọa độ sẽ khác với package lattice. Dưới đây là  ví dụ  khi sử dụng package lattice và ggplot2
###
library(lattice)
x = 1:100000
y = 1:100000
xyplot(y~x, scales=list(x = list(log = 10),y =list(log = 10) ), type=""l"")
### Sử dụng ggplot2
dat=data.frame(cbind(x,y))
library(ggplot2)
library(scales)
g=ggplot(dat,aes(x,y))+ geom_line()+ scale_x_log10(labels=trans_format(""log10"",math_format(10^.x)))
g1= g +scale_y_log10(labels=trans_format(""log10"",math_format(10^.x)))+theme_bw()
g1
###","2016-03-02T17:53:09+0000","photo","https://www.facebook.com/photo.php?fbid=945666718873882&set=gm.570267423127951&type=3","472656846222343_570267423127951",NA,6,1,1
"1151547058277982","Thiên Hà","Chào các Thầy/Cô, Anh/Chị trong nhóm,
Cho em hỏi: phần Plotting Symbols của web sau có số 0 mang 2 kí tự vuông và bầu dục là sao ạ? Cách viết như thế nào ra kí tự vuông hoặc bầu dục ạ?
Em xin cám ơn!
http://www.statmethods.net/advgraphs/parameters.html","2016-03-01T17:48:38+0000","photo","https://www.facebook.com/photo.php?fbid=879631938802830&set=gm.569898666498160&type=3","472656846222343_569898666498160",NA,2,5,0
"1245895802184304","Dinh Tien Tai","Vẽ đường predicted line với khoảng tin cậy 95%.
Trong generalized linear model (GLM), đôi khi chúng ta muốn vẽ một plot thể hiện đường dự báo các giá trị của biến Y và 2 đường thể hiện upper và lower của khoảng tin cậy 95%. Mình sẽ đưa ra 1 ví dụ và code kèm theo như dưới đây, hi vọng các bạn sẽ cảm thấy hữu ích.
#### Predictor là biến x, biến y trong ví dụ này biến số đếm. Mô hình fm.final là mô hình sau cùng. ( trong ví dụ này mình sử dụng negative binomial model)
####
va.predictor=seq(min(predictor),max(predictor),1)
new.data= data.frame(predictor=va.predictor)
pred=predict(fm.final,newdata=new.data,type=""link"",se.fit=T)
fit=pred$fit
solid=exp(fit)
upper=exp(fit+1.96*pred$se.fit)
lower=exp(fit-1.96*pred$se.fit)
plot(new.data$predictor,solid,type=""n"",xlab=""Predictor"",ylab=""Count"",xlim=c(54,75),ylim=c(0,62))
lines(new.data$predictor,solid,lwd=2)
lines(new.data$predictor,upper,lwd=1,lty=2,col=""blue"")
lines(new.data$predictor,lower,lwd=1,lty=2,col=""blue"")
##### Dưới đây là kết quả","2016-03-02T10:02:48+0000","photo","https://www.facebook.com/photo.php?fbid=945457598894794&set=gm.570131879808172&type=3","472656846222343_570131879808172",NA,19,4,3
"1335697526452550","Giau Le","Chào thầy Tuấn, em xem nhiều video của thầy trên youtube mà em chưa tìm thấy bài nào về linear SVMs.

Thầy có video nào về linear SVMs không?

Con cảm ơn Thầy.","2016-03-02T03:14:41+0000","status",NA,"472656846222343_570037876484239",NA,1,2,0
"2395293327278777","Trung Nguyen Thanh","E tham khảo một số tài liệu thì bảo stationary points trong kết quả phân tích của R là điểm tối ưu, trong khi một số khác thì bảo phải dựa kết quả phân tích trên response surface & contour plots. Một số bài báo đã publish thì đi giải phương trình rồi so sánh các giá trị y. Tại điểm nào (x1, x2, x3) cho giá trị y lớn nhất thì điểm đó được chọn làm điểm tối ưu. Do đó e khg biết cách nào là đúng nhất. Kính nhờ thầy cùng các thành viên của group chỉ giúp thêm.","2016-03-01T11:32:57+0000","status",NA,"472656846222343_569796639841696",NA,3,9,0
"2395293327278777","Trung Nguyen Thanh","E dùng R với Box-Bexhken design để optimisation với 3 factors & 3 levels. Sau khi dựa vào data thí nghiệm thì xây dựng được equation cho model. Từ đó e vẽ response surface & contour plots. Câu hỏi của e là làm sao tìm ra điểm tối ưu (optimum conditions)? Cám ơn thầy cùng Bs!","2016-03-01T11:30:08+0000","status",NA,"472656846222343_569796053175088",NA,1,0,0
"1333580880039306","Trần Thanh Tùng","Đây là lần đầu tiên em được nghe đến khái niệm ngôn ngữ R, em có đọc qua link do thầy Tuấn chia sẻ: http://tuanvannguyen.blogspot.com.au/2015/11/tai-sao-hoc-r-van-ap.html và em muốn hỏi rằng đây là phần mềm thống kê hay là cái gì khác? Nó ra đời như thế nào và được sử dụng trên thế giới như thế nào và tại sao những người làm nghiên cứu ở Việt Nam nên sử dụng nó?
Rất mong nhận được câu trả lời từ các thầy, các các bác, các anh chị để em có thể hiểu thêm về khái niệm mới này. Xin chân thành cảm ơn!!!","2016-03-01T10:25:03+0000","link","http://tuanvannguyen.blogspot.com.au/2015/11/tai-sao-hoc-r-van-ap.html","472656846222343_569772586510768",NA,14,3,0
"1913258532222776","Tran Quy Phi",NA,"2016-03-01T05:02:09+0000","status",NA,"472656846222343_569687206519306",NA,3,0,0
"1913258532222776","Tran Quy Phi","Thảo luận về thống kê ứng dụng và ngôn ngữ R","2015-06-02T08:30:10+0000","status",NA,"472656846222343_472657046222323",NA,36,6,0
"1913258532222776","Tran Quy Phi",NA,"2015-06-02T08:28:09+0000","status",NA,"472656846222343_472656849555676",NA,17,0,0
